{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CompProject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emundusov/compproject/blob/master/CompProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXri_A4BXbat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf_repo_url = 'https://github.com/tensorflow/models'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIGsd59pABaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff196nHJXtgF",
        "colab_type": "code",
        "outputId": "080e1194-65cf-4844-bd27-c7492babb53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(tf_repo_url)))\n",
        "\n",
        "!git clone {tf_repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 31137 (delta 3), reused 11 (delta 1), pack-reused 31112\u001b[K\n",
            "Receiving objects: 100% (31137/31137), 510.68 MiB | 31.80 MiB/s, done.\n",
            "Resolving deltas: 100% (19616/19616), done.\n",
            "Checking out files: 100% (3057/3057), done.\n",
            "/content/models\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK1UXP1TYHnJ",
        "colab_type": "code",
        "outputId": "d4d74e2a-1192-4e38-bc17-d02b4776787d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 131183 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.8: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 16 tests in 0.168s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcqjOr4AYY5k",
        "colab_type": "code",
        "outputId": "928f450f-3193-49de-fcac-36f4f4196f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "!python3 setup.py install"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating object_detection.egg-info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/object_detection\n",
            "copying object_detection/exporter.py -> build/lib/object_detection\n",
            "copying object_detection/inputs.py -> build/lib/object_detection\n",
            "copying object_detection/export_tflite_ssd_graph_lib_test.py -> build/lib/object_detection\n",
            "copying object_detection/inputs_test.py -> build/lib/object_detection\n",
            "copying object_detection/model_tpu_main.py -> build/lib/object_detection\n",
            "copying object_detection/model_main.py -> build/lib/object_detection\n",
            "copying object_detection/model_lib_test.py -> build/lib/object_detection\n",
            "copying object_detection/model_lib_v2.py -> build/lib/object_detection\n",
            "copying object_detection/__init__.py -> build/lib/object_detection\n",
            "copying object_detection/export_tflite_ssd_graph.py -> build/lib/object_detection\n",
            "copying object_detection/model_lib.py -> build/lib/object_detection\n",
            "copying object_detection/model_hparams.py -> build/lib/object_detection\n",
            "copying object_detection/eval_util.py -> build/lib/object_detection\n",
            "copying object_detection/exporter_test.py -> build/lib/object_detection\n",
            "copying object_detection/export_tflite_ssd_graph_lib.py -> build/lib/object_detection\n",
            "copying object_detection/export_inference_graph.py -> build/lib/object_detection\n",
            "copying object_detection/eval_util_test.py -> build/lib/object_detection\n",
            "copying object_detection/model_lib_v2_test.py -> build/lib/object_detection\n",
            "creating build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/keypoint_box_coder_test.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/mean_stddev_box_coder.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/faster_rcnn_box_coder.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/mean_stddev_box_coder_test.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/square_box_coder.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/__init__.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/keypoint_box_coder.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/square_box_coder_test.py -> build/lib/object_detection/box_coders\n",
            "copying object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/lib/object_detection/box_coders\n",
            "creating build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/trainer.py -> build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/trainer_test.py -> build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/train.py -> build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/evaluator.py -> build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/__init__.py -> build/lib/object_detection/legacy\n",
            "copying object_detection/legacy/eval.py -> build/lib/object_detection/legacy\n",
            "creating build/lib/object_detection/models\n",
            "copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_inception_v3_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/feature_map_generators_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/__init__.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/feature_map_generators.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_pnasnet_feature_extractor.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "copying object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/lib/object_detection/models\n",
            "creating build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/calibration_evaluation_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/coco_evaluation.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/coco_tools.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/tf_example_parser.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/calibration_metrics.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/coco_evaluation_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/__init__.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/offline_eval_map_corloc_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/calibration_metrics_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/coco_tools_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/io_utils.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/offline_eval_map_corloc.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/calibration_evaluation.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/tf_example_parser_test.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_challenge_evaluation.py -> build/lib/object_detection/metrics\n",
            "copying object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/lib/object_detection/metrics\n",
            "creating build/lib/object_detection/matchers\n",
            "copying object_detection/matchers/bipartite_matcher_test.py -> build/lib/object_detection/matchers\n",
            "copying object_detection/matchers/argmax_matcher.py -> build/lib/object_detection/matchers\n",
            "copying object_detection/matchers/argmax_matcher_test.py -> build/lib/object_detection/matchers\n",
            "copying object_detection/matchers/__init__.py -> build/lib/object_detection/matchers\n",
            "copying object_detection/matchers/bipartite_matcher.py -> build/lib/object_detection/matchers\n",
            "creating build/lib/object_detection/inference\n",
            "copying object_detection/inference/infer_detections.py -> build/lib/object_detection/inference\n",
            "copying object_detection/inference/detection_inference_test.py -> build/lib/object_detection/inference\n",
            "copying object_detection/inference/__init__.py -> build/lib/object_detection/inference\n",
            "copying object_detection/inference/detection_inference.py -> build/lib/object_detection/inference\n",
            "creating build/lib/object_detection/utils\n",
            "copying object_detection/utils/learning_schedules_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_mask_list_ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/context_manager.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_mask_list.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_list_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/config_util.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_mask_list_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/shape_utils.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_mask_ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/label_map_util_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/metrics.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/spatial_transform_ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/label_map_util.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_mask_list_ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_list.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/context_manager_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/object_detection_evaluation.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/test_utils.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/static_shape_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/category_util_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/per_image_vrd_evaluation.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/variables_helper.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/json_utils.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/test_case.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/config_util_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/per_image_vrd_evaluation_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/__init__.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/learning_schedules.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/test_utils_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/vrd_evaluation.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/dataset_util_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/shape_utils_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/dataset_util.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/category_util.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/object_detection_evaluation_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_list_ops_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/model_util_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/model_util.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_box_list_ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/json_utils_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/static_shape.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/np_mask_ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/per_image_evaluation.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/variables_helper_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/per_image_evaluation_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/autoaugment_utils.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/spatial_transform_ops.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/visualization_utils_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/visualization_utils.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/vrd_evaluation_test.py -> build/lib/object_detection/utils\n",
            "copying object_detection/utils/metrics_test.py -> build/lib/object_detection/utils\n",
            "creating build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/ssd_meta_arch.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/rfcn_meta_arch.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/ssd_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/__init__.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n",
            "copying object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n",
            "creating build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/rfcn_keras_box_predictor.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/__init__.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/rfcn_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/convolutional_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/convolutional_box_predictor.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/mask_rcnn_box_predictor.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/convolutional_keras_box_predictor.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/lib/object_detection/predictors\n",
            "copying object_detection/predictors/rfcn_box_predictor.py -> build/lib/object_detection/predictors\n",
            "creating build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/ssd.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/faster_rcnn.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/utils_test.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/__init__.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/utils.py -> build/lib/object_detection/tpu_exporters\n",
            "copying object_detection/tpu_exporters/export_saved_model_tpu.py -> build/lib/object_detection/tpu_exporters\n",
            "creating build/lib/object_detection/protos\n",
            "copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/__init__.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n",
            "creating build/lib/object_detection/data_decoders\n",
            "copying object_detection/data_decoders/tf_example_decoder.py -> build/lib/object_detection/data_decoders\n",
            "copying object_detection/data_decoders/__init__.py -> build/lib/object_detection/data_decoders\n",
            "copying object_detection/data_decoders/tf_example_decoder_test.py -> build/lib/object_detection/data_decoders\n",
            "creating build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_pet_tf_record.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_coco_tf_record.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_kitti_tf_record.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_pascal_tf_record.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/tf_record_creation_util.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/__init__.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_coco_tf_record_test.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_oid_tf_record.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/tf_record_creation_util_test.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/oid_tfrecord_creation.py -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/lib/object_detection/dataset_tools\n",
            "creating build/lib/object_detection/core\n",
            "copying object_detection/core/prefetcher_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_list.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/losses.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/target_assigner_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/batcher.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/model.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/matcher.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/prefetcher.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/multiclass_nms_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/keypoint_ops_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_list_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/preprocessor.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/preprocessor_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/post_processing.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_coder_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/minibatch_sampler_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/batch_multiclass_nms_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/__init__.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/keypoint_ops.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/data_parser.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/freezable_batch_norm_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/matcher_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/minibatch_sampler.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/balanced_positive_negative_sampler.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/class_agnostic_nms_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/losses_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_predictor.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/standard_fields.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/balanced_positive_negative_sampler_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/anchor_generator.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_coder.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/region_similarity_calculator.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/region_similarity_calculator_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_list_ops.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/preprocessor_cache.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/box_list_ops_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/batcher_test.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/freezable_batch_norm.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/target_assigner.py -> build/lib/object_detection/core\n",
            "copying object_detection/core/data_decoder.py -> build/lib/object_detection/core\n",
            "creating build/lib/object_detection/builders\n",
            "copying object_detection/builders/dataset_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/optimizer_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/matcher_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/box_coder_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/anchor_generator_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/preprocessor_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/hyperparams_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/preprocessor_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/calibration_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/anchor_generator_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/losses_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/region_similarity_calculator_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/losses_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/dataset_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/box_predictor_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/graph_rewriter_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/graph_rewriter_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/__init__.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/input_reader_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/image_resizer_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/box_predictor_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/model_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/image_resizer_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/input_reader_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/calibration_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/model_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/matcher_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/hyperparams_builder_test.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/region_similarity_calculator_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/post_processing_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/box_coder_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/optimizer_builder.py -> build/lib/object_detection/builders\n",
            "copying object_detection/builders/post_processing_builder_test.py -> build/lib/object_detection/builders\n",
            "creating build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/__init__.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n",
            "copying object_detection/anchor_generators/grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n",
            "creating build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/inception_resnet_v2_test.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/inception_resnet_v2.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/test_utils.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/mobilenet_v1_test.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/__init__.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/mobilenet_v2.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/resnet_v1_test.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/model_utils.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/mobilenet_v2_test.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/mobilenet_v1.py -> build/lib/object_detection/models/keras_models\n",
            "copying object_detection/models/keras_models/resnet_v1.py -> build/lib/object_detection/models/keras_models\n",
            "creating build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/class_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/mask_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_mask_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/mask_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keypoint_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_box_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keypoint_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/box_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/__init__.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_mask_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_class_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_class_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/box_head.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/keras_box_head_test.py -> build/lib/object_detection/predictors/heads\n",
            "copying object_detection/predictors/heads/class_head.py -> build/lib/object_detection/predictors/heads\n",
            "creating build/lib/object_detection/tpu_exporters/testdata\n",
            "copying object_detection/tpu_exporters/testdata/__init__.py -> build/lib/object_detection/tpu_exporters/testdata\n",
            "copying object_detection/CONTRIBUTING.md -> build/lib/object_detection\n",
            "copying object_detection/README.md -> build/lib/object_detection\n",
            "copying object_detection/object_detection_tutorial.ipynb -> build/lib/object_detection\n",
            "creating build/lib/object_detection/data\n",
            "copying object_detection/data/ava_label_map_v2.1.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/face_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/kitti_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/mscoco_complete_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/mscoco_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/mscoco_minival_ids.txt -> build/lib/object_detection/data\n",
            "copying object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/oid_v4_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/pascal_label_map.pbtxt -> build/lib/object_detection/data\n",
            "copying object_detection/data/pet_label_map.pbtxt -> build/lib/object_detection/data\n",
            "creating build/lib/object_detection/dockerfiles\n",
            "creating build/lib/object_detection/dockerfiles/android\n",
            "copying object_detection/dockerfiles/android/Dockerfile -> build/lib/object_detection/dockerfiles/android\n",
            "copying object_detection/dockerfiles/android/README.md -> build/lib/object_detection/dockerfiles/android\n",
            "creating build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/challenge_evaluation.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/configuring_jobs.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/defining_your_own_model.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/detection_model_zoo.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/evaluation_protocols.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/exporting_models.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/faq.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/installation.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/instance_segmentation.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/oid_inference_and_evaluation.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/preparing_inputs.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/running_locally.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/running_notebook.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/running_on_cloud.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/running_pets.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/tpu_compatibility.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/tpu_exporters.md -> build/lib/object_detection/g3doc\n",
            "copying object_detection/g3doc/using_your_own_dataset.md -> build/lib/object_detection/g3doc\n",
            "creating build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/dataset_explorer.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/dogs_detections_output.jpg -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/example_cat.jpg -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/groupof_case_eval.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/kites_detections_output.jpg -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/kites_with_segment_overlay.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/nongroupof_case_eval.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/oxford_pet.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/tensorboard.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/tensorboard2.png -> build/lib/object_detection/g3doc/img\n",
            "copying object_detection/g3doc/img/tf-od-api-logo.png -> build/lib/object_detection/g3doc/img\n",
            "creating build/lib/object_detection/samples\n",
            "creating build/lib/object_detection/samples/cloud\n",
            "copying object_detection/samples/cloud/cloud.yml -> build/lib/object_detection/samples/cloud\n",
            "creating build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/rfcn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/rfcn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_inception_v3_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n",
            "copying object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n",
            "creating build/lib/object_detection/test_ckpt\n",
            "copying object_detection/test_ckpt/ssd_inception_v2.pb -> build/lib/object_detection/test_ckpt\n",
            "creating build/lib/object_detection/test_data\n",
            "copying object_detection/test_data/pets_examples.record -> build/lib/object_detection/test_data\n",
            "creating build/lib/object_detection/test_images\n",
            "copying object_detection/test_images/image1.jpg -> build/lib/object_detection/test_images\n",
            "copying object_detection/test_images/image2.jpg -> build/lib/object_detection/test_images\n",
            "copying object_detection/test_images/image_info.txt -> build/lib/object_detection/test_images\n",
            "copying object_detection/protos/anchor_generator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/argmax_matcher.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/bipartite_matcher.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_coder.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/box_predictor.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/calibration.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/eval.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/faster_rcnn_box_coder.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/flexible_grid_anchor_generator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/graph_rewriter.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/grid_anchor_generator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/hyperparams.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/image_resizer.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/input_reader.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/keypoint_box_coder.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/losses.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/matcher.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/mean_stddev_box_coder.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/model.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/multiscale_anchor_generator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/optimizer.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/pipeline.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/post_processing.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/preprocessor.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/region_similarity_calculator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/square_box_coder.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/ssd_anchor_generator.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/string_int_label_map.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/protos/train.proto -> build/lib/object_detection/protos\n",
            "copying object_detection/dataset_tools/create_pycocotools_package.sh -> build/lib/object_detection/dataset_tools\n",
            "copying object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/lib/object_detection/dataset_tools\n",
            "creating build/lib/object_detection/models/keras_models/base_models\n",
            "copying object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/lib/object_detection/models/keras_models/base_models\n",
            "creating build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "copying object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "creating build/lib/object_detection/tpu_exporters/testdata/ssd\n",
            "copying object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/lib/object_detection/tpu_exporters/testdata/ssd\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n",
            "copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/object_detection_tutorial.ipynb -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/challenge_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_pets.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/defining_your_own_model.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/tpu_exporters.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/instance_segmentation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/oid_inference_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/tpu_compatibility.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/evaluation_protocols.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/faq.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/exporting_models.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_notebook.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/detection_model_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/installation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/preparing_inputs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/groupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/kites_with_segment_overlay.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/kites_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/dataset_explorer.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/example_cat.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/oxford_pet.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tensorboard2.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/dogs_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tf-od-api-logo.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/nongroupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/img/tensorboard.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n",
            "copying build/lib/object_detection/g3doc/configuring_jobs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/using_your_own_dataset.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_on_cloud.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/g3doc/running_locally.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n",
            "copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/trainer_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n",
            "copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/inception_resnet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n",
            "copying build/lib/object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n",
            "copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/resnet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n",
            "copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n",
            "copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/bipartite_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/detection_inference_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "copying build/lib/object_detection/dockerfiles/android/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "copying build/lib/object_detection/dockerfiles/android/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n",
            "copying build/lib/object_detection/model_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/model_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/variables_helper_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/README.md -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keypoint_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/keras_box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n",
            "copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n",
            "copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n",
            "copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n",
            "copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/rfcn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v3_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/rfcn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n",
            "copying build/lib/object_detection/samples/cloud/cloud.yml -> build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_data\n",
            "copying build/lib/object_detection/test_data/pets_examples.record -> build/bdist.linux-x86_64/egg/object_detection/test_data\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/multiscale_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/argmax_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/bipartite_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/optimizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/region_similarity_calculator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/calibration.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/mean_stddev_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/graph_rewriter.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/image_resizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/hyperparams.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/post_processing.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/square_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/eval.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/train.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/keypoint_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/preprocessor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/ssd.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/model.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_predictor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/flexible_grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/input_reader.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/faster_rcnn_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/pipeline.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/losses.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/string_int_label_map.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n",
            "copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/CONTRIBUTING.md -> build/bdist.linux-x86_64/egg/object_detection\n",
            "copying build/lib/object_detection/exporter_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/dataset_tools/create_pycocotools_package.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n",
            "copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n",
            "copying build/lib/object_detection/test_ckpt/ssd_inception_v2.pb -> build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/prefetcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/freezable_batch_norm_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/batcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/optimizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/graph_rewriter_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/input_reader_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n",
            "copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n",
            "copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/pet_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_v4_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_minival_ids.txt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/pascal_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/face_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/ava_label_map_v2.1.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/kitti_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/data/mscoco_complete_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n",
            "copying build/lib/object_detection/model_lib_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n",
            "creating build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image_info.txt -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "copying build/lib/object_detection/test_images/image2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_test.py to export_tflite_ssd_graph_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_test.py to trainer_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_test.py to inception_resnet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models/original_mobilenet_v2.py to original_mobilenet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_test.py to mobilenet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_test.py to resnet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_test.py to mobilenet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py to embedded_ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py to faster_rcnn_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py to ssd_resnet_v1_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py to faster_rcnn_inception_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py to ssd_mobilenet_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py to ssd_mobilenet_v2_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py to faster_rcnn_resnet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_test.py to faster_rcnn_nas_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py to faster_rcnn_pnas_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_test.py to ssd_pnasnet_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py to ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py to ssd_mobilenet_v1_fpn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py to ssd_mobilenet_v1_ppn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py to ssd_resnet_v1_ppn_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_test.py to ssd_inception_v3_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_test.py to ssd_inception_v2_feature_extractor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_test.py to calibration_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_test.py to calibration_metrics_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_test.py to bipartite_matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_test.py to detection_inference_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_test.py to model_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_test.py to model_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_test.py to variables_helper_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_test.py to rfcn_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py to mask_rcnn_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_test.py to convolutional_keras_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_test.py to class_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_test.py to mask_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_test.py to keras_mask_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_test.py to keypoint_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_test.py to box_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_test.py to keras_class_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_test.py to keras_box_head_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_test.py to rfcn_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_test.py to convolutional_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_test.py to mask_rcnn_box_predictor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py to export_saved_model_tpu_lib_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_test.py to exporter_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_test.py to prefetcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_test.py to freezable_batch_norm_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_test.py to batcher_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_test.py to optimizer_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_test.py to graph_rewriter_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_test.py to input_reader_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2_test.py to model_lib_v2_test.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n",
            "object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n",
            "creating dist\n",
            "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing object_detection-0.1-py3.6.egg\n",
            "creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding object-detection 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Processing dependencies for object-detection==0.1\n",
            "Searching for Cython==0.29.13\n",
            "Best match: Cython 0.29.13\n",
            "Adding Cython 0.29.13 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.0.3\n",
            "Best match: matplotlib 3.0.3\n",
            "Adding matplotlib 3.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==4.3.0\n",
            "Best match: Pillow 4.3.0\n",
            "Adding Pillow 4.3.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.16.5\n",
            "Best match: numpy 1.16.5\n",
            "Adding numpy 1.16.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.5.3\n",
            "Best match: python-dateutil 2.5.3\n",
            "Adding python-dateutil 2.5.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.2\n",
            "Best match: pyparsing 2.4.2\n",
            "Adding pyparsing 2.4.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for olefile==0.46\n",
            "Best match: olefile 0.46\n",
            "Adding olefile 0.46 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==41.2.0\n",
            "Best match: setuptools 41.2.0\n",
            "Adding setuptools 41.2.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for object-detection==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lag_ZUXtYhcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp_repo_url = 'https://github.com/emundusov/compproject'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08p6bjwfYs66",
        "colab_type": "code",
        "outputId": "59b3e2d3-afa0-4b6d-db1f-bed262373c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path2 = os.path.abspath(os.path.join('.', os.path.basename(tf_repo_url)))\n",
        "\n",
        "!git clone {cp_repo_url}\n",
        "%cd {repo_dir_path2}\n",
        "!git pull"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'compproject'...\n",
            "remote: Enumerating objects: 107, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 1358 (delta 49), reused 102 (delta 48), pack-reused 1251\u001b[K\n",
            "Receiving objects: 100% (1358/1358), 87.74 MiB | 27.77 MiB/s, done.\n",
            "Resolving deltas: 100% (731/731), done.\n",
            "/content/models\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMPXUVFiv9Iy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/compproject/images/converted_annotation_in_txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3yrUrAWtGtp",
        "colab_type": "code",
        "outputId": "f3d4d596-7414-4546-f7e6-b1879dfa7d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "out_path = \"/content/compproject/images/bb_box.txt\"\n",
        "data_path = \"/content/compproject/images/train\"\n",
        "img_path = \"/content/compproject/images/train\"\n",
        "xml_path = \"/content/compproject/images/train\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def pca_color_augmentation(image):\n",
        "    assert image.ndim == 3 and image.shape[2] == 3\n",
        "    assert image.dtype == np.uint8\n",
        "    img = image.reshape(-1, 3).astype(np.float32)\n",
        "    sf = np.sqrt(3.0/np.sum(np.var(img, axis=0)))\n",
        "    img = (img - np.mean(img, axis=0))*sf \n",
        "    cov = np.cov(img, rowvar=False) # calculate the covariance matrix\n",
        "    value, p = np.linalg.eig(cov) # calculation of eigen vector and eigen value \n",
        "    rand = np.random.randn(3)*0.08\n",
        "    delta = np.dot(p, rand*value)\n",
        "    delta = (delta*255.0).astype(np.int32)[np.newaxis, np.newaxis, :]\n",
        "    img_out = np.clip(image+delta, 0, 255).astype(np.uint8)\n",
        "    return img_out\n",
        "\n",
        "\n",
        "xml_paths = [os.path.join(xml_path, s) for s in os.listdir(xml_path) if s.endswith('.xml')]\n",
        "#print(xml_paths)\n",
        "\n",
        "pwd_lines = []\n",
        "for xml_file in xml_paths:\n",
        "    et = ET.parse(xml_file)\n",
        "    element = et.getroot()\n",
        "    element_objs = element.findall('object') \n",
        "    element_filename = element.find('filename').text\n",
        "    base_filename = os.path.join(data_path, element_filename)\n",
        "    print(base_filename)                               \n",
        "    img = cv2.imread(base_filename)\n",
        "    rows, cols = img.shape[:2] \n",
        "\n",
        "    img_split = element_filename.strip().split('.jpg')\n",
        "        \n",
        "    for element_obj in element_objs:\n",
        "        class_name = element_obj.find('name').text # return name tag ie class of disease from xml file\n",
        "\n",
        "        obj_bbox = element_obj.find('bndbox')\n",
        "        #print(obj_bbox)\n",
        "        x1 = int(round(float(obj_bbox.find('xmin').text)))\n",
        "        y1 = int(round(float(obj_bbox.find('ymin').text)))\n",
        "        x2 = int(round(float(obj_bbox.find('xmax').text)))\n",
        "        y2 = int(round(float(obj_bbox.find('ymax').text)))\n",
        "# if you specify range(1) total number of augmented data is 6 for one image\n",
        "# 6 types of augmentation means pca, horizontal and vertical flip, 3 rotation\n",
        "# if you specify range(2) total number of augmented data is 12 for one image\n",
        "        for color in range(1):\n",
        "            img_color = pca_color_augmentation(img)\n",
        "            color_name = img_split[0]+ '-color' + str(color)\n",
        "            color_jpg = color_name + '.jpg'\n",
        "            new_path = os.path.join(img_path, color_jpg) # join with augmented image path\n",
        "            lines = [color_jpg, ',', str(x1), ',', str(y1), ',', str(x2), ',', str(y2), ',', class_name, '\\n']\n",
        "            pwd_lines.append(lines)\n",
        "            if not os.path.isfile(new_path):\n",
        "                cv2.imwrite(new_path, img_color)\n",
        "            \n",
        "            # for horizontal and vertical flip\n",
        "            f_points = [0, 1]\n",
        "            for f in f_points:\n",
        "                f_img = cv2.flip(img_color, f)\n",
        "                h,w = img_color.shape[:2]\n",
        "                \n",
        "                if f == 1:\n",
        "                    f_x1 = w-x2\n",
        "                    f_y1 = y1\n",
        "                    f_x2 = w-x1\n",
        "                    f_y2 = y2\n",
        "                    f_str = 'f1'\n",
        "                elif f == 0:\n",
        "                    f_x1 = x1\n",
        "                    f_y1 = h-y2\n",
        "                    f_x2 = x2\n",
        "                    f_y2 = h-y1\n",
        "                    f_str = 'f0'\n",
        "                \n",
        "                new_name = color_name + '-' + f_str + '.jpg'\n",
        "                new_path = os.path.join(img_path, new_name)\n",
        "                \n",
        "                lines = [new_name, ',', str(f_x1), ',', str(f_y1), ',', str(f_x2), ',', str(f_y2), ',', class_name, '\\n']\n",
        "                pwd_lines.append(lines)\n",
        "                if not os.path.isfile(new_path):\n",
        "                    cv2.imwrite(new_path, f_img)\n",
        "                    \n",
        "            # for angle 90\n",
        "            img_transpose = np.transpose(img_color, (1,0,2))\n",
        "            img_90 = cv2.flip(img_transpose, 1)\n",
        "            h,w = img_color.shape[:2]\n",
        "            angle_x1 = h - y2\n",
        "            angle_y1 = x1\n",
        "            angle_x2 = h -y1\n",
        "            angle_y2 = x2\n",
        "            new_name = color_name + '-' + 'rotate_90' + '.jpg'\n",
        "            new_path = os.path.join(img_path, new_name)\n",
        "            lines = [new_name, ',', str(angle_x1), ',', str(angle_y1), ',', str(angle_x2), ',', str(angle_y2), ',', class_name, '\\n']\n",
        "            pwd_lines.append(lines)\n",
        "            if not os.path.isfile(new_path):\n",
        "                cv2.imwrite(new_path,img_90)\n",
        "                \n",
        "            #for angle 180\n",
        "            img_180 = cv2.flip(img_color, -1)\n",
        "            ang_x1 = w - x2\n",
        "            ang_y1 = h - y2\n",
        "            ang_x2 = w - x1\n",
        "            ang_y2 = h - y1\n",
        "            new_name_180 = color_name + '-' + 'rotate_180' + '.jpg'\n",
        "            new_path_180 = os.path.join(img_path, new_name_180)\n",
        "            lines_180 = [new_name_180, ',', str(ang_x1), ',', str(ang_y1), ',', str(ang_x2), ',', str(ang_y2), ',', class_name, '\\n']\n",
        "            pwd_lines.append(lines_180)\n",
        "            if not os.path.isfile(new_path_180):\n",
        "                cv2.imwrite(new_path_180,img_180)\n",
        "                \n",
        "            #for angle 270\n",
        "            img_transpose_270 = np.transpose(img_color, (1,0,2))\n",
        "            img_270 = cv2.flip(img_transpose_270, 0)\n",
        "            an_x1 = y1\n",
        "            an_y1 = w - x2\n",
        "            an_x2 = y2\n",
        "            an_y2 = w - x1\n",
        "            new_name_270 = color_name + '-' + 'rotate_270' + '.jpg'\n",
        "            new_path_270 = os.path.join(img_path, new_name_270)\n",
        "            lines_270 = [new_name_270, ',', str(an_x1), ',', str(an_y1), ',', str(an_x2), ',', str(an_y2), ',', class_name, '\\n']\n",
        "            pwd_lines.append(lines_270)\n",
        "            if not os.path.isfile(new_path_270):\n",
        "                cv2.imwrite(new_path_270, img_270)\n",
        "    \n",
        "#print(pwd_lines)\n",
        "if len(pwd_lines) > 0 :\n",
        "    with open(out_path, 'w') as f:\n",
        "        for line in pwd_lines:\n",
        "            f.writelines(line)\n",
        "            \n",
        "print('End')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/compproject/images/train/palm_15.jpg\n",
            "/content/compproject/images/train/peace_78.jpg\n",
            "/content/compproject/images/train/ok_91.jpg\n",
            "/content/compproject/images/train/ok_35.jpg\n",
            "/content/compproject/images/train/palm_35.jpg\n",
            "/content/compproject/images/train/peace_3.jpg\n",
            "/content/compproject/images/train/peace_87.jpg\n",
            "/content/compproject/images/train/ok_79.jpg\n",
            "/content/compproject/images/train/ok_77.jpg\n",
            "/content/compproject/images/train/peace_92.jpg\n",
            "/content/compproject/images/train/ok_9.jpg\n",
            "/content/compproject/images/train/palm_24.jpg\n",
            "/content/compproject/images/train/palm_94.jpg\n",
            "/content/compproject/images/train/ok_20.jpg\n",
            "/content/compproject/images/train/ok_87.jpg\n",
            "/content/compproject/images/train/palm_34.jpg\n",
            "/content/compproject/images/train/ok_76.jpg\n",
            "/content/compproject/images/train/ok_59.jpg\n",
            "/content/compproject/images/train/ok_1.jpg\n",
            "/content/compproject/images/train/peace_28.jpg\n",
            "/content/compproject/images/train/palm_28.jpg\n",
            "/content/compproject/images/train/palm_43.jpg\n",
            "/content/compproject/images/train/ok_26.jpg\n",
            "/content/compproject/images/train/palm_67.jpg\n",
            "/content/compproject/images/train/peace_59.jpg\n",
            "/content/compproject/images/train/ok_15.jpg\n",
            "/content/compproject/images/train/ok_81.jpg\n",
            "/content/compproject/images/train/peace_91.jpg\n",
            "/content/compproject/images/train/peace_35.jpg\n",
            "/content/compproject/images/train/palm_88.jpg\n",
            "/content/compproject/images/train/peace_9.jpg\n",
            "/content/compproject/images/train/ok_90.jpg\n",
            "/content/compproject/images/train/peace_84.jpg\n",
            "/content/compproject/images/train/peace_93.jpg\n",
            "/content/compproject/images/train/ok_80.jpg\n",
            "/content/compproject/images/train/palm_70.jpg\n",
            "/content/compproject/images/train/palm_79.jpg\n",
            "/content/compproject/images/train/peace_31.jpg\n",
            "/content/compproject/images/train/palm_66.jpg\n",
            "/content/compproject/images/train/peace_24.jpg\n",
            "/content/compproject/images/train/ok_28.jpg\n",
            "/content/compproject/images/train/peace_68.jpg\n",
            "/content/compproject/images/train/peace_6.jpg\n",
            "/content/compproject/images/train/ok_69.jpg\n",
            "/content/compproject/images/train/palm_55.jpg\n",
            "/content/compproject/images/train/peace_20.jpg\n",
            "/content/compproject/images/train/palm_53.jpg\n",
            "/content/compproject/images/train/peace_96.jpg\n",
            "/content/compproject/images/train/palm_18.jpg\n",
            "/content/compproject/images/train/palm_38.jpg\n",
            "/content/compproject/images/train/ok_29.jpg\n",
            "/content/compproject/images/train/peace_86.jpg\n",
            "/content/compproject/images/train/peace_29.jpg\n",
            "/content/compproject/images/train/peace_55.jpg\n",
            "/content/compproject/images/train/peace_76.jpg\n",
            "/content/compproject/images/train/palm_20.jpg\n",
            "/content/compproject/images/train/palm_56.jpg\n",
            "/content/compproject/images/train/palm_6.jpg\n",
            "/content/compproject/images/train/ok_93.jpg\n",
            "/content/compproject/images/train/palm_95.jpg\n",
            "/content/compproject/images/train/peace_58.jpg\n",
            "/content/compproject/images/train/palm_76.jpg\n",
            "/content/compproject/images/train/ok_61.jpg\n",
            "/content/compproject/images/train/ok_88.jpg\n",
            "/content/compproject/images/train/palm_42.jpg\n",
            "/content/compproject/images/train/peace_83.jpg\n",
            "/content/compproject/images/train/ok_92.jpg\n",
            "/content/compproject/images/train/ok_25.jpg\n",
            "/content/compproject/images/train/palm_16.jpg\n",
            "/content/compproject/images/train/peace_66.jpg\n",
            "/content/compproject/images/train/ok_6.jpg\n",
            "/content/compproject/images/train/palm_93.jpg\n",
            "/content/compproject/images/train/palm_96.jpg\n",
            "/content/compproject/images/train/ok_33.jpg\n",
            "/content/compproject/images/train/palm_82.jpg\n",
            "/content/compproject/images/train/ok_65.jpg\n",
            "/content/compproject/images/train/palm_59.jpg\n",
            "/content/compproject/images/train/palm_17.jpg\n",
            "/content/compproject/images/train/palm_72.jpg\n",
            "/content/compproject/images/train/ok_97.jpg\n",
            "/content/compproject/images/train/peace_63.jpg\n",
            "/content/compproject/images/train/peace_90.jpg\n",
            "/content/compproject/images/train/peace_54.jpg\n",
            "/content/compproject/images/train/peace_81.jpg\n",
            "/content/compproject/images/train/palm_36.jpg\n",
            "/content/compproject/images/train/ok_85.jpg\n",
            "/content/compproject/images/train/ok_60.jpg\n",
            "/content/compproject/images/train/palm_87.jpg\n",
            "/content/compproject/images/train/ok_31.jpg\n",
            "/content/compproject/images/train/peace_10.jpg\n",
            "/content/compproject/images/train/ok_54.jpg\n",
            "/content/compproject/images/train/peace_12.jpg\n",
            "/content/compproject/images/train/palm_63.jpg\n",
            "/content/compproject/images/train/peace_95.jpg\n",
            "/content/compproject/images/train/ok_47.jpg\n",
            "/content/compproject/images/train/ok_17.jpg\n",
            "/content/compproject/images/train/peace_34.jpg\n",
            "/content/compproject/images/train/palm_4.jpg\n",
            "/content/compproject/images/train/palm_86.jpg\n",
            "/content/compproject/images/train/ok_23.jpg\n",
            "/content/compproject/images/train/peace_40.jpg\n",
            "/content/compproject/images/train/ok_16.jpg\n",
            "/content/compproject/images/train/peace_70.jpg\n",
            "/content/compproject/images/train/palm_9.jpg\n",
            "/content/compproject/images/train/peace_32.jpg\n",
            "/content/compproject/images/train/peace_88.jpg\n",
            "/content/compproject/images/train/ok_41.jpg\n",
            "/content/compproject/images/train/palm_77.jpg\n",
            "/content/compproject/images/train/peace_17.jpg\n",
            "/content/compproject/images/train/peace_27.jpg\n",
            "/content/compproject/images/train/ok_63.jpg\n",
            "/content/compproject/images/train/ok_7.jpg\n",
            "/content/compproject/images/train/ok_14.jpg\n",
            "/content/compproject/images/train/ok_89.jpg\n",
            "/content/compproject/images/train/palm_57.jpg\n",
            "/content/compproject/images/train/palm_31.jpg\n",
            "/content/compproject/images/train/palm_7.jpg\n",
            "/content/compproject/images/train/palm_91.jpg\n",
            "/content/compproject/images/train/peace_64.jpg\n",
            "/content/compproject/images/train/palm_10.jpg\n",
            "/content/compproject/images/train/peace_26.jpg\n",
            "/content/compproject/images/train/ok_37.jpg\n",
            "/content/compproject/images/train/palm_71.jpg\n",
            "/content/compproject/images/train/peace_1.jpg\n",
            "/content/compproject/images/train/peace_33.jpg\n",
            "/content/compproject/images/train/ok_40.jpg\n",
            "/content/compproject/images/train/peace_85.jpg\n",
            "/content/compproject/images/train/palm_61.jpg\n",
            "/content/compproject/images/train/palm_22.jpg\n",
            "/content/compproject/images/train/palm_92.jpg\n",
            "/content/compproject/images/train/palm_54.jpg\n",
            "/content/compproject/images/train/palm_19.jpg\n",
            "/content/compproject/images/train/palm_52.jpg\n",
            "/content/compproject/images/train/ok_8.jpg\n",
            "/content/compproject/images/train/ok_34.jpg\n",
            "/content/compproject/images/train/palm_23.jpg\n",
            "/content/compproject/images/train/palm_3.jpg\n",
            "/content/compproject/images/train/palm_89.jpg\n",
            "/content/compproject/images/train/peace_8.jpg\n",
            "/content/compproject/images/train/peace_60.jpg\n",
            "/content/compproject/images/train/palm_29.jpg\n",
            "/content/compproject/images/train/palm_30.jpg\n",
            "/content/compproject/images/train/ok_18.jpg\n",
            "/content/compproject/images/train/palm_97.jpg\n",
            "/content/compproject/images/train/peace_18.jpg\n",
            "/content/compproject/images/train/peace_72.jpg\n",
            "/content/compproject/images/train/peace_89.jpg\n",
            "/content/compproject/images/train/ok_62.jpg\n",
            "/content/compproject/images/train/palm_14.jpg\n",
            "/content/compproject/images/train/peace_21.jpg\n",
            "/content/compproject/images/train/peace_5.jpg\n",
            "/content/compproject/images/train/ok_82.jpg\n",
            "/content/compproject/images/train/palm_45.jpg\n",
            "/content/compproject/images/train/peace_53.jpg\n",
            "/content/compproject/images/train/ok_58.jpg\n",
            "/content/compproject/images/train/palm_84.jpg\n",
            "/content/compproject/images/train/palm_37.jpg\n",
            "/content/compproject/images/train/ok_70.jpg\n",
            "/content/compproject/images/train/peace_69.jpg\n",
            "/content/compproject/images/train/ok_42.jpg\n",
            "/content/compproject/images/train/peace_38.jpg\n",
            "/content/compproject/images/train/palm_5.jpg\n",
            "/content/compproject/images/train/palm_60.jpg\n",
            "/content/compproject/images/train/peace_19.jpg\n",
            "/content/compproject/images/train/palm_62.jpg\n",
            "/content/compproject/images/train/palm_39.jpg\n",
            "/content/compproject/images/train/ok_39.jpg\n",
            "/content/compproject/images/train/peace_11.jpg\n",
            "/content/compproject/images/train/palm_13.jpg\n",
            "/content/compproject/images/train/ok_10.jpg\n",
            "/content/compproject/images/train/peace_65.jpg\n",
            "/content/compproject/images/train/peace_82.jpg\n",
            "/content/compproject/images/train/ok_32.jpg\n",
            "/content/compproject/images/train/palm_68.jpg\n",
            "/content/compproject/images/train/peace_30.jpg\n",
            "/content/compproject/images/train/palm_78.jpg\n",
            "/content/compproject/images/train/palm_26.jpg\n",
            "/content/compproject/images/train/peace_57.jpg\n",
            "/content/compproject/images/train/palm_8.jpg\n",
            "/content/compproject/images/train/peace_23.jpg\n",
            "/content/compproject/images/train/ok_96.jpg\n",
            "/content/compproject/images/train/peace_56.jpg\n",
            "/content/compproject/images/train/peace_16.jpg\n",
            "/content/compproject/images/train/ok_78.jpg\n",
            "/content/compproject/images/train/palm_65.jpg\n",
            "/content/compproject/images/train/palm_83.jpg\n",
            "/content/compproject/images/train/peace_43.jpg\n",
            "/content/compproject/images/train/ok_68.jpg\n",
            "/content/compproject/images/train/palm_33.jpg\n",
            "/content/compproject/images/train/ok_30.jpg\n",
            "/content/compproject/images/train/ok_64.jpg\n",
            "/content/compproject/images/train/palm_25.jpg\n",
            "/content/compproject/images/train/peace_41.jpg\n",
            "/content/compproject/images/train/palm_44.jpg\n",
            "/content/compproject/images/train/palm_58.jpg\n",
            "/content/compproject/images/train/ok_43.jpg\n",
            "/content/compproject/images/train/ok_57.jpg\n",
            "/content/compproject/images/train/ok_72.jpg\n",
            "/content/compproject/images/train/ok_24.jpg\n",
            "/content/compproject/images/train/peace_13.jpg\n",
            "/content/compproject/images/train/ok_3.jpg\n",
            "/content/compproject/images/train/ok_56.jpg\n",
            "/content/compproject/images/train/peace_52.jpg\n",
            "/content/compproject/images/train/peace_36.jpg\n",
            "/content/compproject/images/train/peace_7.jpg\n",
            "/content/compproject/images/train/peace_2.jpg\n",
            "/content/compproject/images/train/peace_39.jpg\n",
            "/content/compproject/images/train/ok_95.jpg\n",
            "/content/compproject/images/train/palm_2.jpg\n",
            "/content/compproject/images/train/peace_42.jpg\n",
            "/content/compproject/images/train/palm_1.jpg\n",
            "/content/compproject/images/train/peace_67.jpg\n",
            "/content/compproject/images/train/peace_25.jpg\n",
            "/content/compproject/images/train/peace_62.jpg\n",
            "/content/compproject/images/train/peace_80.jpg\n",
            "/content/compproject/images/train/ok_27.jpg\n",
            "/content/compproject/images/train/peace_37.jpg\n",
            "/content/compproject/images/train/ok_21.jpg\n",
            "/content/compproject/images/train/ok_94.jpg\n",
            "/content/compproject/images/train/ok_19.jpg\n",
            "/content/compproject/images/train/peace_77.jpg\n",
            "/content/compproject/images/train/ok_71.jpg\n",
            "/content/compproject/images/train/palm_64.jpg\n",
            "/content/compproject/images/train/peace_97.jpg\n",
            "/content/compproject/images/train/ok_36.jpg\n",
            "/content/compproject/images/train/palm_40.jpg\n",
            "/content/compproject/images/train/ok_38.jpg\n",
            "/content/compproject/images/train/peace_15.jpg\n",
            "/content/compproject/images/train/peace_79.jpg\n",
            "/content/compproject/images/train/peace_4.jpg\n",
            "/content/compproject/images/train/ok_44.jpg\n",
            "/content/compproject/images/train/ok_66.jpg\n",
            "/content/compproject/images/train/ok_5.jpg\n",
            "/content/compproject/images/train/palm_21.jpg\n",
            "/content/compproject/images/train/peace_71.jpg\n",
            "/content/compproject/images/train/peace_94.jpg\n",
            "/content/compproject/images/train/ok_2.jpg\n",
            "/content/compproject/images/train/peace_44.jpg\n",
            "/content/compproject/images/train/palm_69.jpg\n",
            "/content/compproject/images/train/palm_41.jpg\n",
            "/content/compproject/images/train/peace_22.jpg\n",
            "/content/compproject/images/train/palm_81.jpg\n",
            "/content/compproject/images/train/ok_86.jpg\n",
            "/content/compproject/images/train/palm_27.jpg\n",
            "/content/compproject/images/train/ok_22.jpg\n",
            "/content/compproject/images/train/ok_52.jpg\n",
            "/content/compproject/images/train/ok_83.jpg\n",
            "/content/compproject/images/train/palm_90.jpg\n",
            "/content/compproject/images/train/ok_53.jpg\n",
            "/content/compproject/images/train/peace_61.jpg\n",
            "/content/compproject/images/train/ok_4.jpg\n",
            "/content/compproject/images/train/palm_80.jpg\n",
            "/content/compproject/images/train/palm_32.jpg\n",
            "/content/compproject/images/train/ok_13.jpg\n",
            "/content/compproject/images/train/ok_84.jpg\n",
            "/content/compproject/images/train/ok_67.jpg\n",
            "/content/compproject/images/train/palm_85.jpg\n",
            "/content/compproject/images/train/ok_55.jpg\n",
            "End\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy73Z6eu3RDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/compproject/images/converted_annotation_in_txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuTKWqxCWKs1",
        "colab_type": "code",
        "outputId": "9cdd67a5-d550-40fb-c770-10cc0b295207",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "datapath = \"/content/compproject/images/bb_box.txt\"\n",
        "savepath = \"/content/compproject/images/converted_annotation_in_txt/\"\n",
        "filepath = \"/content/compproject/images/file_name.txt\"\n",
        "\n",
        "def make_dataset(input_path):\n",
        "    all_imgs = {}\n",
        "    print(\"the input path is\", input_path)\n",
        "    with open(input_path,'r') as f:\n",
        "        print('Parsing annotation files')\n",
        "        for line in f:\n",
        "            line_split = line.strip().split(',')\n",
        "            (filename,x1,y1,x2,y2,class_name) = line_split\n",
        "            if filename not in all_imgs:\n",
        "                all_imgs[filename] = {}\n",
        "                \n",
        "                all_imgs[filename]['filepath'] = filename\n",
        "                all_imgs[filename]['bboxes'] = []\n",
        "                \n",
        "            all_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "            \n",
        "        all_data = []\n",
        "        \n",
        "        for key in all_imgs:\n",
        "            all_data.append(all_imgs[key])\n",
        "            \n",
        "        return all_data\n",
        "            \n",
        "dataset = make_dataset(datapath)\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    dataset_path = dataset[i]['filepath']\n",
        "    dataset_name = dataset_path.split(',')[0]\n",
        "    sep_dataset = dataset[i]['bboxes']\n",
        "    \n",
        "    with open(filepath, 'a') as fn:\n",
        "        file_name = \"{}\\n\".format(dataset_name)\n",
        "        fn.write(file_name)\n",
        "        \n",
        "    with open(savepath + str(dataset_name)+ \".txt\", 'w') as f:\n",
        "        for j in range(len(sep_dataset)):\n",
        "            save_dataset = sep_dataset[j]\n",
        "            \n",
        "            data = \"{} {} {} {} {} \\n\".format(sep_dataset[j]['class'],sep_dataset[j]['x1'],sep_dataset[j]['y1'], sep_dataset[j]['x2'], sep_dataset[j]['y2'])\n",
        "            \n",
        "            f.write(data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the input path is /content/compproject/images/bb_box.txt\n",
            "Parsing annotation files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWnyVXpJWzlW",
        "colab_type": "code",
        "outputId": "77c035ab-a7f8-4246-b194-3deab2965c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import xml.etree.cElementTree as ET\n",
        "from PIL import Image\n",
        "\n",
        "ANNOTATIONS_DIR_PREFIX = \"/content/compproject/images/converted_annotation_in_txt\"\n",
        "\n",
        "DESTINATION_DIR = \"/content/compproject/images/train\"\n",
        "\n",
        "def create_root(file_prefix, width, height):\n",
        "    root = ET.Element(\"annotations\")\n",
        "    ET.SubElement(root, \"filename\").text = \"{}.jpg\".format(file_prefix)\n",
        "    ET.SubElement(root, \"folder\").text = \"images\"\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size, \"width\").text = str(width)\n",
        "    ET.SubElement(size, \"height\").text = str(height)\n",
        "    ET.SubElement(size, \"depth\").text = \"3\"\n",
        "    return root\n",
        "\n",
        "def create_object_annotation(root, voc_labels):\n",
        "    for voc_label in voc_labels:\n",
        "        obj = ET.SubElement(root, \"object\")\n",
        "        ET.SubElement(obj, \"name\").text = voc_label[0]\n",
        "        ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
        "        ET.SubElement(obj, \"truncated\").text = str(0)\n",
        "        ET.SubElement(obj, \"difficult\").text = str(0)\n",
        "        bbox = ET.SubElement(obj, \"bndbox\")\n",
        "        ET.SubElement(bbox, \"xmin\").text = str(voc_label[1])\n",
        "        ET.SubElement(bbox, \"ymin\").text = str(voc_label[2])\n",
        "        ET.SubElement(bbox, \"xmax\").text = str(voc_label[3])\n",
        "        ET.SubElement(bbox, \"ymax\").text = str(voc_label[4])\n",
        "    return root\n",
        "\n",
        "def create_file(file_prefix, width, height, voc_labels):\n",
        "    root = create_root(file_prefix, width, height)\n",
        "    root = create_object_annotation(root, voc_labels)\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(\"/content/compproject/images/train/{}.xml\".format(file_prefix))\n",
        "\n",
        "def read_file(file_path):\n",
        "    file_prefix = file_path.split(\".jpg\")[0]\n",
        "    file_path_data = \"/content/compproject/images/converted_annotation_in_txt/\" + file_path\n",
        "    print(\"the file path data\", file_path_data)\n",
        "    image_file_name = \"{}.jpg\".format(file_prefix)\n",
        "    img = Image.open(\"{}/{}\".format(\"/content/compproject/images/train\", image_file_name))\n",
        "    w, h = img.size\n",
        "    with open(file_path_data, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        voc_labels = []\n",
        "        for line in lines:\n",
        "            voc = []\n",
        "            line = line.strip()\n",
        "            data = line.split()\n",
        "            print(data[0],data[1],data[2],data[3],data[4])\n",
        "            voc.append(data[0])\n",
        "            voc.append(data[1])\n",
        "            voc.append(data[2])\n",
        "            voc.append(data[3])\n",
        "            voc.append(data[4])\n",
        "            voc_labels.append(voc)\n",
        "            print(voc_labels)\n",
        "        create_file(file_prefix, w, h, voc_labels)\n",
        "    print(\"Processing complete for file: {}\".format(file_path))\n",
        "\n",
        "def start():\n",
        "    if not os.path.exists(DESTINATION_DIR):\n",
        "        os.makedirs(DESTINATION_DIR)\n",
        "    for filename in os.listdir(ANNOTATIONS_DIR_PREFIX):\n",
        "        print(filename)\n",
        "        if filename.endswith('txt'):\n",
        "            read_file(filename)\n",
        "        else:\n",
        "            print(\"Skipping file: {}\".format(filename))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "peace_54-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0.jpg.txt\n",
            "peacesign 472 43 778 667\n",
            "[['peacesign', '472', '43', '778', '667']]\n",
            "Processing complete for file: peace_54-color0.jpg.txt\n",
            "peace_23-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0.jpg.txt\n",
            "peacesign 299 40 767 799\n",
            "[['peacesign', '299', '40', '767', '799']]\n",
            "Processing complete for file: peace_23-color0.jpg.txt\n",
            "palm_42-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0-rotate_270.jpg.txt\n",
            "palmhand 166 151 303 388\n",
            "[['palmhand', '166', '151', '303', '388']]\n",
            "Processing complete for file: palm_42-color0-rotate_270.jpg.txt\n",
            "ok_80-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0-f1.jpg.txt\n",
            "oksign 165 156 438 589\n",
            "[['oksign', '165', '156', '438', '589']]\n",
            "Processing complete for file: ok_80-color0-f1.jpg.txt\n",
            "peace_3-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0-rotate_270.jpg.txt\n",
            "peacesign 26 84 583 400\n",
            "[['peacesign', '26', '84', '583', '400']]\n",
            "Processing complete for file: peace_3-color0-rotate_270.jpg.txt\n",
            "palm_1-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0-f1.jpg.txt\n",
            "palmhand 86 58 397 622\n",
            "[['palmhand', '86', '58', '397', '622']]\n",
            "Processing complete for file: palm_1-color0-f1.jpg.txt\n",
            "ok_62-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0-f0.jpg.txt\n",
            "oksign 182 239 409 468\n",
            "[['oksign', '182', '239', '409', '468']]\n",
            "Processing complete for file: ok_62-color0-f0.jpg.txt\n",
            "ok_61-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0-f1.jpg.txt\n",
            "oksign 402 23 657 398\n",
            "[['oksign', '402', '23', '657', '398']]\n",
            "Processing complete for file: ok_61-color0-f1.jpg.txt\n",
            "ok_60-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0-f1.jpg.txt\n",
            "oksign 421 85 704 523\n",
            "[['oksign', '421', '85', '704', '523']]\n",
            "Processing complete for file: ok_60-color0-f1.jpg.txt\n",
            "ok_42-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0-rotate_180.jpg.txt\n",
            "oksign 246 249 525 671\n",
            "[['oksign', '246', '249', '525', '671']]\n",
            "Processing complete for file: ok_42-color0-rotate_180.jpg.txt\n",
            "ok_56-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0-f0.jpg.txt\n",
            "oksign 230 247 490 620\n",
            "[['oksign', '230', '247', '490', '620']]\n",
            "Processing complete for file: ok_56-color0-f0.jpg.txt\n",
            "peace_72-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0-rotate_180.jpg.txt\n",
            "peacesign 521 181 852 616\n",
            "[['peacesign', '521', '181', '852', '616']]\n",
            "Processing complete for file: peace_72-color0-rotate_180.jpg.txt\n",
            "palm_4-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0-f0.jpg.txt\n",
            "palmhand 58 8 371 579\n",
            "[['palmhand', '58', '8', '371', '579']]\n",
            "Processing complete for file: palm_4-color0-f0.jpg.txt\n",
            "ok_88-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0-rotate_270.jpg.txt\n",
            "oksign 306 496 531 711\n",
            "[['oksign', '306', '496', '531', '711']]\n",
            "Processing complete for file: ok_88-color0-rotate_270.jpg.txt\n",
            "peace_88-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0-rotate_270.jpg.txt\n",
            "peacesign 161 179 650 462\n",
            "[['peacesign', '161', '179', '650', '462']]\n",
            "Processing complete for file: peace_88-color0-rotate_270.jpg.txt\n",
            "palm_43-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0-rotate_270.jpg.txt\n",
            "palmhand 113 63 351 412\n",
            "[['palmhand', '113', '63', '351', '412']]\n",
            "Processing complete for file: palm_43-color0-rotate_270.jpg.txt\n",
            "peace_61-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0-f0.jpg.txt\n",
            "peacesign 621 313 890 648\n",
            "[['peacesign', '621', '313', '890', '648']]\n",
            "Processing complete for file: peace_61-color0-f0.jpg.txt\n",
            "ok_92-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0-f0.jpg.txt\n",
            "oksign 521 287 744 578\n",
            "[['oksign', '521', '287', '744', '578']]\n",
            "Processing complete for file: ok_92-color0-f0.jpg.txt\n",
            "palm_86-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0.jpg.txt\n",
            "palmhand 361 100 680 419\n",
            "[['palmhand', '361', '100', '680', '419']]\n",
            "Processing complete for file: palm_86-color0.jpg.txt\n",
            "ok_94-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0-f0.jpg.txt\n",
            "oksign 588 168 890 649\n",
            "[['oksign', '588', '168', '890', '649']]\n",
            "Processing complete for file: ok_94-color0-f0.jpg.txt\n",
            "palm_87-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0-f0.jpg.txt\n",
            "palmhand 517 299 742 670\n",
            "[['palmhand', '517', '299', '742', '670']]\n",
            "Processing complete for file: palm_87-color0-f0.jpg.txt\n",
            "peace_84-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0-rotate_90.jpg.txt\n",
            "peacesign 159 434 628 738\n",
            "[['peacesign', '159', '434', '628', '738']]\n",
            "Processing complete for file: peace_84-color0-rotate_90.jpg.txt\n",
            "palm_2-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0-rotate_90.jpg.txt\n",
            "palmhand 0 97 642 454\n",
            "[['palmhand', '0', '97', '642', '454']]\n",
            "Processing complete for file: palm_2-color0-rotate_90.jpg.txt\n",
            "ok_87-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0-rotate_90.jpg.txt\n",
            "oksign 201 426 441 640\n",
            "[['oksign', '201', '426', '441', '640']]\n",
            "Processing complete for file: ok_87-color0-rotate_90.jpg.txt\n",
            "peace_15-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0-rotate_90.jpg.txt\n",
            "peacesign 8 316 548 609\n",
            "[['peacesign', '8', '316', '548', '609']]\n",
            "Processing complete for file: peace_15-color0-rotate_90.jpg.txt\n",
            "peace_12-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0-rotate_180.jpg.txt\n",
            "peacesign 73 10 323 432\n",
            "[['peacesign', '73', '10', '323', '432']]\n",
            "Processing complete for file: peace_12-color0-rotate_180.jpg.txt\n",
            "palm_13-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0.jpg.txt\n",
            "palmhand 695 156 998 687\n",
            "[['palmhand', '695', '156', '998', '687']]\n",
            "palmhand 355 201 689 753\n",
            "[['palmhand', '695', '156', '998', '687'], ['palmhand', '355', '201', '689', '753']]\n",
            "Processing complete for file: palm_13-color0.jpg.txt\n",
            "ok_30-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0.jpg.txt\n",
            "oksign 125 247 606 893\n",
            "[['oksign', '125', '247', '606', '893']]\n",
            "Processing complete for file: ok_30-color0.jpg.txt\n",
            "peace_62-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0-f1.jpg.txt\n",
            "peacesign 279 263 464 607\n",
            "[['peacesign', '279', '263', '464', '607']]\n",
            "Processing complete for file: peace_62-color0-f1.jpg.txt\n",
            "peace_83-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0.jpg.txt\n",
            "peacesign 423 187 665 545\n",
            "[['peacesign', '423', '187', '665', '545']]\n",
            "Processing complete for file: peace_83-color0.jpg.txt\n",
            "palm_4-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0-f1.jpg.txt\n",
            "palmhand 122 12 435 583\n",
            "[['palmhand', '122', '12', '435', '583']]\n",
            "Processing complete for file: palm_4-color0-f1.jpg.txt\n",
            "palm_38-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0-rotate_270.jpg.txt\n",
            "palmhand 27 43 444 326\n",
            "[['palmhand', '27', '43', '444', '326']]\n",
            "Processing complete for file: palm_38-color0-rotate_270.jpg.txt\n",
            "palm_68-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0-f0.jpg.txt\n",
            "palmhand 253 308 486 639\n",
            "[['palmhand', '253', '308', '486', '639']]\n",
            "Processing complete for file: palm_68-color0-f0.jpg.txt\n",
            "peace_70-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0-rotate_270.jpg.txt\n",
            "peacesign 76 526 516 793\n",
            "[['peacesign', '76', '526', '516', '793']]\n",
            "Processing complete for file: peace_70-color0-rotate_270.jpg.txt\n",
            "ok_69-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0-f0.jpg.txt\n",
            "oksign 76 278 371 553\n",
            "[['oksign', '76', '278', '371', '553']]\n",
            "Processing complete for file: ok_69-color0-f0.jpg.txt\n",
            "ok_9-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0.jpg.txt\n",
            "oksign 741 442 875 600\n",
            "[['oksign', '741', '442', '875', '600']]\n",
            "Processing complete for file: ok_9-color0.jpg.txt\n",
            "peace_66-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0-f1.jpg.txt\n",
            "peacesign 384 107 615 572\n",
            "[['peacesign', '384', '107', '615', '572']]\n",
            "Processing complete for file: peace_66-color0-f1.jpg.txt\n",
            "peace_59-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0-rotate_180.jpg.txt\n",
            "peacesign 93 162 644 495\n",
            "[['peacesign', '93', '162', '644', '495']]\n",
            "Processing complete for file: peace_59-color0-rotate_180.jpg.txt\n",
            "ok_27-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0-f1.jpg.txt\n",
            "oksign 142 94 340 392\n",
            "[['oksign', '142', '94', '340', '392']]\n",
            "Processing complete for file: ok_27-color0-f1.jpg.txt\n",
            "palm_28-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0-f0.jpg.txt\n",
            "palmhand 49 43 589 286\n",
            "[['palmhand', '49', '43', '589', '286']]\n",
            "Processing complete for file: palm_28-color0-f0.jpg.txt\n",
            "ok_71-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0.jpg.txt\n",
            "oksign 321 50 555 402\n",
            "[['oksign', '321', '50', '555', '402']]\n",
            "Processing complete for file: ok_71-color0.jpg.txt\n",
            "peace_43-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0-rotate_90.jpg.txt\n",
            "peacesign 105 155 920 594\n",
            "[['peacesign', '105', '155', '920', '594']]\n",
            "Processing complete for file: peace_43-color0-rotate_90.jpg.txt\n",
            "palm_90-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0-f0.jpg.txt\n",
            "palmhand 544 295 830 606\n",
            "[['palmhand', '544', '295', '830', '606']]\n",
            "Processing complete for file: palm_90-color0-f0.jpg.txt\n",
            "ok_85-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0-rotate_90.jpg.txt\n",
            "oksign 237 665 489 857\n",
            "[['oksign', '237', '665', '489', '857']]\n",
            "Processing complete for file: ok_85-color0-rotate_90.jpg.txt\n",
            "ok_57-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0-f0.jpg.txt\n",
            "oksign 290 241 551 612\n",
            "[['oksign', '290', '241', '551', '612']]\n",
            "Processing complete for file: ok_57-color0-f0.jpg.txt\n",
            "peace_57-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0-f0.jpg.txt\n",
            "peacesign 156 162 647 497\n",
            "[['peacesign', '156', '162', '647', '497']]\n",
            "Processing complete for file: peace_57-color0-f0.jpg.txt\n",
            "palm_82-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0-rotate_270.jpg.txt\n",
            "palmhand 48 327 544 636\n",
            "[['palmhand', '48', '327', '544', '636']]\n",
            "Processing complete for file: palm_82-color0-rotate_270.jpg.txt\n",
            "palm_72-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0-f1.jpg.txt\n",
            "palmhand 567 196 815 471\n",
            "[['palmhand', '567', '196', '815', '471']]\n",
            "Processing complete for file: palm_72-color0-f1.jpg.txt\n",
            "ok_28-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0.jpg.txt\n",
            "oksign 152 66 244 164\n",
            "[['oksign', '152', '66', '244', '164']]\n",
            "oksign 386 57 478 157\n",
            "[['oksign', '152', '66', '244', '164'], ['oksign', '386', '57', '478', '157']]\n",
            "Processing complete for file: ok_28-color0.jpg.txt\n",
            "peace_53-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0.jpg.txt\n",
            "peacesign 325 96 756 703\n",
            "[['peacesign', '325', '96', '756', '703']]\n",
            "Processing complete for file: peace_53-color0.jpg.txt\n",
            "peace_9-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0-rotate_180.jpg.txt\n",
            "peacesign 78 32 396 613\n",
            "[['peacesign', '78', '32', '396', '613']]\n",
            "Processing complete for file: peace_9-color0-rotate_180.jpg.txt\n",
            "peace_43-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0-f1.jpg.txt\n",
            "peacesign 134 51 573 866\n",
            "[['peacesign', '134', '51', '573', '866']]\n",
            "Processing complete for file: peace_43-color0-f1.jpg.txt\n",
            "ok_61-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0-rotate_270.jpg.txt\n",
            "oksign 23 402 398 657\n",
            "[['oksign', '23', '402', '398', '657']]\n",
            "Processing complete for file: ok_61-color0-rotate_270.jpg.txt\n",
            "peace_10-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0-rotate_270.jpg.txt\n",
            "peacesign 9 85 622 414\n",
            "[['peacesign', '9', '85', '622', '414']]\n",
            "Processing complete for file: peace_10-color0-rotate_270.jpg.txt\n",
            "peace_12-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0-rotate_270.jpg.txt\n",
            "peacesign 17 73 439 323\n",
            "[['peacesign', '17', '73', '439', '323']]\n",
            "Processing complete for file: peace_12-color0-rotate_270.jpg.txt\n",
            "ok_95-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0-rotate_90.jpg.txt\n",
            "oksign 320 617 545 905\n",
            "[['oksign', '320', '617', '545', '905']]\n",
            "Processing complete for file: ok_95-color0-rotate_90.jpg.txt\n",
            "palm_13-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0-rotate_90.jpg.txt\n",
            "palmhand 166 695 697 998\n",
            "[['palmhand', '166', '695', '697', '998']]\n",
            "palmhand 100 355 652 689\n",
            "[['palmhand', '166', '695', '697', '998'], ['palmhand', '100', '355', '652', '689']]\n",
            "Processing complete for file: palm_13-color0-rotate_90.jpg.txt\n",
            "palm_45-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0-f1.jpg.txt\n",
            "palmhand 114 84 502 439\n",
            "[['palmhand', '114', '84', '502', '439']]\n",
            "Processing complete for file: palm_45-color0-f1.jpg.txt\n",
            "palm_53-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0-rotate_180.jpg.txt\n",
            "palmhand 244 89 582 628\n",
            "[['palmhand', '244', '89', '582', '628']]\n",
            "Processing complete for file: palm_53-color0-rotate_180.jpg.txt\n",
            "peace_91-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0-rotate_270.jpg.txt\n",
            "peacesign 185 579 605 968\n",
            "[['peacesign', '185', '579', '605', '968']]\n",
            "Processing complete for file: peace_91-color0-rotate_270.jpg.txt\n",
            "ok_76-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0-f1.jpg.txt\n",
            "oksign 252 114 490 514\n",
            "[['oksign', '252', '114', '490', '514']]\n",
            "Processing complete for file: ok_76-color0-f1.jpg.txt\n",
            "palm_16-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0-f0.jpg.txt\n",
            "palmhand 305 162 574 477\n",
            "[['palmhand', '305', '162', '574', '477']]\n",
            "palmhand 78 140 297 479\n",
            "[['palmhand', '305', '162', '574', '477'], ['palmhand', '78', '140', '297', '479']]\n",
            "Processing complete for file: palm_16-color0-f0.jpg.txt\n",
            "peace_63-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0-f0.jpg.txt\n",
            "peacesign 356 217 587 564\n",
            "[['peacesign', '356', '217', '587', '564']]\n",
            "Processing complete for file: peace_63-color0-f0.jpg.txt\n",
            "ok_95-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0-f1.jpg.txt\n",
            "oksign 175 175 463 400\n",
            "[['oksign', '175', '175', '463', '400']]\n",
            "Processing complete for file: ok_95-color0-f1.jpg.txt\n",
            "ok_77-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0-rotate_270.jpg.txt\n",
            "oksign 117 357 537 632\n",
            "[['oksign', '117', '357', '537', '632']]\n",
            "Processing complete for file: ok_77-color0-rotate_270.jpg.txt\n",
            "ok_6-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0-f1.jpg.txt\n",
            "oksign 245 138 705 715\n",
            "[['oksign', '245', '138', '705', '715']]\n",
            "Processing complete for file: ok_6-color0-f1.jpg.txt\n",
            "ok_5-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0-f1.jpg.txt\n",
            "oksign 569 209 803 493\n",
            "[['oksign', '569', '209', '803', '493']]\n",
            "Processing complete for file: ok_5-color0-f1.jpg.txt\n",
            "ok_37-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0-f1.jpg.txt\n",
            "oksign 197 115 421 437\n",
            "[['oksign', '197', '115', '421', '437']]\n",
            "Processing complete for file: ok_37-color0-f1.jpg.txt\n",
            "peace_35-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0-rotate_90.jpg.txt\n",
            "peacesign 309 463 519 575\n",
            "[['peacesign', '309', '463', '519', '575']]\n",
            "Processing complete for file: peace_35-color0-rotate_90.jpg.txt\n",
            "ok_15-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0-rotate_180.jpg.txt\n",
            "oksign 129 77 392 469\n",
            "[['oksign', '129', '77', '392', '469']]\n",
            "Processing complete for file: ok_15-color0-rotate_180.jpg.txt\n",
            "peace_56-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0.jpg.txt\n",
            "peacesign 310 178 567 618\n",
            "[['peacesign', '310', '178', '567', '618']]\n",
            "Processing complete for file: peace_56-color0.jpg.txt\n",
            "ok_81-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0.jpg.txt\n",
            "oksign 484 219 751 614\n",
            "[['oksign', '484', '219', '751', '614']]\n",
            "Processing complete for file: ok_81-color0.jpg.txt\n",
            "palm_60-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0-rotate_270.jpg.txt\n",
            "palmhand 337 117 606 540\n",
            "[['palmhand', '337', '117', '606', '540']]\n",
            "Processing complete for file: palm_60-color0-rotate_270.jpg.txt\n",
            "peace_33-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0-f1.jpg.txt\n",
            "peacesign 588 94 664 216\n",
            "[['peacesign', '588', '94', '664', '216']]\n",
            "peacesign 326 50 393 174\n",
            "[['peacesign', '588', '94', '664', '216'], ['peacesign', '326', '50', '393', '174']]\n",
            "Processing complete for file: peace_33-color0-f1.jpg.txt\n",
            "peace_7-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0-rotate_270.jpg.txt\n",
            "peacesign 1 61 571 380\n",
            "[['peacesign', '1', '61', '571', '380']]\n",
            "Processing complete for file: peace_7-color0-rotate_270.jpg.txt\n",
            "palm_34-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0-f1.jpg.txt\n",
            "palmhand 73 10 280 407\n",
            "[['palmhand', '73', '10', '280', '407']]\n",
            "Processing complete for file: palm_34-color0-f1.jpg.txt\n",
            "palm_69-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0-rotate_270.jpg.txt\n",
            "palmhand 92 373 410 696\n",
            "[['palmhand', '92', '373', '410', '696']]\n",
            "Processing complete for file: palm_69-color0-rotate_270.jpg.txt\n",
            "ok_57-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0-f1.jpg.txt\n",
            "oksign 529 108 790 479\n",
            "[['oksign', '529', '108', '790', '479']]\n",
            "Processing complete for file: ok_57-color0-f1.jpg.txt\n",
            "peace_32-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0-rotate_180.jpg.txt\n",
            "peacesign 261 96 413 368\n",
            "[['peacesign', '261', '96', '413', '368']]\n",
            "Processing complete for file: peace_32-color0-rotate_180.jpg.txt\n",
            "peace_43-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0.jpg.txt\n",
            "peacesign 155 51 594 866\n",
            "[['peacesign', '155', '51', '594', '866']]\n",
            "Processing complete for file: peace_43-color0.jpg.txt\n",
            "ok_79-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0-f1.jpg.txt\n",
            "oksign 534 158 809 531\n",
            "[['oksign', '534', '158', '809', '531']]\n",
            "Processing complete for file: ok_79-color0-f1.jpg.txt\n",
            "ok_60-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0.jpg.txt\n",
            "oksign 376 85 659 523\n",
            "[['oksign', '376', '85', '659', '523']]\n",
            "Processing complete for file: ok_60-color0.jpg.txt\n",
            "ok_63-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0-rotate_90.jpg.txt\n",
            "oksign 264 396 531 621\n",
            "[['oksign', '264', '396', '531', '621']]\n",
            "Processing complete for file: ok_63-color0-rotate_90.jpg.txt\n",
            "palm_2-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0.jpg.txt\n",
            "palmhand 97 27 454 669\n",
            "[['palmhand', '97', '27', '454', '669']]\n",
            "Processing complete for file: palm_2-color0.jpg.txt\n",
            "peace_34-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0.jpg.txt\n",
            "peacesign 581 131 762 407\n",
            "[['peacesign', '581', '131', '762', '407']]\n",
            "Processing complete for file: peace_34-color0.jpg.txt\n",
            "palm_72-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0-rotate_90.jpg.txt\n",
            "palmhand 249 265 524 513\n",
            "[['palmhand', '249', '265', '524', '513']]\n",
            "Processing complete for file: palm_72-color0-rotate_90.jpg.txt\n",
            "palm_53-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0-rotate_90.jpg.txt\n",
            "palmhand 89 498 628 836\n",
            "[['palmhand', '89', '498', '628', '836']]\n",
            "Processing complete for file: palm_53-color0-rotate_90.jpg.txt\n",
            "peace_56-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0-rotate_270.jpg.txt\n",
            "peacesign 178 513 618 770\n",
            "[['peacesign', '178', '513', '618', '770']]\n",
            "Processing complete for file: peace_56-color0-rotate_270.jpg.txt\n",
            "peace_65-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0.jpg.txt\n",
            "peacesign 421 203 828 603\n",
            "[['peacesign', '421', '203', '828', '603']]\n",
            "Processing complete for file: peace_65-color0.jpg.txt\n",
            "palm_87-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0-rotate_270.jpg.txt\n",
            "palmhand 50 338 421 563\n",
            "[['palmhand', '50', '338', '421', '563']]\n",
            "Processing complete for file: palm_87-color0-rotate_270.jpg.txt\n",
            "peace_30-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0-f0.jpg.txt\n",
            "peacesign 24 301 115 454\n",
            "[['peacesign', '24', '301', '115', '454']]\n",
            "Processing complete for file: peace_30-color0-f0.jpg.txt\n",
            "ok_19-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0.jpg.txt\n",
            "oksign 27 19 556 602\n",
            "[['oksign', '27', '19', '556', '602']]\n",
            "Processing complete for file: ok_19-color0.jpg.txt\n",
            "peace_12-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0-rotate_90.jpg.txt\n",
            "peacesign 10 28 432 278\n",
            "[['peacesign', '10', '28', '432', '278']]\n",
            "Processing complete for file: peace_12-color0-rotate_90.jpg.txt\n",
            "ok_14-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0-rotate_90.jpg.txt\n",
            "oksign 25 172 425 491\n",
            "[['oksign', '25', '172', '425', '491']]\n",
            "Processing complete for file: ok_14-color0-rotate_90.jpg.txt\n",
            "ok_27-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0-rotate_270.jpg.txt\n",
            "oksign 94 142 392 340\n",
            "[['oksign', '94', '142', '392', '340']]\n",
            "Processing complete for file: ok_27-color0-rotate_270.jpg.txt\n",
            "peace_28-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0-rotate_270.jpg.txt\n",
            "peacesign 53 141 188 226\n",
            "[['peacesign', '53', '141', '188', '226']]\n",
            "Processing complete for file: peace_28-color0-rotate_270.jpg.txt\n",
            "peace_36-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0-rotate_270.jpg.txt\n",
            "peacesign 113 376 482 584\n",
            "[['peacesign', '113', '376', '482', '584']]\n",
            "Processing complete for file: peace_36-color0-rotate_270.jpg.txt\n",
            "peace_79-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0-rotate_180.jpg.txt\n",
            "peacesign 142 157 535 597\n",
            "[['peacesign', '142', '157', '535', '597']]\n",
            "Processing complete for file: peace_79-color0-rotate_180.jpg.txt\n",
            "palm_68-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0-rotate_180.jpg.txt\n",
            "palmhand 594 308 827 639\n",
            "[['palmhand', '594', '308', '827', '639']]\n",
            "Processing complete for file: palm_68-color0-rotate_180.jpg.txt\n",
            "ok_81-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0-f1.jpg.txt\n",
            "oksign 329 219 596 614\n",
            "[['oksign', '329', '219', '596', '614']]\n",
            "Processing complete for file: ok_81-color0-f1.jpg.txt\n",
            "peace_39-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0-rotate_90.jpg.txt\n",
            "peacesign 21 60 357 268\n",
            "[['peacesign', '21', '60', '357', '268']]\n",
            "Processing complete for file: peace_39-color0-rotate_90.jpg.txt\n",
            "palm_56-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0-rotate_180.jpg.txt\n",
            "palmhand 313 199 582 612\n",
            "[['palmhand', '313', '199', '582', '612']]\n",
            "Processing complete for file: palm_56-color0-rotate_180.jpg.txt\n",
            "palm_65-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0-rotate_90.jpg.txt\n",
            "palmhand 187 244 668 648\n",
            "[['palmhand', '187', '244', '668', '648']]\n",
            "Processing complete for file: palm_65-color0-rotate_90.jpg.txt\n",
            "ok_82-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0-f0.jpg.txt\n",
            "oksign 415 176 655 562\n",
            "[['oksign', '415', '176', '655', '562']]\n",
            "Processing complete for file: ok_82-color0-f0.jpg.txt\n",
            "palm_5-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0-rotate_180.jpg.txt\n",
            "palmhand 73 19 379 568\n",
            "[['palmhand', '73', '19', '379', '568']]\n",
            "Processing complete for file: palm_5-color0-rotate_180.jpg.txt\n",
            "ok_4-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0-rotate_270.jpg.txt\n",
            "oksign 197 784 386 953\n",
            "[['oksign', '197', '784', '386', '953']]\n",
            "Processing complete for file: ok_4-color0-rotate_270.jpg.txt\n",
            "ok_21-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0-rotate_90.jpg.txt\n",
            "oksign 109 252 323 397\n",
            "[['oksign', '109', '252', '323', '397']]\n",
            "Processing complete for file: ok_21-color0-rotate_90.jpg.txt\n",
            "ok_44-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0-rotate_90.jpg.txt\n",
            "oksign 209 153 429 310\n",
            "[['oksign', '209', '153', '429', '310']]\n",
            "Processing complete for file: ok_44-color0-rotate_90.jpg.txt\n",
            "ok_62-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0-rotate_270.jpg.txt\n",
            "oksign 252 671 481 898\n",
            "[['oksign', '252', '671', '481', '898']]\n",
            "Processing complete for file: ok_62-color0-rotate_270.jpg.txt\n",
            "palm_61-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0-f0.jpg.txt\n",
            "palmhand 507 203 869 574\n",
            "[['palmhand', '507', '203', '869', '574']]\n",
            "Processing complete for file: palm_61-color0-f0.jpg.txt\n",
            "palm_31-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0-f0.jpg.txt\n",
            "palmhand 57 52 609 314\n",
            "[['palmhand', '57', '52', '609', '314']]\n",
            "Processing complete for file: palm_31-color0-f0.jpg.txt\n",
            "ok_83-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0-rotate_180.jpg.txt\n",
            "oksign 232 364 504 668\n",
            "[['oksign', '232', '364', '504', '668']]\n",
            "Processing complete for file: ok_83-color0-rotate_180.jpg.txt\n",
            "ok_36-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0-f0.jpg.txt\n",
            "oksign 96 105 205 265\n",
            "[['oksign', '96', '105', '205', '265']]\n",
            "Processing complete for file: ok_36-color0-f0.jpg.txt\n",
            "ok_31-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0-f1.jpg.txt\n",
            "oksign 189 18 394 337\n",
            "[['oksign', '189', '18', '394', '337']]\n",
            "Processing complete for file: ok_31-color0-f1.jpg.txt\n",
            "ok_9-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0-rotate_180.jpg.txt\n",
            "oksign 405 360 539 518\n",
            "[['oksign', '405', '360', '539', '518']]\n",
            "Processing complete for file: ok_9-color0-rotate_180.jpg.txt\n",
            "ok_65-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0-rotate_270.jpg.txt\n",
            "oksign 335 282 558 611\n",
            "[['oksign', '335', '282', '558', '611']]\n",
            "Processing complete for file: ok_65-color0-rotate_270.jpg.txt\n",
            "ok_25-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0-f0.jpg.txt\n",
            "oksign 1006 497 2106 1784\n",
            "[['oksign', '1006', '497', '2106', '1784']]\n",
            "Processing complete for file: ok_25-color0-f0.jpg.txt\n",
            "peace_22-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0-f1.jpg.txt\n",
            "peacesign 47 24 892 1018\n",
            "[['peacesign', '47', '24', '892', '1018']]\n",
            "Processing complete for file: peace_22-color0-f1.jpg.txt\n",
            "palm_2-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0-f0.jpg.txt\n",
            "palmhand 97 0 454 642\n",
            "[['palmhand', '97', '0', '454', '642']]\n",
            "Processing complete for file: palm_2-color0-f0.jpg.txt\n",
            "ok_9-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0-rotate_90.jpg.txt\n",
            "oksign 360 741 518 875\n",
            "[['oksign', '360', '741', '518', '875']]\n",
            "Processing complete for file: ok_9-color0-rotate_90.jpg.txt\n",
            "palm_29-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0-rotate_90.jpg.txt\n",
            "palmhand 8 53 450 278\n",
            "[['palmhand', '8', '53', '450', '278']]\n",
            "Processing complete for file: palm_29-color0-rotate_90.jpg.txt\n",
            "peace_8-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0-f0.jpg.txt\n",
            "peacesign 23 28 341 597\n",
            "[['peacesign', '23', '28', '341', '597']]\n",
            "Processing complete for file: peace_8-color0-f0.jpg.txt\n",
            "palm_17-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0-rotate_180.jpg.txt\n",
            "palmhand 199 135 514 308\n",
            "[['palmhand', '199', '135', '514', '308']]\n",
            "Processing complete for file: palm_17-color0-rotate_180.jpg.txt\n",
            "palm_22-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0-f1.jpg.txt\n",
            "palmhand 315 69 569 414\n",
            "[['palmhand', '315', '69', '569', '414']]\n",
            "palmhand 68 66 310 411\n",
            "[['palmhand', '315', '69', '569', '414'], ['palmhand', '68', '66', '310', '411']]\n",
            "Processing complete for file: palm_22-color0-f1.jpg.txt\n",
            "ok_17-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0-f1.jpg.txt\n",
            "oksign 88 42 660 827\n",
            "[['oksign', '88', '42', '660', '827']]\n",
            "Processing complete for file: ok_17-color0-f1.jpg.txt\n",
            "palm_6-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0.jpg.txt\n",
            "palmhand 51 14 393 607\n",
            "[['palmhand', '51', '14', '393', '607']]\n",
            "Processing complete for file: palm_6-color0.jpg.txt\n",
            "peace_17-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0-f1.jpg.txt\n",
            "peacesign 656 73 1201 381\n",
            "[['peacesign', '656', '73', '1201', '381']]\n",
            "peacesign 240 259 727 903\n",
            "[['peacesign', '656', '73', '1201', '381'], ['peacesign', '240', '259', '727', '903']]\n",
            "Processing complete for file: peace_17-color0-f1.jpg.txt\n",
            "ok_20-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0-rotate_90.jpg.txt\n",
            "oksign 147 244 467 452\n",
            "[['oksign', '147', '244', '467', '452']]\n",
            "Processing complete for file: ok_20-color0-rotate_90.jpg.txt\n",
            "palm_8-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0-f0.jpg.txt\n",
            "palmhand 61 43 402 646\n",
            "[['palmhand', '61', '43', '402', '646']]\n",
            "Processing complete for file: palm_8-color0-f0.jpg.txt\n",
            "ok_59-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0-rotate_270.jpg.txt\n",
            "oksign 114 404 494 679\n",
            "[['oksign', '114', '404', '494', '679']]\n",
            "Processing complete for file: ok_59-color0-rotate_270.jpg.txt\n",
            "peace_69-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0-f1.jpg.txt\n",
            "peacesign 503 200 898 591\n",
            "[['peacesign', '503', '200', '898', '591']]\n",
            "Processing complete for file: peace_69-color0-f1.jpg.txt\n",
            "peace_25-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0-rotate_90.jpg.txt\n",
            "peacesign 321 533 715 774\n",
            "[['peacesign', '321', '533', '715', '774']]\n",
            "Processing complete for file: peace_25-color0-rotate_90.jpg.txt\n",
            "palm_38-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0-rotate_90.jpg.txt\n",
            "palmhand 36 34 453 317\n",
            "[['palmhand', '36', '34', '453', '317']]\n",
            "Processing complete for file: palm_38-color0-rotate_90.jpg.txt\n",
            "ok_15-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0-f0.jpg.txt\n",
            "oksign 88 77 351 469\n",
            "[['oksign', '88', '77', '351', '469']]\n",
            "Processing complete for file: ok_15-color0-f0.jpg.txt\n",
            "palm_24-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0-f0.jpg.txt\n",
            "palmhand 118 0 428 472\n",
            "[['palmhand', '118', '0', '428', '472']]\n",
            "Processing complete for file: palm_24-color0-f0.jpg.txt\n",
            "peace_27-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0.jpg.txt\n",
            "peacesign 197 160 367 492\n",
            "[['peacesign', '197', '160', '367', '492']]\n",
            "Processing complete for file: peace_27-color0.jpg.txt\n",
            "ok_2-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0-rotate_180.jpg.txt\n",
            "oksign 125 301 556 942\n",
            "[['oksign', '125', '301', '556', '942']]\n",
            "Processing complete for file: ok_2-color0-rotate_180.jpg.txt\n",
            "peace_20-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0-f1.jpg.txt\n",
            "peacesign 457 138 1067 667\n",
            "[['peacesign', '457', '138', '1067', '667']]\n",
            "Processing complete for file: peace_20-color0-f1.jpg.txt\n",
            "peace_84-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0.jpg.txt\n",
            "peacesign 434 92 738 561\n",
            "[['peacesign', '434', '92', '738', '561']]\n",
            "Processing complete for file: peace_84-color0.jpg.txt\n",
            "palm_20-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0.jpg.txt\n",
            "palmhand 11 42 265 392\n",
            "[['palmhand', '11', '42', '265', '392']]\n",
            "Processing complete for file: palm_20-color0.jpg.txt\n",
            "ok_41-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0-rotate_90.jpg.txt\n",
            "oksign 174 269 280 345\n",
            "[['oksign', '174', '269', '280', '345']]\n",
            "oksign 153 513 265 593\n",
            "[['oksign', '174', '269', '280', '345'], ['oksign', '153', '513', '265', '593']]\n",
            "Processing complete for file: ok_41-color0-rotate_90.jpg.txt\n",
            "peace_20-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0-rotate_90.jpg.txt\n",
            "peacesign 184 213 713 823\n",
            "[['peacesign', '184', '213', '713', '823']]\n",
            "Processing complete for file: peace_20-color0-rotate_90.jpg.txt\n",
            "palm_4-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0.jpg.txt\n",
            "palmhand 58 12 371 583\n",
            "[['palmhand', '58', '12', '371', '583']]\n",
            "Processing complete for file: palm_4-color0.jpg.txt\n",
            "peace_91-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0.jpg.txt\n",
            "peacesign 112 185 501 605\n",
            "[['peacesign', '112', '185', '501', '605']]\n",
            "Processing complete for file: peace_91-color0.jpg.txt\n",
            "ok_55-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0-rotate_180.jpg.txt\n",
            "oksign 498 281 718 627\n",
            "[['oksign', '498', '281', '718', '627']]\n",
            "Processing complete for file: ok_55-color0-rotate_180.jpg.txt\n",
            "palm_57-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0-f1.jpg.txt\n",
            "palmhand 440 123 721 508\n",
            "[['palmhand', '440', '123', '721', '508']]\n",
            "Processing complete for file: palm_57-color0-f1.jpg.txt\n",
            "palm_66-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0-rotate_90.jpg.txt\n",
            "palmhand 178 398 697 709\n",
            "[['palmhand', '178', '398', '697', '709']]\n",
            "Processing complete for file: palm_66-color0-rotate_90.jpg.txt\n",
            "palm_10-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0-f1.jpg.txt\n",
            "palmhand 62 23 366 564\n",
            "[['palmhand', '62', '23', '366', '564']]\n",
            "Processing complete for file: palm_10-color0-f1.jpg.txt\n",
            "ok_10-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0-f0.jpg.txt\n",
            "oksign 241 16 717 634\n",
            "[['oksign', '241', '16', '717', '634']]\n",
            "Processing complete for file: ok_10-color0-f0.jpg.txt\n",
            "ok_17-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0.jpg.txt\n",
            "oksign 215 42 787 827\n",
            "[['oksign', '215', '42', '787', '827']]\n",
            "Processing complete for file: ok_17-color0.jpg.txt\n",
            "palm_28-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0-rotate_90.jpg.txt\n",
            "palmhand 43 49 286 589\n",
            "[['palmhand', '43', '49', '286', '589']]\n",
            "Processing complete for file: palm_28-color0-rotate_90.jpg.txt\n",
            "peace_19-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0-f0.jpg.txt\n",
            "peacesign 510 212 572 274\n",
            "[['peacesign', '510', '212', '572', '274']]\n",
            "peacesign 845 270 914 365\n",
            "[['peacesign', '510', '212', '572', '274'], ['peacesign', '845', '270', '914', '365']]\n",
            "Processing complete for file: peace_19-color0-f0.jpg.txt\n",
            "peace_53-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0-rotate_270.jpg.txt\n",
            "peacesign 96 324 703 755\n",
            "[['peacesign', '96', '324', '703', '755']]\n",
            "Processing complete for file: peace_53-color0-rotate_270.jpg.txt\n",
            "peace_52-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0-f0.jpg.txt\n",
            "peacesign 305 68 750 662\n",
            "[['peacesign', '305', '68', '750', '662']]\n",
            "Processing complete for file: peace_52-color0-f0.jpg.txt\n",
            "ok_55-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0.jpg.txt\n",
            "oksign 362 93 582 439\n",
            "[['oksign', '362', '93', '582', '439']]\n",
            "Processing complete for file: ok_55-color0.jpg.txt\n",
            "peace_18-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0-rotate_90.jpg.txt\n",
            "peacesign 187 167 758 489\n",
            "[['peacesign', '187', '167', '758', '489']]\n",
            "peacesign 112 744 726 1077\n",
            "[['peacesign', '187', '167', '758', '489'], ['peacesign', '112', '744', '726', '1077']]\n",
            "Processing complete for file: peace_18-color0-rotate_90.jpg.txt\n",
            "palm_18-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0.jpg.txt\n",
            "palmhand 35 95 605 409\n",
            "[['palmhand', '35', '95', '605', '409']]\n",
            "Processing complete for file: palm_18-color0.jpg.txt\n",
            "palm_56-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0-f1.jpg.txt\n",
            "palmhand 313 108 582 521\n",
            "[['palmhand', '313', '108', '582', '521']]\n",
            "Processing complete for file: palm_56-color0-f1.jpg.txt\n",
            "peace_82-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0-f0.jpg.txt\n",
            "peacesign 592 133 992 413\n",
            "[['peacesign', '592', '133', '992', '413']]\n",
            "Processing complete for file: peace_82-color0-f0.jpg.txt\n",
            "peace_63-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0-rotate_90.jpg.txt\n",
            "peacesign 217 356 564 587\n",
            "[['peacesign', '217', '356', '564', '587']]\n",
            "Processing complete for file: peace_63-color0-rotate_90.jpg.txt\n",
            "peace_15-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0-f1.jpg.txt\n",
            "peacesign 411 26 704 566\n",
            "[['peacesign', '411', '26', '704', '566']]\n",
            "Processing complete for file: peace_15-color0-f1.jpg.txt\n",
            "peace_76-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0-f1.jpg.txt\n",
            "peacesign 390 314 1004 650\n",
            "[['peacesign', '390', '314', '1004', '650']]\n",
            "Processing complete for file: peace_76-color0-f1.jpg.txt\n",
            "palm_56-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0-f0.jpg.txt\n",
            "palmhand 498 199 767 612\n",
            "[['palmhand', '498', '199', '767', '612']]\n",
            "Processing complete for file: palm_56-color0-f0.jpg.txt\n",
            "palm_19-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0-rotate_90.jpg.txt\n",
            "palmhand 79 82 479 494\n",
            "[['palmhand', '79', '82', '479', '494']]\n",
            "Processing complete for file: palm_19-color0-rotate_90.jpg.txt\n",
            "palm_42-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0-rotate_90.jpg.txt\n",
            "palmhand 177 332 314 569\n",
            "[['palmhand', '177', '332', '314', '569']]\n",
            "Processing complete for file: palm_42-color0-rotate_90.jpg.txt\n",
            "ok_88-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0-f0.jpg.txt\n",
            "oksign 369 189 584 414\n",
            "[['oksign', '369', '189', '584', '414']]\n",
            "Processing complete for file: ok_88-color0-f0.jpg.txt\n",
            "palm_6-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0-rotate_180.jpg.txt\n",
            "palmhand 96 54 438 647\n",
            "[['palmhand', '96', '54', '438', '647']]\n",
            "Processing complete for file: palm_6-color0-rotate_180.jpg.txt\n",
            "palm_83-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0-rotate_90.jpg.txt\n",
            "palmhand 278 498 526 723\n",
            "[['palmhand', '278', '498', '526', '723']]\n",
            "Processing complete for file: palm_83-color0-rotate_90.jpg.txt\n",
            "ok_26-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0-rotate_270.jpg.txt\n",
            "oksign 36 206 288 395\n",
            "[['oksign', '36', '206', '288', '395']]\n",
            "Processing complete for file: ok_26-color0-rotate_270.jpg.txt\n",
            "peace_36-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0-rotate_180.jpg.txt\n",
            "peacesign 376 185 584 554\n",
            "[['peacesign', '376', '185', '584', '554']]\n",
            "Processing complete for file: peace_36-color0-rotate_180.jpg.txt\n",
            "peace_42-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0-rotate_90.jpg.txt\n",
            "peacesign 386 201 748 511\n",
            "[['peacesign', '386', '201', '748', '511']]\n",
            "peacesign 417 1186 823 1486\n",
            "[['peacesign', '386', '201', '748', '511'], ['peacesign', '417', '1186', '823', '1486']]\n",
            "Processing complete for file: peace_42-color0-rotate_90.jpg.txt\n",
            "ok_55-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0-rotate_90.jpg.txt\n",
            "oksign 281 362 627 582\n",
            "[['oksign', '281', '362', '627', '582']]\n",
            "Processing complete for file: ok_55-color0-rotate_90.jpg.txt\n",
            "palm_28-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0-rotate_180.jpg.txt\n",
            "palmhand 51 43 591 286\n",
            "[['palmhand', '51', '43', '591', '286']]\n",
            "Processing complete for file: palm_28-color0-rotate_180.jpg.txt\n",
            "ok_30-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0-rotate_90.jpg.txt\n",
            "oksign 153 125 799 606\n",
            "[['oksign', '153', '125', '799', '606']]\n",
            "Processing complete for file: ok_30-color0-rotate_90.jpg.txt\n",
            "ok_39-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0-rotate_180.jpg.txt\n",
            "oksign 311 146 566 546\n",
            "[['oksign', '311', '146', '566', '546']]\n",
            "Processing complete for file: ok_39-color0-rotate_180.jpg.txt\n",
            "palm_91-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0-rotate_270.jpg.txt\n",
            "palmhand 73 350 398 569\n",
            "[['palmhand', '73', '350', '398', '569']]\n",
            "Processing complete for file: palm_91-color0-rotate_270.jpg.txt\n",
            "peace_96-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0-f1.jpg.txt\n",
            "peacesign 533 78 770 561\n",
            "[['peacesign', '533', '78', '770', '561']]\n",
            "Processing complete for file: peace_96-color0-f1.jpg.txt\n",
            "ok_93-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0-rotate_270.jpg.txt\n",
            "oksign 244 82 435 384\n",
            "[['oksign', '244', '82', '435', '384']]\n",
            "Processing complete for file: ok_93-color0-rotate_270.jpg.txt\n",
            "peace_89-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0-rotate_180.jpg.txt\n",
            "peacesign 295 84 568 537\n",
            "[['peacesign', '295', '84', '568', '537']]\n",
            "Processing complete for file: peace_89-color0-rotate_180.jpg.txt\n",
            "palm_55-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0-rotate_270.jpg.txt\n",
            "palmhand 139 307 554 573\n",
            "[['palmhand', '139', '307', '554', '573']]\n",
            "Processing complete for file: palm_55-color0-rotate_270.jpg.txt\n",
            "peace_53-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0-f1.jpg.txt\n",
            "peacesign 324 96 755 703\n",
            "[['peacesign', '324', '96', '755', '703']]\n",
            "Processing complete for file: peace_53-color0-f1.jpg.txt\n",
            "ok_95-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0-f0.jpg.txt\n",
            "oksign 617 320 905 545\n",
            "[['oksign', '617', '320', '905', '545']]\n",
            "Processing complete for file: ok_95-color0-f0.jpg.txt\n",
            "ok_71-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0-rotate_90.jpg.txt\n",
            "oksign 318 321 670 555\n",
            "[['oksign', '318', '321', '670', '555']]\n",
            "Processing complete for file: ok_71-color0-rotate_90.jpg.txt\n",
            "palm_21-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0-rotate_270.jpg.txt\n",
            "palmhand 38 353 782 963\n",
            "[['palmhand', '38', '353', '782', '963']]\n",
            "Processing complete for file: palm_21-color0-rotate_270.jpg.txt\n",
            "peace_85-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0-rotate_90.jpg.txt\n",
            "peacesign 162 638 679 992\n",
            "[['peacesign', '162', '638', '679', '992']]\n",
            "Processing complete for file: peace_85-color0-rotate_90.jpg.txt\n",
            "ok_70-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0-rotate_270.jpg.txt\n",
            "oksign 81 617 406 852\n",
            "[['oksign', '81', '617', '406', '852']]\n",
            "Processing complete for file: ok_70-color0-rotate_270.jpg.txt\n",
            "ok_80-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0-f0.jpg.txt\n",
            "oksign 642 131 915 564\n",
            "[['oksign', '642', '131', '915', '564']]\n",
            "Processing complete for file: ok_80-color0-f0.jpg.txt\n",
            "peace_13-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0-f1.jpg.txt\n",
            "peacesign 46 13 294 466\n",
            "[['peacesign', '46', '13', '294', '466']]\n",
            "Processing complete for file: peace_13-color0-f1.jpg.txt\n",
            "peace_82-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0-f1.jpg.txt\n",
            "peacesign 88 307 488 587\n",
            "[['peacesign', '88', '307', '488', '587']]\n",
            "Processing complete for file: peace_82-color0-f1.jpg.txt\n",
            "palm_4-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0-rotate_270.jpg.txt\n",
            "palmhand 12 122 583 435\n",
            "[['palmhand', '12', '122', '583', '435']]\n",
            "Processing complete for file: palm_4-color0-rotate_270.jpg.txt\n",
            "palm_38-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0-f1.jpg.txt\n",
            "palmhand 43 27 326 444\n",
            "[['palmhand', '43', '27', '326', '444']]\n",
            "Processing complete for file: palm_38-color0-f1.jpg.txt\n",
            "ok_89-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0-rotate_90.jpg.txt\n",
            "oksign 199 317 389 609\n",
            "[['oksign', '199', '317', '389', '609']]\n",
            "Processing complete for file: ok_89-color0-rotate_90.jpg.txt\n",
            "peace_69-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0.jpg.txt\n",
            "peacesign 182 200 577 591\n",
            "[['peacesign', '182', '200', '577', '591']]\n",
            "Processing complete for file: peace_69-color0.jpg.txt\n",
            "palm_4-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0-rotate_180.jpg.txt\n",
            "palmhand 122 8 435 579\n",
            "[['palmhand', '122', '8', '435', '579']]\n",
            "Processing complete for file: palm_4-color0-rotate_180.jpg.txt\n",
            "palm_18-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0-f0.jpg.txt\n",
            "palmhand 35 71 605 385\n",
            "[['palmhand', '35', '71', '605', '385']]\n",
            "Processing complete for file: palm_18-color0-f0.jpg.txt\n",
            "palm_31-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0-rotate_90.jpg.txt\n",
            "palmhand 52 57 314 609\n",
            "[['palmhand', '52', '57', '314', '609']]\n",
            "Processing complete for file: palm_31-color0-rotate_90.jpg.txt\n",
            "palm_40-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0-rotate_270.jpg.txt\n",
            "palmhand 82 60 429 560\n",
            "[['palmhand', '82', '60', '429', '560']]\n",
            "Processing complete for file: palm_40-color0-rotate_270.jpg.txt\n",
            "palm_76-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0-rotate_90.jpg.txt\n",
            "palmhand 158 540 564 769\n",
            "[['palmhand', '158', '540', '564', '769']]\n",
            "Processing complete for file: palm_76-color0-rotate_90.jpg.txt\n",
            "peace_80-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0-f0.jpg.txt\n",
            "peacesign 367 157 583 533\n",
            "[['peacesign', '367', '157', '583', '533']]\n",
            "Processing complete for file: peace_80-color0-f0.jpg.txt\n",
            "palm_25-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0-f0.jpg.txt\n",
            "palmhand 450 202 514 303\n",
            "[['palmhand', '450', '202', '514', '303']]\n",
            "palmhand 325 205 390 305\n",
            "[['palmhand', '450', '202', '514', '303'], ['palmhand', '325', '205', '390', '305']]\n",
            "Processing complete for file: palm_25-color0-f0.jpg.txt\n",
            "ok_52-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0.jpg.txt\n",
            "oksign 476 125 746 517\n",
            "[['oksign', '476', '125', '746', '517']]\n",
            "Processing complete for file: ok_52-color0.jpg.txt\n",
            "palm_68-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0.jpg.txt\n",
            "palmhand 253 81 486 412\n",
            "[['palmhand', '253', '81', '486', '412']]\n",
            "Processing complete for file: palm_68-color0.jpg.txt\n",
            "palm_41-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0-f0.jpg.txt\n",
            "palmhand 52 0 339 375\n",
            "[['palmhand', '52', '0', '339', '375']]\n",
            "palmhand 344 13 600 419\n",
            "[['palmhand', '52', '0', '339', '375'], ['palmhand', '344', '13', '600', '419']]\n",
            "Processing complete for file: palm_41-color0-f0.jpg.txt\n",
            "palm_29-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0-f0.jpg.txt\n",
            "palmhand 53 8 278 450\n",
            "[['palmhand', '53', '8', '278', '450']]\n",
            "Processing complete for file: palm_29-color0-f0.jpg.txt\n",
            "peace_11-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0-rotate_270.jpg.txt\n",
            "peacesign 36 67 460 303\n",
            "[['peacesign', '36', '67', '460', '303']]\n",
            "Processing complete for file: peace_11-color0-rotate_270.jpg.txt\n",
            "peace_11-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0.jpg.txt\n",
            "peacesign 48 36 284 460\n",
            "[['peacesign', '48', '36', '284', '460']]\n",
            "Processing complete for file: peace_11-color0.jpg.txt\n",
            "ok_70-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0-f0.jpg.txt\n",
            "oksign 228 314 463 639\n",
            "[['oksign', '228', '314', '463', '639']]\n",
            "Processing complete for file: ok_70-color0-f0.jpg.txt\n",
            "peace_55-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0-f1.jpg.txt\n",
            "peacesign 157 41 648 610\n",
            "[['peacesign', '157', '41', '648', '610']]\n",
            "Processing complete for file: peace_55-color0-f1.jpg.txt\n",
            "palm_92-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0-rotate_270.jpg.txt\n",
            "palmhand 119 467 408 661\n",
            "[['palmhand', '119', '467', '408', '661']]\n",
            "Processing complete for file: palm_92-color0-rotate_270.jpg.txt\n",
            "ok_10-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0-rotate_270.jpg.txt\n",
            "oksign 47 251 665 727\n",
            "[['oksign', '47', '251', '665', '727']]\n",
            "Processing complete for file: ok_10-color0-rotate_270.jpg.txt\n",
            "ok_79-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0-f0.jpg.txt\n",
            "oksign 271 189 546 562\n",
            "[['oksign', '271', '189', '546', '562']]\n",
            "Processing complete for file: ok_79-color0-f0.jpg.txt\n",
            "peace_32-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0-rotate_270.jpg.txt\n",
            "peacesign 42 261 314 413\n",
            "[['peacesign', '42', '261', '314', '413']]\n",
            "Processing complete for file: peace_32-color0-rotate_270.jpg.txt\n",
            "ok_4-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0-rotate_180.jpg.txt\n",
            "oksign 784 468 953 657\n",
            "[['oksign', '784', '468', '953', '657']]\n",
            "Processing complete for file: ok_4-color0-rotate_180.jpg.txt\n",
            "peace_80-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0-rotate_180.jpg.txt\n",
            "peacesign 497 157 713 533\n",
            "[['peacesign', '497', '157', '713', '533']]\n",
            "Processing complete for file: peace_80-color0-rotate_180.jpg.txt\n",
            "ok_30-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0-rotate_180.jpg.txt\n",
            "oksign 94 153 575 799\n",
            "[['oksign', '94', '153', '575', '799']]\n",
            "Processing complete for file: ok_30-color0-rotate_180.jpg.txt\n",
            "peace_81-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0-f0.jpg.txt\n",
            "peacesign 490 190 814 557\n",
            "[['peacesign', '490', '190', '814', '557']]\n",
            "Processing complete for file: peace_81-color0-f0.jpg.txt\n",
            "ok_96-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0-rotate_90.jpg.txt\n",
            "oksign 337 655 595 865\n",
            "[['oksign', '337', '655', '595', '865']]\n",
            "Processing complete for file: ok_96-color0-rotate_90.jpg.txt\n",
            "ok_9-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0-f0.jpg.txt\n",
            "oksign 741 360 875 518\n",
            "[['oksign', '741', '360', '875', '518']]\n",
            "Processing complete for file: ok_9-color0-f0.jpg.txt\n",
            "peace_15-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0.jpg.txt\n",
            "peacesign 316 26 609 566\n",
            "[['peacesign', '316', '26', '609', '566']]\n",
            "Processing complete for file: peace_15-color0.jpg.txt\n",
            "palm_55-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0.jpg.txt\n",
            "palmhand 507 139 773 554\n",
            "[['palmhand', '507', '139', '773', '554']]\n",
            "Processing complete for file: palm_55-color0.jpg.txt\n",
            "palm_6-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0-rotate_270.jpg.txt\n",
            "palmhand 14 96 607 438\n",
            "[['palmhand', '14', '96', '607', '438']]\n",
            "Processing complete for file: palm_6-color0-rotate_270.jpg.txt\n",
            "ok_47-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0-f1.jpg.txt\n",
            "oksign 696 239 820 393\n",
            "[['oksign', '696', '239', '820', '393']]\n",
            "oksign 399 267 551 434\n",
            "[['oksign', '696', '239', '820', '393'], ['oksign', '399', '267', '551', '434']]\n",
            "Processing complete for file: ok_47-color0-f1.jpg.txt\n",
            "peace_96-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0.jpg.txt\n",
            "peacesign 310 78 547 561\n",
            "[['peacesign', '310', '78', '547', '561']]\n",
            "Processing complete for file: peace_96-color0.jpg.txt\n",
            "peace_4-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0.jpg.txt\n",
            "peacesign 14 21 430 577\n",
            "[['peacesign', '14', '21', '430', '577']]\n",
            "Processing complete for file: peace_4-color0.jpg.txt\n",
            "ok_88-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0-rotate_180.jpg.txt\n",
            "oksign 496 189 711 414\n",
            "[['oksign', '496', '189', '711', '414']]\n",
            "Processing complete for file: ok_88-color0-rotate_180.jpg.txt\n",
            "ok_90-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0-f0.jpg.txt\n",
            "oksign 323 216 588 418\n",
            "[['oksign', '323', '216', '588', '418']]\n",
            "Processing complete for file: ok_90-color0-f0.jpg.txt\n",
            "peace_88-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0-rotate_180.jpg.txt\n",
            "peacesign 179 70 462 559\n",
            "[['peacesign', '179', '70', '462', '559']]\n",
            "Processing complete for file: peace_88-color0-rotate_180.jpg.txt\n",
            "ok_26-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0-f1.jpg.txt\n",
            "oksign 206 36 395 288\n",
            "[['oksign', '206', '36', '395', '288']]\n",
            "Processing complete for file: ok_26-color0-f1.jpg.txt\n",
            "ok_36-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0.jpg.txt\n",
            "oksign 96 87 205 247\n",
            "[['oksign', '96', '87', '205', '247']]\n",
            "Processing complete for file: ok_36-color0.jpg.txt\n",
            "palm_87-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0-rotate_180.jpg.txt\n",
            "palmhand 338 299 563 670\n",
            "[['palmhand', '338', '299', '563', '670']]\n",
            "Processing complete for file: palm_87-color0-rotate_180.jpg.txt\n",
            "peace_33-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0-rotate_270.jpg.txt\n",
            "peacesign 94 588 216 664\n",
            "[['peacesign', '94', '588', '216', '664']]\n",
            "peacesign 50 326 174 393\n",
            "[['peacesign', '94', '588', '216', '664'], ['peacesign', '50', '326', '174', '393']]\n",
            "Processing complete for file: peace_33-color0-rotate_270.jpg.txt\n",
            "ok_81-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0-f0.jpg.txt\n",
            "oksign 484 106 751 501\n",
            "[['oksign', '484', '106', '751', '501']]\n",
            "Processing complete for file: ok_81-color0-f0.jpg.txt\n",
            "palm_17-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0-rotate_90.jpg.txt\n",
            "palmhand 135 206 308 521\n",
            "[['palmhand', '135', '206', '308', '521']]\n",
            "Processing complete for file: palm_17-color0-rotate_90.jpg.txt\n",
            "ok_24-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0.jpg.txt\n",
            "oksign 184 51 357 325\n",
            "[['oksign', '184', '51', '357', '325']]\n",
            "Processing complete for file: ok_24-color0.jpg.txt\n",
            "peace_19-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0-f1.jpg.txt\n",
            "peacesign 708 580 770 642\n",
            "[['peacesign', '708', '580', '770', '642']]\n",
            "peacesign 366 489 435 584\n",
            "[['peacesign', '708', '580', '770', '642'], ['peacesign', '366', '489', '435', '584']]\n",
            "Processing complete for file: peace_19-color0-f1.jpg.txt\n",
            "peace_37-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0-f0.jpg.txt\n",
            "peacesign 643 211 922 648\n",
            "[['peacesign', '643', '211', '922', '648']]\n",
            "Processing complete for file: peace_37-color0-f0.jpg.txt\n",
            "peace_18-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0-rotate_270.jpg.txt\n",
            "peacesign 95 791 666 1113\n",
            "[['peacesign', '95', '791', '666', '1113']]\n",
            "peacesign 127 203 741 536\n",
            "[['peacesign', '95', '791', '666', '1113'], ['peacesign', '127', '203', '741', '536']]\n",
            "Processing complete for file: peace_18-color0-rotate_270.jpg.txt\n",
            "peace_52-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0.jpg.txt\n",
            "peacesign 305 58 750 652\n",
            "[['peacesign', '305', '58', '750', '652']]\n",
            "Processing complete for file: peace_52-color0.jpg.txt\n",
            "peace_1-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0-rotate_180.jpg.txt\n",
            "peacesign 70 48 394 612\n",
            "[['peacesign', '70', '48', '394', '612']]\n",
            "Processing complete for file: peace_1-color0-rotate_180.jpg.txt\n",
            "peace_19-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0.jpg.txt\n",
            "peacesign 510 580 572 642\n",
            "[['peacesign', '510', '580', '572', '642']]\n",
            "peacesign 845 489 914 584\n",
            "[['peacesign', '510', '580', '572', '642'], ['peacesign', '845', '489', '914', '584']]\n",
            "Processing complete for file: peace_19-color0.jpg.txt\n",
            "ok_37-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0-rotate_180.jpg.txt\n",
            "oksign 197 175 421 497\n",
            "[['oksign', '197', '175', '421', '497']]\n",
            "Processing complete for file: ok_37-color0-rotate_180.jpg.txt\n",
            "palm_2-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0-rotate_180.jpg.txt\n",
            "palmhand 125 0 482 642\n",
            "[['palmhand', '125', '0', '482', '642']]\n",
            "Processing complete for file: palm_2-color0-rotate_180.jpg.txt\n",
            "ok_86-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0-rotate_180.jpg.txt\n",
            "oksign 361 233 554 447\n",
            "[['oksign', '361', '233', '554', '447']]\n",
            "Processing complete for file: ok_86-color0-rotate_180.jpg.txt\n",
            "ok_58-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0-f1.jpg.txt\n",
            "oksign 344 154 613 487\n",
            "[['oksign', '344', '154', '613', '487']]\n",
            "Processing complete for file: ok_58-color0-f1.jpg.txt\n",
            "palm_90-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0-rotate_270.jpg.txt\n",
            "palmhand 114 250 425 536\n",
            "[['palmhand', '114', '250', '425', '536']]\n",
            "Processing complete for file: palm_90-color0-rotate_270.jpg.txt\n",
            "ok_97-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0-rotate_180.jpg.txt\n",
            "oksign 292 339 500 645\n",
            "[['oksign', '292', '339', '500', '645']]\n",
            "Processing complete for file: ok_97-color0-rotate_180.jpg.txt\n",
            "ok_13-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0-rotate_270.jpg.txt\n",
            "oksign 72 79 392 323\n",
            "[['oksign', '72', '79', '392', '323']]\n",
            "Processing complete for file: ok_13-color0-rotate_270.jpg.txt\n",
            "palm_86-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0-f0.jpg.txt\n",
            "palmhand 361 301 680 620\n",
            "[['palmhand', '361', '301', '680', '620']]\n",
            "Processing complete for file: palm_86-color0-f0.jpg.txt\n",
            "ok_53-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0-rotate_270.jpg.txt\n",
            "oksign 50 421 450 682\n",
            "[['oksign', '50', '421', '450', '682']]\n",
            "Processing complete for file: ok_53-color0-rotate_270.jpg.txt\n",
            "peace_32-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0.jpg.txt\n",
            "peacesign 205 42 357 314\n",
            "[['peacesign', '205', '42', '357', '314']]\n",
            "Processing complete for file: peace_32-color0.jpg.txt\n",
            "peace_1-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0-rotate_90.jpg.txt\n",
            "peacesign 48 31 612 355\n",
            "[['peacesign', '48', '31', '612', '355']]\n",
            "Processing complete for file: peace_1-color0-rotate_90.jpg.txt\n",
            "palm_3-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0-rotate_270.jpg.txt\n",
            "palmhand 50 102 582 399\n",
            "[['palmhand', '50', '102', '582', '399']]\n",
            "Processing complete for file: palm_3-color0-rotate_270.jpg.txt\n",
            "peace_28-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0.jpg.txt\n",
            "peacesign 134 53 219 188\n",
            "[['peacesign', '134', '53', '219', '188']]\n",
            "Processing complete for file: peace_28-color0.jpg.txt\n",
            "peace_66-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0-f0.jpg.txt\n",
            "peacesign 465 148 696 613\n",
            "[['peacesign', '465', '148', '696', '613']]\n",
            "Processing complete for file: peace_66-color0-f0.jpg.txt\n",
            "ok_71-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0-f0.jpg.txt\n",
            "oksign 321 318 555 670\n",
            "[['oksign', '321', '318', '555', '670']]\n",
            "Processing complete for file: ok_71-color0-f0.jpg.txt\n",
            "palm_61-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0-rotate_90.jpg.txt\n",
            "palmhand 203 507 574 869\n",
            "[['palmhand', '203', '507', '574', '869']]\n",
            "Processing complete for file: palm_61-color0-rotate_90.jpg.txt\n",
            "ok_36-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0-rotate_180.jpg.txt\n",
            "oksign 235 105 344 265\n",
            "[['oksign', '235', '105', '344', '265']]\n",
            "Processing complete for file: ok_36-color0-rotate_180.jpg.txt\n",
            "ok_94-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0-rotate_270.jpg.txt\n",
            "oksign 71 190 552 492\n",
            "[['oksign', '71', '190', '552', '492']]\n",
            "Processing complete for file: ok_94-color0-rotate_270.jpg.txt\n",
            "peace_90-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0-f0.jpg.txt\n",
            "peacesign 358 122 618 573\n",
            "[['peacesign', '358', '122', '618', '573']]\n",
            "Processing complete for file: peace_90-color0-f0.jpg.txt\n",
            "palm_68-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0-rotate_270.jpg.txt\n",
            "palmhand 81 594 412 827\n",
            "[['palmhand', '81', '594', '412', '827']]\n",
            "Processing complete for file: palm_68-color0-rotate_270.jpg.txt\n",
            "ok_71-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0-rotate_180.jpg.txt\n",
            "oksign 525 318 759 670\n",
            "[['oksign', '525', '318', '759', '670']]\n",
            "Processing complete for file: ok_71-color0-rotate_180.jpg.txt\n",
            "ok_59-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0.jpg.txt\n",
            "oksign 401 114 676 494\n",
            "[['oksign', '401', '114', '676', '494']]\n",
            "Processing complete for file: ok_59-color0.jpg.txt\n",
            "palm_22-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0-rotate_270.jpg.txt\n",
            "palmhand 69 315 414 569\n",
            "[['palmhand', '69', '315', '414', '569']]\n",
            "palmhand 66 68 411 310\n",
            "[['palmhand', '69', '315', '414', '569'], ['palmhand', '66', '68', '411', '310']]\n",
            "Processing complete for file: palm_22-color0-rotate_270.jpg.txt\n",
            "palm_14-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0-f0.jpg.txt\n",
            "palmhand 180 99 576 368\n",
            "[['palmhand', '180', '99', '576', '368']]\n",
            "Processing complete for file: palm_14-color0-f0.jpg.txt\n",
            "ok_97-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0-f0.jpg.txt\n",
            "oksign 580 339 788 645\n",
            "[['oksign', '580', '339', '788', '645']]\n",
            "Processing complete for file: ok_97-color0-f0.jpg.txt\n",
            "peace_16-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0-f0.jpg.txt\n",
            "peacesign 134 43 318 383\n",
            "[['peacesign', '134', '43', '318', '383']]\n",
            "Processing complete for file: peace_16-color0-f0.jpg.txt\n",
            "palm_33-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0-rotate_180.jpg.txt\n",
            "palmhand 220 151 342 351\n",
            "[['palmhand', '220', '151', '342', '351']]\n",
            "palmhand 369 145 517 329\n",
            "[['palmhand', '220', '151', '342', '351'], ['palmhand', '369', '145', '517', '329']]\n",
            "Processing complete for file: palm_33-color0-rotate_180.jpg.txt\n",
            "peace_37-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0-rotate_180.jpg.txt\n",
            "peacesign 262 211 541 648\n",
            "[['peacesign', '262', '211', '541', '648']]\n",
            "Processing complete for file: peace_37-color0-rotate_180.jpg.txt\n",
            "ok_18-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0-rotate_180.jpg.txt\n",
            "oksign 304 9 448 227\n",
            "[['oksign', '304', '9', '448', '227']]\n",
            "oksign 35 3 221 184\n",
            "[['oksign', '304', '9', '448', '227'], ['oksign', '35', '3', '221', '184']]\n",
            "Processing complete for file: ok_18-color0-rotate_180.jpg.txt\n",
            "peace_8-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0-f1.jpg.txt\n",
            "peacesign 58 8 376 577\n",
            "[['peacesign', '58', '8', '376', '577']]\n",
            "Processing complete for file: peace_8-color0-f1.jpg.txt\n",
            "peace_31-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0-f0.jpg.txt\n",
            "peacesign 191 194 691 1035\n",
            "[['peacesign', '191', '194', '691', '1035']]\n",
            "Processing complete for file: peace_31-color0-f0.jpg.txt\n",
            "peace_37-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0-rotate_270.jpg.txt\n",
            "peacesign 138 262 575 541\n",
            "[['peacesign', '138', '262', '575', '541']]\n",
            "Processing complete for file: peace_37-color0-rotate_270.jpg.txt\n",
            "ok_24-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0-rotate_270.jpg.txt\n",
            "oksign 51 255 325 428\n",
            "[['oksign', '51', '255', '325', '428']]\n",
            "Processing complete for file: ok_24-color0-rotate_270.jpg.txt\n",
            "peace_35-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0-rotate_270.jpg.txt\n",
            "peacesign 281 625 491 737\n",
            "[['peacesign', '281', '625', '491', '737']]\n",
            "Processing complete for file: peace_35-color0-rotate_270.jpg.txt\n",
            "ok_42-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0-f0.jpg.txt\n",
            "oksign 775 249 1054 671\n",
            "[['oksign', '775', '249', '1054', '671']]\n",
            "Processing complete for file: ok_42-color0-f0.jpg.txt\n",
            "palm_1-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0.jpg.txt\n",
            "palmhand 112 58 423 622\n",
            "[['palmhand', '112', '58', '423', '622']]\n",
            "Processing complete for file: palm_1-color0.jpg.txt\n",
            "ok_44-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0-f0.jpg.txt\n",
            "oksign 153 209 310 429\n",
            "[['oksign', '153', '209', '310', '429']]\n",
            "Processing complete for file: ok_44-color0-f0.jpg.txt\n",
            "ok_53-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0.jpg.txt\n",
            "oksign 398 50 659 450\n",
            "[['oksign', '398', '50', '659', '450']]\n",
            "Processing complete for file: ok_53-color0.jpg.txt\n",
            "palm_84-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0.jpg.txt\n",
            "palmhand 205 275 603 500\n",
            "[['palmhand', '205', '275', '603', '500']]\n",
            "Processing complete for file: palm_84-color0.jpg.txt\n",
            "palm_16-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0.jpg.txt\n",
            "palmhand 305 3 574 318\n",
            "[['palmhand', '305', '3', '574', '318']]\n",
            "palmhand 78 1 297 340\n",
            "[['palmhand', '305', '3', '574', '318'], ['palmhand', '78', '1', '297', '340']]\n",
            "Processing complete for file: palm_16-color0.jpg.txt\n",
            "peace_39-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0-rotate_270.jpg.txt\n",
            "peacesign 51 344 387 552\n",
            "[['peacesign', '51', '344', '387', '552']]\n",
            "Processing complete for file: peace_39-color0-rotate_270.jpg.txt\n",
            "peace_65-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0-f1.jpg.txt\n",
            "peacesign 252 203 659 603\n",
            "[['peacesign', '252', '203', '659', '603']]\n",
            "Processing complete for file: peace_65-color0-f1.jpg.txt\n",
            "peace_67-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0.jpg.txt\n",
            "peacesign 254 123 645 550\n",
            "[['peacesign', '254', '123', '645', '550']]\n",
            "Processing complete for file: peace_67-color0.jpg.txt\n",
            "peace_60-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0-f1.jpg.txt\n",
            "peacesign 582 107 835 418\n",
            "[['peacesign', '582', '107', '835', '418']]\n",
            "Processing complete for file: peace_60-color0-f1.jpg.txt\n",
            "peace_58-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0-f1.jpg.txt\n",
            "peacesign 148 125 610 616\n",
            "[['peacesign', '148', '125', '610', '616']]\n",
            "Processing complete for file: peace_58-color0-f1.jpg.txt\n",
            "palm_13-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0-f1.jpg.txt\n",
            "palmhand 282 156 585 687\n",
            "[['palmhand', '282', '156', '585', '687']]\n",
            "palmhand 591 201 925 753\n",
            "[['palmhand', '282', '156', '585', '687'], ['palmhand', '591', '201', '925', '753']]\n",
            "Processing complete for file: palm_13-color0-f1.jpg.txt\n",
            "palm_60-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0-f0.jpg.txt\n",
            "palmhand 540 114 963 383\n",
            "[['palmhand', '540', '114', '963', '383']]\n",
            "Processing complete for file: palm_60-color0-f0.jpg.txt\n",
            "palm_33-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0-rotate_270.jpg.txt\n",
            "palmhand 129 220 329 342\n",
            "[['palmhand', '129', '220', '329', '342']]\n",
            "palmhand 151 369 335 517\n",
            "[['palmhand', '129', '220', '329', '342'], ['palmhand', '151', '369', '335', '517']]\n",
            "Processing complete for file: palm_33-color0-rotate_270.jpg.txt\n",
            "peace_3-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0-rotate_180.jpg.txt\n",
            "peacesign 84 32 400 589\n",
            "[['peacesign', '84', '32', '400', '589']]\n",
            "Processing complete for file: peace_3-color0-rotate_180.jpg.txt\n",
            "ok_41-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0.jpg.txt\n",
            "oksign 269 137 345 243\n",
            "[['oksign', '269', '137', '345', '243']]\n",
            "oksign 513 152 593 264\n",
            "[['oksign', '269', '137', '345', '243'], ['oksign', '513', '152', '593', '264']]\n",
            "Processing complete for file: ok_41-color0.jpg.txt\n",
            "palm_15-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0.jpg.txt\n",
            "palmhand 54 52 355 443\n",
            "[['palmhand', '54', '52', '355', '443']]\n",
            "palmhand 364 52 675 443\n",
            "[['palmhand', '54', '52', '355', '443'], ['palmhand', '364', '52', '675', '443']]\n",
            "Processing complete for file: palm_15-color0.jpg.txt\n",
            "ok_53-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0-rotate_90.jpg.txt\n",
            "oksign 270 398 670 659\n",
            "[['oksign', '270', '398', '670', '659']]\n",
            "Processing complete for file: ok_53-color0-rotate_90.jpg.txt\n",
            "ok_1-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0-rotate_90.jpg.txt\n",
            "oksign 499 296 731 477\n",
            "[['oksign', '499', '296', '731', '477']]\n",
            "Processing complete for file: ok_1-color0-rotate_90.jpg.txt\n",
            "palm_79-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0-f1.jpg.txt\n",
            "palmhand 569 204 779 564\n",
            "[['palmhand', '569', '204', '779', '564']]\n",
            "Processing complete for file: palm_79-color0-f1.jpg.txt\n",
            "palm_64-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0-f0.jpg.txt\n",
            "palmhand 192 124 673 503\n",
            "[['palmhand', '192', '124', '673', '503']]\n",
            "Processing complete for file: palm_64-color0-f0.jpg.txt\n",
            "peace_7-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0-rotate_90.jpg.txt\n",
            "peacesign 56 47 626 366\n",
            "[['peacesign', '56', '47', '626', '366']]\n",
            "Processing complete for file: peace_7-color0-rotate_90.jpg.txt\n",
            "ok_30-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0-rotate_270.jpg.txt\n",
            "oksign 247 94 893 575\n",
            "[['oksign', '247', '94', '893', '575']]\n",
            "Processing complete for file: ok_30-color0-rotate_270.jpg.txt\n",
            "palm_64-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0-rotate_270.jpg.txt\n",
            "palmhand 217 407 596 888\n",
            "[['palmhand', '217', '407', '596', '888']]\n",
            "Processing complete for file: palm_64-color0-rotate_270.jpg.txt\n",
            "ok_38-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0-rotate_90.jpg.txt\n",
            "oksign 4 80 366 315\n",
            "[['oksign', '4', '80', '366', '315']]\n",
            "Processing complete for file: ok_38-color0-rotate_90.jpg.txt\n",
            "peace_53-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0-rotate_90.jpg.txt\n",
            "peacesign 17 325 624 756\n",
            "[['peacesign', '17', '325', '624', '756']]\n",
            "Processing complete for file: peace_53-color0-rotate_90.jpg.txt\n",
            "palm_21-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0-f1.jpg.txt\n",
            "palmhand 353 38 963 782\n",
            "[['palmhand', '353', '38', '963', '782']]\n",
            "Processing complete for file: palm_21-color0-f1.jpg.txt\n",
            "ok_22-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0.jpg.txt\n",
            "oksign 295 51 547 435\n",
            "[['oksign', '295', '51', '547', '435']]\n",
            "Processing complete for file: ok_22-color0.jpg.txt\n",
            "ok_58-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0.jpg.txt\n",
            "oksign 467 154 736 487\n",
            "[['oksign', '467', '154', '736', '487']]\n",
            "Processing complete for file: ok_58-color0.jpg.txt\n",
            "palm_18-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0-f1.jpg.txt\n",
            "palmhand 35 95 605 409\n",
            "[['palmhand', '35', '95', '605', '409']]\n",
            "Processing complete for file: palm_18-color0-f1.jpg.txt\n",
            "peace_40-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0-rotate_180.jpg.txt\n",
            "peacesign 278 128 400 308\n",
            "[['peacesign', '278', '128', '400', '308']]\n",
            "Processing complete for file: peace_40-color0-rotate_180.jpg.txt\n",
            "ok_89-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0-rotate_270.jpg.txt\n",
            "oksign 331 471 521 763\n",
            "[['oksign', '331', '471', '521', '763']]\n",
            "Processing complete for file: ok_89-color0-rotate_270.jpg.txt\n",
            "ok_31-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0-rotate_270.jpg.txt\n",
            "oksign 18 189 337 394\n",
            "[['oksign', '18', '189', '337', '394']]\n",
            "Processing complete for file: ok_31-color0-rotate_270.jpg.txt\n",
            "palm_19-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0-rotate_180.jpg.txt\n",
            "palmhand 0 79 412 479\n",
            "[['palmhand', '0', '79', '412', '479']]\n",
            "Processing complete for file: palm_19-color0-rotate_180.jpg.txt\n",
            "ok_29-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0-rotate_90.jpg.txt\n",
            "oksign 238 112 432 284\n",
            "[['oksign', '238', '112', '432', '284']]\n",
            "Processing complete for file: ok_29-color0-rotate_90.jpg.txt\n",
            "peace_61-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0-rotate_90.jpg.txt\n",
            "peacesign 313 621 648 890\n",
            "[['peacesign', '313', '621', '648', '890']]\n",
            "Processing complete for file: peace_61-color0-rotate_90.jpg.txt\n",
            "ok_8-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0-f0.jpg.txt\n",
            "oksign 75 409 227 588\n",
            "[['oksign', '75', '409', '227', '588']]\n",
            "Processing complete for file: ok_8-color0-f0.jpg.txt\n",
            "palm_69-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0-rotate_90.jpg.txt\n",
            "palmhand 310 384 628 707\n",
            "[['palmhand', '310', '384', '628', '707']]\n",
            "Processing complete for file: palm_69-color0-rotate_90.jpg.txt\n",
            "peace_15-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0-rotate_270.jpg.txt\n",
            "peacesign 26 411 566 704\n",
            "[['peacesign', '26', '411', '566', '704']]\n",
            "Processing complete for file: peace_15-color0-rotate_270.jpg.txt\n",
            "ok_18-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0-f1.jpg.txt\n",
            "oksign 304 144 448 362\n",
            "[['oksign', '304', '144', '448', '362']]\n",
            "oksign 35 187 221 368\n",
            "[['oksign', '304', '144', '448', '362'], ['oksign', '35', '187', '221', '368']]\n",
            "Processing complete for file: ok_18-color0-f1.jpg.txt\n",
            "peace_62-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0-rotate_90.jpg.txt\n",
            "peacesign 113 616 457 801\n",
            "[['peacesign', '113', '616', '457', '801']]\n",
            "Processing complete for file: peace_62-color0-rotate_90.jpg.txt\n",
            "ok_3-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0-rotate_270.jpg.txt\n",
            "oksign 227 166 451 366\n",
            "[['oksign', '227', '166', '451', '366']]\n",
            "Processing complete for file: ok_3-color0-rotate_270.jpg.txt\n",
            "peace_32-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0-f1.jpg.txt\n",
            "peacesign 261 42 413 314\n",
            "[['peacesign', '261', '42', '413', '314']]\n",
            "Processing complete for file: peace_32-color0-f1.jpg.txt\n",
            "ok_7-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0-rotate_180.jpg.txt\n",
            "oksign 858 321 1134 768\n",
            "[['oksign', '858', '321', '1134', '768']]\n",
            "Processing complete for file: ok_7-color0-rotate_180.jpg.txt\n",
            "palm_21-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0-rotate_90.jpg.txt\n",
            "palmhand 71 317 815 927\n",
            "[['palmhand', '71', '317', '815', '927']]\n",
            "Processing complete for file: palm_21-color0-rotate_90.jpg.txt\n",
            "palm_97-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0-f1.jpg.txt\n",
            "palmhand 234 114 513 392\n",
            "[['palmhand', '234', '114', '513', '392']]\n",
            "Processing complete for file: palm_97-color0-f1.jpg.txt\n",
            "peace_60-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0-rotate_270.jpg.txt\n",
            "peacesign 107 582 418 835\n",
            "[['peacesign', '107', '582', '418', '835']]\n",
            "Processing complete for file: peace_60-color0-rotate_270.jpg.txt\n",
            "ok_18-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0.jpg.txt\n",
            "oksign 212 144 356 362\n",
            "[['oksign', '212', '144', '356', '362']]\n",
            "oksign 439 187 625 368\n",
            "[['oksign', '212', '144', '356', '362'], ['oksign', '439', '187', '625', '368']]\n",
            "Processing complete for file: ok_18-color0.jpg.txt\n",
            "peace_71-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0-rotate_270.jpg.txt\n",
            "peacesign 80 382 483 716\n",
            "[['peacesign', '80', '382', '483', '716']]\n",
            "Processing complete for file: peace_71-color0-rotate_270.jpg.txt\n",
            "ok_94-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0.jpg.txt\n",
            "oksign 588 71 890 552\n",
            "[['oksign', '588', '71', '890', '552']]\n",
            "Processing complete for file: ok_94-color0.jpg.txt\n",
            "ok_87-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0-f1.jpg.txt\n",
            "oksign 440 279 654 519\n",
            "[['oksign', '440', '279', '654', '519']]\n",
            "Processing complete for file: ok_87-color0-f1.jpg.txt\n",
            "peace_29-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0.jpg.txt\n",
            "peacesign 402 139 862 1043\n",
            "[['peacesign', '402', '139', '862', '1043']]\n",
            "Processing complete for file: peace_29-color0.jpg.txt\n",
            "ok_7-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0.jpg.txt\n",
            "oksign 146 85 422 532\n",
            "[['oksign', '146', '85', '422', '532']]\n",
            "Processing complete for file: ok_7-color0.jpg.txt\n",
            "palm_30-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0-rotate_90.jpg.txt\n",
            "palmhand 35 246 474 521\n",
            "[['palmhand', '35', '246', '474', '521']]\n",
            "Processing complete for file: palm_30-color0-rotate_90.jpg.txt\n",
            "palm_15-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0-rotate_270.jpg.txt\n",
            "palmhand 52 366 443 667\n",
            "[['palmhand', '52', '366', '443', '667']]\n",
            "palmhand 52 46 443 357\n",
            "[['palmhand', '52', '366', '443', '667'], ['palmhand', '52', '46', '443', '357']]\n",
            "Processing complete for file: palm_15-color0-rotate_270.jpg.txt\n",
            "palm_96-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0.jpg.txt\n",
            "palmhand 426 108 626 398\n",
            "[['palmhand', '426', '108', '626', '398']]\n",
            "Processing complete for file: palm_96-color0.jpg.txt\n",
            "peace_57-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0-f1.jpg.txt\n",
            "peacesign 433 223 924 558\n",
            "[['peacesign', '433', '223', '924', '558']]\n",
            "Processing complete for file: peace_57-color0-f1.jpg.txt\n",
            "palm_19-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0-f1.jpg.txt\n",
            "palmhand 0 1 412 401\n",
            "[['palmhand', '0', '1', '412', '401']]\n",
            "Processing complete for file: palm_19-color0-f1.jpg.txt\n",
            "ok_14-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0-rotate_180.jpg.txt\n",
            "oksign 277 25 596 425\n",
            "[['oksign', '277', '25', '596', '425']]\n",
            "Processing complete for file: ok_14-color0-rotate_180.jpg.txt\n",
            "ok_84-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0-rotate_270.jpg.txt\n",
            "oksign 112 250 452 479\n",
            "[['oksign', '112', '250', '452', '479']]\n",
            "Processing complete for file: ok_84-color0-rotate_270.jpg.txt\n",
            "ok_71-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0-rotate_270.jpg.txt\n",
            "oksign 50 525 402 759\n",
            "[['oksign', '50', '525', '402', '759']]\n",
            "Processing complete for file: ok_71-color0-rotate_270.jpg.txt\n",
            "peace_81-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0-rotate_90.jpg.txt\n",
            "peacesign 190 490 557 814\n",
            "[['peacesign', '190', '490', '557', '814']]\n",
            "Processing complete for file: peace_81-color0-rotate_90.jpg.txt\n",
            "palm_23-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0-rotate_180.jpg.txt\n",
            "palmhand 111 147 538 291\n",
            "[['palmhand', '111', '147', '538', '291']]\n",
            "Processing complete for file: palm_23-color0-rotate_180.jpg.txt\n",
            "palm_85-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0-rotate_180.jpg.txt\n",
            "palmhand 477 245 838 497\n",
            "[['palmhand', '477', '245', '838', '497']]\n",
            "Processing complete for file: palm_85-color0-rotate_180.jpg.txt\n",
            "ok_59-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0-f0.jpg.txt\n",
            "oksign 401 226 676 606\n",
            "[['oksign', '401', '226', '676', '606']]\n",
            "Processing complete for file: ok_59-color0-f0.jpg.txt\n",
            "ok_27-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0-rotate_90.jpg.txt\n",
            "oksign 220 272 518 470\n",
            "[['oksign', '220', '272', '518', '470']]\n",
            "Processing complete for file: ok_27-color0-rotate_90.jpg.txt\n",
            "peace_3-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0-rotate_90.jpg.txt\n",
            "peacesign 32 21 589 337\n",
            "[['peacesign', '32', '21', '589', '337']]\n",
            "Processing complete for file: peace_3-color0-rotate_90.jpg.txt\n",
            "peace_29-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0-f0.jpg.txt\n",
            "peacesign 402 207 862 1111\n",
            "[['peacesign', '402', '207', '862', '1111']]\n",
            "Processing complete for file: peace_29-color0-f0.jpg.txt\n",
            "palm_80-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0.jpg.txt\n",
            "palmhand 696 37 988 537\n",
            "[['palmhand', '696', '37', '988', '537']]\n",
            "Processing complete for file: palm_80-color0.jpg.txt\n",
            "ok_95-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0-rotate_270.jpg.txt\n",
            "oksign 175 175 400 463\n",
            "[['oksign', '175', '175', '400', '463']]\n",
            "Processing complete for file: ok_95-color0-rotate_270.jpg.txt\n",
            "ok_78-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0-rotate_90.jpg.txt\n",
            "oksign 212 273 599 586\n",
            "[['oksign', '212', '273', '599', '586']]\n",
            "Processing complete for file: ok_78-color0-rotate_90.jpg.txt\n",
            "peace_57-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0-rotate_90.jpg.txt\n",
            "peacesign 162 156 497 647\n",
            "[['peacesign', '162', '156', '497', '647']]\n",
            "Processing complete for file: peace_57-color0-rotate_90.jpg.txt\n",
            "ok_19-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0-rotate_180.jpg.txt\n",
            "oksign 644 30 1173 613\n",
            "[['oksign', '644', '30', '1173', '613']]\n",
            "Processing complete for file: ok_19-color0-rotate_180.jpg.txt\n",
            "peace_42-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0-f1.jpg.txt\n",
            "peacesign 1089 407 1399 769\n",
            "[['peacesign', '1089', '407', '1399', '769']]\n",
            "peacesign 114 332 414 738\n",
            "[['peacesign', '1089', '407', '1399', '769'], ['peacesign', '114', '332', '414', '738']]\n",
            "Processing complete for file: peace_42-color0-f1.jpg.txt\n",
            "palm_36-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0-rotate_90.jpg.txt\n",
            "palmhand 67 70 474 279\n",
            "[['palmhand', '67', '70', '474', '279']]\n",
            "Processing complete for file: palm_36-color0-rotate_90.jpg.txt\n",
            "palm_6-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0-rotate_90.jpg.txt\n",
            "palmhand 54 51 647 393\n",
            "[['palmhand', '54', '51', '647', '393']]\n",
            "Processing complete for file: palm_6-color0-rotate_90.jpg.txt\n",
            "palm_25-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0.jpg.txt\n",
            "palmhand 450 177 514 278\n",
            "[['palmhand', '450', '177', '514', '278']]\n",
            "palmhand 325 175 390 275\n",
            "[['palmhand', '450', '177', '514', '278'], ['palmhand', '325', '175', '390', '275']]\n",
            "Processing complete for file: palm_25-color0.jpg.txt\n",
            "peace_40-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0-rotate_90.jpg.txt\n",
            "peacesign 128 250 308 372\n",
            "[['peacesign', '128', '250', '308', '372']]\n",
            "Processing complete for file: peace_40-color0-rotate_90.jpg.txt\n",
            "ok_32-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0-f0.jpg.txt\n",
            "oksign 212 19 459 346\n",
            "[['oksign', '212', '19', '459', '346']]\n",
            "Processing complete for file: ok_32-color0-f0.jpg.txt\n",
            "ok_57-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0-rotate_90.jpg.txt\n",
            "oksign 241 290 612 551\n",
            "[['oksign', '241', '290', '612', '551']]\n",
            "Processing complete for file: ok_57-color0-rotate_90.jpg.txt\n",
            "peace_61-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0-rotate_180.jpg.txt\n",
            "peacesign 190 313 459 648\n",
            "[['peacesign', '190', '313', '459', '648']]\n",
            "Processing complete for file: peace_61-color0-rotate_180.jpg.txt\n",
            "ok_39-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0.jpg.txt\n",
            "oksign 334 54 589 454\n",
            "[['oksign', '334', '54', '589', '454']]\n",
            "Processing complete for file: ok_39-color0.jpg.txt\n",
            "palm_78-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0-f1.jpg.txt\n",
            "palmhand 432 148 679 519\n",
            "[['palmhand', '432', '148', '679', '519']]\n",
            "Processing complete for file: palm_78-color0-f1.jpg.txt\n",
            "ok_68-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0-f1.jpg.txt\n",
            "oksign 582 21 813 373\n",
            "[['oksign', '582', '21', '813', '373']]\n",
            "Processing complete for file: ok_68-color0-f1.jpg.txt\n",
            "ok_83-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0.jpg.txt\n",
            "oksign 576 52 848 356\n",
            "[['oksign', '576', '52', '848', '356']]\n",
            "Processing complete for file: ok_83-color0.jpg.txt\n",
            "palm_16-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0-rotate_90.jpg.txt\n",
            "palmhand 162 305 477 574\n",
            "[['palmhand', '162', '305', '477', '574']]\n",
            "palmhand 140 78 479 297\n",
            "[['palmhand', '162', '305', '477', '574'], ['palmhand', '140', '78', '479', '297']]\n",
            "Processing complete for file: palm_16-color0-rotate_90.jpg.txt\n",
            "palm_84-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0-rotate_180.jpg.txt\n",
            "palmhand 477 220 875 445\n",
            "[['palmhand', '477', '220', '875', '445']]\n",
            "Processing complete for file: palm_84-color0-rotate_180.jpg.txt\n",
            "peace_32-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0-rotate_90.jpg.txt\n",
            "peacesign 96 205 368 357\n",
            "[['peacesign', '96', '205', '368', '357']]\n",
            "Processing complete for file: peace_32-color0-rotate_90.jpg.txt\n",
            "ok_96-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0-f1.jpg.txt\n",
            "oksign 215 125 425 383\n",
            "[['oksign', '215', '125', '425', '383']]\n",
            "Processing complete for file: ok_96-color0-f1.jpg.txt\n",
            "peace_36-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0-f1.jpg.txt\n",
            "peacesign 376 113 584 482\n",
            "[['peacesign', '376', '113', '584', '482']]\n",
            "Processing complete for file: peace_36-color0-f1.jpg.txt\n",
            "ok_21-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0-f1.jpg.txt\n",
            "oksign 215 85 360 299\n",
            "[['oksign', '215', '85', '360', '299']]\n",
            "Processing complete for file: ok_21-color0-f1.jpg.txt\n",
            "peace_93-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0-rotate_270.jpg.txt\n",
            "peacesign 185 453 634 695\n",
            "[['peacesign', '185', '453', '634', '695']]\n",
            "Processing complete for file: peace_93-color0-rotate_270.jpg.txt\n",
            "palm_41-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0-rotate_180.jpg.txt\n",
            "palmhand 381 0 668 375\n",
            "[['palmhand', '381', '0', '668', '375']]\n",
            "palmhand 120 13 376 419\n",
            "[['palmhand', '381', '0', '668', '375'], ['palmhand', '120', '13', '376', '419']]\n",
            "Processing complete for file: palm_41-color0-rotate_180.jpg.txt\n",
            "palm_61-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0-rotate_180.jpg.txt\n",
            "palmhand 211 203 573 574\n",
            "[['palmhand', '211', '203', '573', '574']]\n",
            "Processing complete for file: palm_61-color0-rotate_180.jpg.txt\n",
            "ok_52-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0-f0.jpg.txt\n",
            "oksign 476 203 746 595\n",
            "[['oksign', '476', '203', '746', '595']]\n",
            "Processing complete for file: ok_52-color0-f0.jpg.txt\n",
            "ok_21-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0-rotate_270.jpg.txt\n",
            "oksign 85 215 299 360\n",
            "[['oksign', '85', '215', '299', '360']]\n",
            "Processing complete for file: ok_21-color0-rotate_270.jpg.txt\n",
            "palm_70-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0-f0.jpg.txt\n",
            "palmhand 530 283 921 512\n",
            "[['palmhand', '530', '283', '921', '512']]\n",
            "Processing complete for file: palm_70-color0-f0.jpg.txt\n",
            "peace_88-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0.jpg.txt\n",
            "peacesign 618 161 901 650\n",
            "[['peacesign', '618', '161', '901', '650']]\n",
            "Processing complete for file: peace_88-color0.jpg.txt\n",
            "peace_84-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0-rotate_270.jpg.txt\n",
            "peacesign 92 342 561 646\n",
            "[['peacesign', '92', '342', '561', '646']]\n",
            "Processing complete for file: peace_84-color0-rotate_270.jpg.txt\n",
            "ok_64-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0-f1.jpg.txt\n",
            "oksign 334 260 563 469\n",
            "[['oksign', '334', '260', '563', '469']]\n",
            "Processing complete for file: ok_64-color0-f1.jpg.txt\n",
            "ok_17-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0-rotate_270.jpg.txt\n",
            "oksign 42 88 827 660\n",
            "[['oksign', '42', '88', '827', '660']]\n",
            "Processing complete for file: ok_17-color0-rotate_270.jpg.txt\n",
            "ok_26-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0-rotate_90.jpg.txt\n",
            "oksign 119 220 371 409\n",
            "[['oksign', '119', '220', '371', '409']]\n",
            "Processing complete for file: ok_26-color0-rotate_90.jpg.txt\n",
            "palm_20-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0-f0.jpg.txt\n",
            "palmhand 11 88 265 438\n",
            "[['palmhand', '11', '88', '265', '438']]\n",
            "Processing complete for file: palm_20-color0-f0.jpg.txt\n",
            "peace_86-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0-rotate_180.jpg.txt\n",
            "peacesign 355 130 782 475\n",
            "[['peacesign', '355', '130', '782', '475']]\n",
            "Processing complete for file: peace_86-color0-rotate_180.jpg.txt\n",
            "ok_82-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0-rotate_90.jpg.txt\n",
            "oksign 176 415 562 655\n",
            "[['oksign', '176', '415', '562', '655']]\n",
            "Processing complete for file: ok_82-color0-rotate_90.jpg.txt\n",
            "palm_78-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0-rotate_270.jpg.txt\n",
            "palmhand 148 432 519 679\n",
            "[['palmhand', '148', '432', '519', '679']]\n",
            "Processing complete for file: palm_78-color0-rotate_270.jpg.txt\n",
            "palm_20-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0-f1.jpg.txt\n",
            "palmhand 55 42 309 392\n",
            "[['palmhand', '55', '42', '309', '392']]\n",
            "Processing complete for file: palm_20-color0-f1.jpg.txt\n",
            "ok_25-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0.jpg.txt\n",
            "oksign 1006 376 2106 1663\n",
            "[['oksign', '1006', '376', '2106', '1663']]\n",
            "Processing complete for file: ok_25-color0.jpg.txt\n",
            "ok_47-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0-rotate_270.jpg.txt\n",
            "oksign 239 696 393 820\n",
            "[['oksign', '239', '696', '393', '820']]\n",
            "oksign 267 399 434 551\n",
            "[['oksign', '239', '696', '393', '820'], ['oksign', '267', '399', '434', '551']]\n",
            "Processing complete for file: ok_47-color0-rotate_270.jpg.txt\n",
            "ok_35-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0-f1.jpg.txt\n",
            "oksign 363 230 456 371\n",
            "[['oksign', '363', '230', '456', '371']]\n",
            "Processing complete for file: ok_35-color0-f1.jpg.txt\n",
            "peace_42-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0-rotate_270.jpg.txt\n",
            "peacesign 407 1089 769 1399\n",
            "[['peacesign', '407', '1089', '769', '1399']]\n",
            "peacesign 332 114 738 414\n",
            "[['peacesign', '407', '1089', '769', '1399'], ['peacesign', '332', '114', '738', '414']]\n",
            "Processing complete for file: peace_42-color0-rotate_270.jpg.txt\n",
            "peace_22-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0-rotate_90.jpg.txt\n",
            "peacesign 262 66 1256 911\n",
            "[['peacesign', '262', '66', '1256', '911']]\n",
            "Processing complete for file: peace_22-color0-rotate_90.jpg.txt\n",
            "ok_32-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0-rotate_90.jpg.txt\n",
            "oksign 19 212 346 459\n",
            "[['oksign', '19', '212', '346', '459']]\n",
            "Processing complete for file: ok_32-color0-rotate_90.jpg.txt\n",
            "peace_94-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0-rotate_90.jpg.txt\n",
            "peacesign 99 232 510 465\n",
            "[['peacesign', '99', '232', '510', '465']]\n",
            "Processing complete for file: peace_94-color0-rotate_90.jpg.txt\n",
            "palm_81-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0-rotate_180.jpg.txt\n",
            "palmhand 515 233 923 614\n",
            "[['palmhand', '515', '233', '923', '614']]\n",
            "Processing complete for file: palm_81-color0-rotate_180.jpg.txt\n",
            "peace_63-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0.jpg.txt\n",
            "peacesign 356 156 587 503\n",
            "[['peacesign', '356', '156', '587', '503']]\n",
            "Processing complete for file: peace_63-color0.jpg.txt\n",
            "peace_55-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0-rotate_90.jpg.txt\n",
            "peacesign 110 432 679 923\n",
            "[['peacesign', '110', '432', '679', '923']]\n",
            "Processing complete for file: peace_55-color0-rotate_90.jpg.txt\n",
            "ok_76-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0.jpg.txt\n",
            "oksign 590 114 828 514\n",
            "[['oksign', '590', '114', '828', '514']]\n",
            "Processing complete for file: ok_76-color0.jpg.txt\n",
            "peace_18-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0-f0.jpg.txt\n",
            "peacesign 167 187 489 758\n",
            "[['peacesign', '167', '187', '489', '758']]\n",
            "peacesign 744 112 1077 726\n",
            "[['peacesign', '167', '187', '489', '758'], ['peacesign', '744', '112', '1077', '726']]\n",
            "Processing complete for file: peace_18-color0-f0.jpg.txt\n",
            "ok_8-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0.jpg.txt\n",
            "oksign 75 263 227 442\n",
            "[['oksign', '75', '263', '227', '442']]\n",
            "Processing complete for file: ok_8-color0.jpg.txt\n",
            "ok_96-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0-f0.jpg.txt\n",
            "oksign 655 337 865 595\n",
            "[['oksign', '655', '337', '865', '595']]\n",
            "Processing complete for file: ok_96-color0-f0.jpg.txt\n",
            "peace_81-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0.jpg.txt\n",
            "peacesign 490 163 814 530\n",
            "[['peacesign', '490', '163', '814', '530']]\n",
            "Processing complete for file: peace_81-color0.jpg.txt\n",
            "peace_7-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0-rotate_180.jpg.txt\n",
            "peacesign 61 56 380 626\n",
            "[['peacesign', '61', '56', '380', '626']]\n",
            "Processing complete for file: peace_7-color0-rotate_180.jpg.txt\n",
            "peace_26-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0-f1.jpg.txt\n",
            "peacesign 180 131 678 958\n",
            "[['peacesign', '180', '131', '678', '958']]\n",
            "Processing complete for file: peace_26-color0-f1.jpg.txt\n",
            "peace_6-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0-rotate_270.jpg.txt\n",
            "peacesign 12 91 565 414\n",
            "[['peacesign', '12', '91', '565', '414']]\n",
            "Processing complete for file: peace_6-color0-rotate_270.jpg.txt\n",
            "ok_36-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0-rotate_90.jpg.txt\n",
            "oksign 105 96 265 205\n",
            "[['oksign', '105', '96', '265', '205']]\n",
            "Processing complete for file: ok_36-color0-rotate_90.jpg.txt\n",
            "ok_16-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0-rotate_90.jpg.txt\n",
            "oksign 92 191 926 736\n",
            "[['oksign', '92', '191', '926', '736']]\n",
            "Processing complete for file: ok_16-color0-rotate_90.jpg.txt\n",
            "peace_97-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0-f0.jpg.txt\n",
            "peacesign 438 139 678 622\n",
            "[['peacesign', '438', '139', '678', '622']]\n",
            "Processing complete for file: peace_97-color0-f0.jpg.txt\n",
            "ok_8-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0-rotate_180.jpg.txt\n",
            "oksign 1053 409 1205 588\n",
            "[['oksign', '1053', '409', '1205', '588']]\n",
            "Processing complete for file: ok_8-color0-rotate_180.jpg.txt\n",
            "peace_84-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0-rotate_180.jpg.txt\n",
            "peacesign 342 159 646 628\n",
            "[['peacesign', '342', '159', '646', '628']]\n",
            "Processing complete for file: peace_84-color0-rotate_180.jpg.txt\n",
            "palm_67-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0-f0.jpg.txt\n",
            "palmhand 123 297 428 591\n",
            "[['palmhand', '123', '297', '428', '591']]\n",
            "Processing complete for file: palm_67-color0-f0.jpg.txt\n",
            "palm_62-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0.jpg.txt\n",
            "palmhand 380 60 661 498\n",
            "[['palmhand', '380', '60', '661', '498']]\n",
            "Processing complete for file: palm_62-color0.jpg.txt\n",
            "palm_69-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0-f1.jpg.txt\n",
            "palmhand 373 92 696 410\n",
            "[['palmhand', '373', '92', '696', '410']]\n",
            "Processing complete for file: palm_69-color0-f1.jpg.txt\n",
            "ok_32-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0-f1.jpg.txt\n",
            "oksign 181 14 428 341\n",
            "[['oksign', '181', '14', '428', '341']]\n",
            "Processing complete for file: ok_32-color0-f1.jpg.txt\n",
            "ok_38-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0-f0.jpg.txt\n",
            "oksign 80 4 315 366\n",
            "[['oksign', '80', '4', '315', '366']]\n",
            "Processing complete for file: ok_38-color0-f0.jpg.txt\n",
            "ok_15-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0.jpg.txt\n",
            "oksign 88 11 351 403\n",
            "[['oksign', '88', '11', '351', '403']]\n",
            "Processing complete for file: ok_15-color0.jpg.txt\n",
            "ok_55-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0-f1.jpg.txt\n",
            "oksign 498 93 718 439\n",
            "[['oksign', '498', '93', '718', '439']]\n",
            "Processing complete for file: ok_55-color0-f1.jpg.txt\n",
            "peace_34-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0-rotate_270.jpg.txt\n",
            "peacesign 131 518 407 699\n",
            "[['peacesign', '131', '518', '407', '699']]\n",
            "Processing complete for file: peace_34-color0-rotate_270.jpg.txt\n",
            "palm_81-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0-f1.jpg.txt\n",
            "palmhand 515 106 923 487\n",
            "[['palmhand', '515', '106', '923', '487']]\n",
            "Processing complete for file: palm_81-color0-f1.jpg.txt\n",
            "palm_82-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0.jpg.txt\n",
            "palmhand 444 48 753 544\n",
            "[['palmhand', '444', '48', '753', '544']]\n",
            "Processing complete for file: palm_82-color0.jpg.txt\n",
            "peace_29-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0-rotate_270.jpg.txt\n",
            "peacesign 139 388 1043 848\n",
            "[['peacesign', '139', '388', '1043', '848']]\n",
            "Processing complete for file: peace_29-color0-rotate_270.jpg.txt\n",
            "peace_94-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0-rotate_270.jpg.txt\n",
            "peacesign 210 615 621 848\n",
            "[['peacesign', '210', '615', '621', '848']]\n",
            "Processing complete for file: peace_94-color0-rotate_270.jpg.txt\n",
            "peace_2-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0-f1.jpg.txt\n",
            "peacesign 57 13 418 583\n",
            "[['peacesign', '57', '13', '418', '583']]\n",
            "Processing complete for file: peace_2-color0-f1.jpg.txt\n",
            "palm_15-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0-rotate_180.jpg.txt\n",
            "palmhand 366 37 667 428\n",
            "[['palmhand', '366', '37', '667', '428']]\n",
            "palmhand 46 37 357 428\n",
            "[['palmhand', '366', '37', '667', '428'], ['palmhand', '46', '37', '357', '428']]\n",
            "Processing complete for file: palm_15-color0-rotate_180.jpg.txt\n",
            "ok_72-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0-f1.jpg.txt\n",
            "oksign 367 50 623 408\n",
            "[['oksign', '367', '50', '623', '408']]\n",
            "Processing complete for file: ok_72-color0-f1.jpg.txt\n",
            "ok_59-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0-rotate_180.jpg.txt\n",
            "oksign 404 226 679 606\n",
            "[['oksign', '404', '226', '679', '606']]\n",
            "Processing complete for file: ok_59-color0-rotate_180.jpg.txt\n",
            "ok_65-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0.jpg.txt\n",
            "oksign 469 335 798 558\n",
            "[['oksign', '469', '335', '798', '558']]\n",
            "Processing complete for file: ok_65-color0.jpg.txt\n",
            "peace_76-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0-rotate_180.jpg.txt\n",
            "peacesign 390 70 1004 406\n",
            "[['peacesign', '390', '70', '1004', '406']]\n",
            "Processing complete for file: peace_76-color0-rotate_180.jpg.txt\n",
            "palm_7-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0-rotate_270.jpg.txt\n",
            "palmhand 22 61 699 453\n",
            "[['palmhand', '22', '61', '699', '453']]\n",
            "Processing complete for file: palm_7-color0-rotate_270.jpg.txt\n",
            "ok_55-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0-rotate_270.jpg.txt\n",
            "oksign 93 498 439 718\n",
            "[['oksign', '93', '498', '439', '718']]\n",
            "Processing complete for file: ok_55-color0-rotate_270.jpg.txt\n",
            "peace_70-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0.jpg.txt\n",
            "peacesign 287 76 554 516\n",
            "[['peacesign', '287', '76', '554', '516']]\n",
            "Processing complete for file: peace_70-color0.jpg.txt\n",
            "ok_66-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0-rotate_90.jpg.txt\n",
            "oksign 226 505 451 805\n",
            "[['oksign', '226', '505', '451', '805']]\n",
            "Processing complete for file: ok_66-color0-rotate_90.jpg.txt\n",
            "palm_3-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0-f0.jpg.txt\n",
            "palmhand 72 37 369 569\n",
            "[['palmhand', '72', '37', '369', '569']]\n",
            "Processing complete for file: palm_3-color0-f0.jpg.txt\n",
            "ok_28-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0-rotate_180.jpg.txt\n",
            "oksign 388 168 480 266\n",
            "[['oksign', '388', '168', '480', '266']]\n",
            "oksign 154 175 246 275\n",
            "[['oksign', '388', '168', '480', '266'], ['oksign', '154', '175', '246', '275']]\n",
            "Processing complete for file: ok_28-color0-rotate_180.jpg.txt\n",
            "peace_62-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0-rotate_180.jpg.txt\n",
            "peacesign 279 113 464 457\n",
            "[['peacesign', '279', '113', '464', '457']]\n",
            "Processing complete for file: peace_62-color0-rotate_180.jpg.txt\n",
            "ok_70-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0.jpg.txt\n",
            "oksign 228 81 463 406\n",
            "[['oksign', '228', '81', '463', '406']]\n",
            "Processing complete for file: ok_70-color0.jpg.txt\n",
            "peace_28-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0-rotate_180.jpg.txt\n",
            "peacesign 141 52 226 187\n",
            "[['peacesign', '141', '52', '226', '187']]\n",
            "Processing complete for file: peace_28-color0-rotate_180.jpg.txt\n",
            "ok_38-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0-f1.jpg.txt\n",
            "oksign 69 18 304 380\n",
            "[['oksign', '69', '18', '304', '380']]\n",
            "Processing complete for file: ok_38-color0-f1.jpg.txt\n",
            "ok_14-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0.jpg.txt\n",
            "oksign 172 7 491 407\n",
            "[['oksign', '172', '7', '491', '407']]\n",
            "Processing complete for file: ok_14-color0.jpg.txt\n",
            "ok_16-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0-rotate_180.jpg.txt\n",
            "oksign 288 92 833 926\n",
            "[['oksign', '288', '92', '833', '926']]\n",
            "Processing complete for file: ok_16-color0-rotate_180.jpg.txt\n",
            "palm_65-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0-rotate_270.jpg.txt\n",
            "palmhand 52 432 533 836\n",
            "[['palmhand', '52', '432', '533', '836']]\n",
            "Processing complete for file: palm_65-color0-rotate_270.jpg.txt\n",
            "ok_62-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0-f1.jpg.txt\n",
            "oksign 671 252 898 481\n",
            "[['oksign', '671', '252', '898', '481']]\n",
            "Processing complete for file: ok_62-color0-f1.jpg.txt\n",
            "peace_11-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0-rotate_180.jpg.txt\n",
            "peacesign 67 21 303 445\n",
            "[['peacesign', '67', '21', '303', '445']]\n",
            "Processing complete for file: peace_11-color0-rotate_180.jpg.txt\n",
            "ok_5-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0.jpg.txt\n",
            "oksign 477 209 711 493\n",
            "[['oksign', '477', '209', '711', '493']]\n",
            "Processing complete for file: ok_5-color0.jpg.txt\n",
            "ok_41-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0-rotate_270.jpg.txt\n",
            "oksign 137 281 243 357\n",
            "[['oksign', '137', '281', '243', '357']]\n",
            "oksign 152 33 264 113\n",
            "[['oksign', '137', '281', '243', '357'], ['oksign', '152', '33', '264', '113']]\n",
            "Processing complete for file: ok_41-color0-rotate_270.jpg.txt\n",
            "ok_63-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0-f0.jpg.txt\n",
            "oksign 396 264 621 531\n",
            "[['oksign', '396', '264', '621', '531']]\n",
            "Processing complete for file: ok_63-color0-f0.jpg.txt\n",
            "peace_97-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0.jpg.txt\n",
            "peacesign 438 98 678 581\n",
            "[['peacesign', '438', '98', '678', '581']]\n",
            "Processing complete for file: peace_97-color0.jpg.txt\n",
            "ok_34-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0-f0.jpg.txt\n",
            "oksign 298 99 478 357\n",
            "[['oksign', '298', '99', '478', '357']]\n",
            "Processing complete for file: ok_34-color0-f0.jpg.txt\n",
            "palm_36-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0.jpg.txt\n",
            "palmhand 70 6 279 413\n",
            "[['palmhand', '70', '6', '279', '413']]\n",
            "Processing complete for file: palm_36-color0.jpg.txt\n",
            "palm_96-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0-f1.jpg.txt\n",
            "palmhand 454 108 654 398\n",
            "[['palmhand', '454', '108', '654', '398']]\n",
            "Processing complete for file: palm_96-color0-f1.jpg.txt\n",
            "ok_33-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0-f0.jpg.txt\n",
            "oksign 222 520 579 1033\n",
            "[['oksign', '222', '520', '579', '1033']]\n",
            "Processing complete for file: ok_33-color0-f0.jpg.txt\n",
            "ok_40-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0-f0.jpg.txt\n",
            "oksign 313 459 562 705\n",
            "[['oksign', '313', '459', '562', '705']]\n",
            "Processing complete for file: ok_40-color0-f0.jpg.txt\n",
            "palm_35-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0.jpg.txt\n",
            "palmhand 153 23 557 463\n",
            "[['palmhand', '153', '23', '557', '463']]\n",
            "Processing complete for file: palm_35-color0.jpg.txt\n",
            "peace_65-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0-rotate_90.jpg.txt\n",
            "peacesign 117 421 517 828\n",
            "[['peacesign', '117', '421', '517', '828']]\n",
            "Processing complete for file: peace_65-color0-rotate_90.jpg.txt\n",
            "ok_22-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0-rotate_270.jpg.txt\n",
            "oksign 51 305 435 557\n",
            "[['oksign', '51', '305', '435', '557']]\n",
            "Processing complete for file: ok_22-color0-rotate_270.jpg.txt\n",
            "palm_67-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0-rotate_270.jpg.txt\n",
            "palmhand 129 652 423 957\n",
            "[['palmhand', '129', '652', '423', '957']]\n",
            "Processing complete for file: palm_67-color0-rotate_270.jpg.txt\n",
            "peace_57-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0.jpg.txt\n",
            "peacesign 156 223 647 558\n",
            "[['peacesign', '156', '223', '647', '558']]\n",
            "Processing complete for file: peace_57-color0.jpg.txt\n",
            "palm_55-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0-rotate_90.jpg.txt\n",
            "palmhand 166 507 581 773\n",
            "[['palmhand', '166', '507', '581', '773']]\n",
            "Processing complete for file: palm_55-color0-rotate_90.jpg.txt\n",
            "peace_17-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0-rotate_180.jpg.txt\n",
            "peacesign 656 579 1201 887\n",
            "[['peacesign', '656', '579', '1201', '887']]\n",
            "peacesign 240 57 727 701\n",
            "[['peacesign', '656', '579', '1201', '887'], ['peacesign', '240', '57', '727', '701']]\n",
            "Processing complete for file: peace_17-color0-rotate_180.jpg.txt\n",
            "ok_7-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0-f0.jpg.txt\n",
            "oksign 146 321 422 768\n",
            "[['oksign', '146', '321', '422', '768']]\n",
            "Processing complete for file: ok_7-color0-f0.jpg.txt\n",
            "peace_54-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0-f0.jpg.txt\n",
            "peacesign 472 53 778 677\n",
            "[['peacesign', '472', '53', '778', '677']]\n",
            "Processing complete for file: peace_54-color0-f0.jpg.txt\n",
            "peace_44-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0-f0.jpg.txt\n",
            "peacesign 42 178 143 357\n",
            "[['peacesign', '42', '178', '143', '357']]\n",
            "Processing complete for file: peace_44-color0-f0.jpg.txt\n",
            "palm_33-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0-f1.jpg.txt\n",
            "palmhand 220 129 342 329\n",
            "[['palmhand', '220', '129', '342', '329']]\n",
            "palmhand 369 151 517 335\n",
            "[['palmhand', '220', '129', '342', '329'], ['palmhand', '369', '151', '517', '335']]\n",
            "Processing complete for file: palm_33-color0-f1.jpg.txt\n",
            "peace_62-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0-f0.jpg.txt\n",
            "peacesign 616 113 801 457\n",
            "[['peacesign', '616', '113', '801', '457']]\n",
            "Processing complete for file: peace_62-color0-f0.jpg.txt\n",
            "palm_45-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0.jpg.txt\n",
            "palmhand 222 84 610 439\n",
            "[['palmhand', '222', '84', '610', '439']]\n",
            "Processing complete for file: palm_45-color0.jpg.txt\n",
            "palm_9-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0.jpg.txt\n",
            "palmhand 43 19 352 580\n",
            "[['palmhand', '43', '19', '352', '580']]\n",
            "Processing complete for file: palm_9-color0.jpg.txt\n",
            "peace_24-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0-f1.jpg.txt\n",
            "peacesign 562 240 754 595\n",
            "[['peacesign', '562', '240', '754', '595']]\n",
            "Processing complete for file: peace_24-color0-f1.jpg.txt\n",
            "ok_58-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0-rotate_90.jpg.txt\n",
            "oksign 233 467 566 736\n",
            "[['oksign', '233', '467', '566', '736']]\n",
            "Processing complete for file: ok_58-color0-rotate_90.jpg.txt\n",
            "palm_20-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0-rotate_270.jpg.txt\n",
            "palmhand 42 55 392 309\n",
            "[['palmhand', '42', '55', '392', '309']]\n",
            "Processing complete for file: palm_20-color0-rotate_270.jpg.txt\n",
            "palm_91-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0.jpg.txt\n",
            "palmhand 511 73 730 398\n",
            "[['palmhand', '511', '73', '730', '398']]\n",
            "Processing complete for file: palm_91-color0.jpg.txt\n",
            "peace_52-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0-rotate_90.jpg.txt\n",
            "peacesign 68 305 662 750\n",
            "[['peacesign', '68', '305', '662', '750']]\n",
            "Processing complete for file: peace_52-color0-rotate_90.jpg.txt\n",
            "palm_22-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0-rotate_180.jpg.txt\n",
            "palmhand 315 66 569 411\n",
            "[['palmhand', '315', '66', '569', '411']]\n",
            "palmhand 68 69 310 414\n",
            "[['palmhand', '315', '66', '569', '411'], ['palmhand', '68', '69', '310', '414']]\n",
            "Processing complete for file: palm_22-color0-rotate_180.jpg.txt\n",
            "peace_55-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0-rotate_180.jpg.txt\n",
            "peacesign 157 110 648 679\n",
            "[['peacesign', '157', '110', '648', '679']]\n",
            "Processing complete for file: peace_55-color0-rotate_180.jpg.txt\n",
            "palm_32-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0-rotate_270.jpg.txt\n",
            "palmhand 14 223 452 465\n",
            "[['palmhand', '14', '223', '452', '465']]\n",
            "Processing complete for file: palm_32-color0-rotate_270.jpg.txt\n",
            "peace_20-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0.jpg.txt\n",
            "peacesign 213 138 823 667\n",
            "[['peacesign', '213', '138', '823', '667']]\n",
            "Processing complete for file: peace_20-color0.jpg.txt\n",
            "ok_67-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0-f0.jpg.txt\n",
            "oksign 451 289 705 606\n",
            "[['oksign', '451', '289', '705', '606']]\n",
            "Processing complete for file: ok_67-color0-f0.jpg.txt\n",
            "ok_91-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0-rotate_180.jpg.txt\n",
            "oksign 425 281 690 508\n",
            "[['oksign', '425', '281', '690', '508']]\n",
            "Processing complete for file: ok_91-color0-rotate_180.jpg.txt\n",
            "ok_86-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0-f0.jpg.txt\n",
            "oksign 526 233 719 447\n",
            "[['oksign', '526', '233', '719', '447']]\n",
            "Processing complete for file: ok_86-color0-f0.jpg.txt\n",
            "peace_23-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0-rotate_90.jpg.txt\n",
            "peacesign 56 299 815 767\n",
            "[['peacesign', '56', '299', '815', '767']]\n",
            "Processing complete for file: peace_23-color0-rotate_90.jpg.txt\n",
            "peace_61-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0.jpg.txt\n",
            "peacesign 621 72 890 407\n",
            "[['peacesign', '621', '72', '890', '407']]\n",
            "Processing complete for file: peace_61-color0.jpg.txt\n",
            "peace_77-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0-f1.jpg.txt\n",
            "peacesign 426 116 926 650\n",
            "[['peacesign', '426', '116', '926', '650']]\n",
            "Processing complete for file: peace_77-color0-f1.jpg.txt\n",
            "peace_24-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0.jpg.txt\n",
            "peacesign 526 240 718 595\n",
            "[['peacesign', '526', '240', '718', '595']]\n",
            "Processing complete for file: peace_24-color0.jpg.txt\n",
            "ok_87-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0-rotate_270.jpg.txt\n",
            "oksign 279 440 519 654\n",
            "[['oksign', '279', '440', '519', '654']]\n",
            "Processing complete for file: ok_87-color0-rotate_270.jpg.txt\n",
            "peace_70-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0-f0.jpg.txt\n",
            "peacesign 287 204 554 644\n",
            "[['peacesign', '287', '204', '554', '644']]\n",
            "Processing complete for file: peace_70-color0-f0.jpg.txt\n",
            "palm_36-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0-f0.jpg.txt\n",
            "palmhand 70 67 279 474\n",
            "[['palmhand', '70', '67', '279', '474']]\n",
            "Processing complete for file: palm_36-color0-f0.jpg.txt\n",
            "palm_3-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0-rotate_180.jpg.txt\n",
            "palmhand 102 37 399 569\n",
            "[['palmhand', '102', '37', '399', '569']]\n",
            "Processing complete for file: palm_3-color0-rotate_180.jpg.txt\n",
            "palm_55-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0-f1.jpg.txt\n",
            "palmhand 307 139 573 554\n",
            "[['palmhand', '307', '139', '573', '554']]\n",
            "Processing complete for file: palm_55-color0-f1.jpg.txt\n",
            "ok_47-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0-rotate_180.jpg.txt\n",
            "oksign 696 207 820 361\n",
            "[['oksign', '696', '207', '820', '361']]\n",
            "oksign 399 166 551 333\n",
            "[['oksign', '696', '207', '820', '361'], ['oksign', '399', '166', '551', '333']]\n",
            "Processing complete for file: ok_47-color0-rotate_180.jpg.txt\n",
            "ok_26-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0-rotate_180.jpg.txt\n",
            "oksign 206 119 395 371\n",
            "[['oksign', '206', '119', '395', '371']]\n",
            "Processing complete for file: ok_26-color0-rotate_180.jpg.txt\n",
            "palm_87-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0-rotate_90.jpg.txt\n",
            "palmhand 299 517 670 742\n",
            "[['palmhand', '299', '517', '670', '742']]\n",
            "Processing complete for file: palm_87-color0-rotate_90.jpg.txt\n",
            "palm_7-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0-rotate_180.jpg.txt\n",
            "palmhand 61 0 453 677\n",
            "[['palmhand', '61', '0', '453', '677']]\n",
            "Processing complete for file: palm_7-color0-rotate_180.jpg.txt\n",
            "peace_77-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0.jpg.txt\n",
            "peacesign 154 116 654 650\n",
            "[['peacesign', '154', '116', '654', '650']]\n",
            "Processing complete for file: peace_77-color0.jpg.txt\n",
            "palm_37-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0-f1.jpg.txt\n",
            "palmhand 52 14 326 443\n",
            "[['palmhand', '52', '14', '326', '443']]\n",
            "Processing complete for file: palm_37-color0-f1.jpg.txt\n",
            "ok_23-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0.jpg.txt\n",
            "oksign 120 132 339 444\n",
            "[['oksign', '120', '132', '339', '444']]\n",
            "Processing complete for file: ok_23-color0.jpg.txt\n",
            "palm_37-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0-rotate_270.jpg.txt\n",
            "palmhand 14 52 443 326\n",
            "[['palmhand', '14', '52', '443', '326']]\n",
            "Processing complete for file: palm_37-color0-rotate_270.jpg.txt\n",
            "peace_35-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0-f1.jpg.txt\n",
            "peacesign 625 281 737 491\n",
            "[['peacesign', '625', '281', '737', '491']]\n",
            "Processing complete for file: peace_35-color0-f1.jpg.txt\n",
            "palm_27-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0-f0.jpg.txt\n",
            "palmhand 54 16 320 450\n",
            "[['palmhand', '54', '16', '320', '450']]\n",
            "Processing complete for file: palm_27-color0-f0.jpg.txt\n",
            "peace_20-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0-rotate_270.jpg.txt\n",
            "peacesign 138 457 667 1067\n",
            "[['peacesign', '138', '457', '667', '1067']]\n",
            "Processing complete for file: peace_20-color0-rotate_270.jpg.txt\n",
            "peace_30-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0.jpg.txt\n",
            "peacesign 24 96 115 249\n",
            "[['peacesign', '24', '96', '115', '249']]\n",
            "Processing complete for file: peace_30-color0.jpg.txt\n",
            "ok_58-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0-f0.jpg.txt\n",
            "oksign 467 233 736 566\n",
            "[['oksign', '467', '233', '736', '566']]\n",
            "Processing complete for file: ok_58-color0-f0.jpg.txt\n",
            "peace_10-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0-rotate_90.jpg.txt\n",
            "peacesign 37 45 650 374\n",
            "[['peacesign', '37', '45', '650', '374']]\n",
            "Processing complete for file: peace_10-color0-rotate_90.jpg.txt\n",
            "peace_5-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0-f1.jpg.txt\n",
            "peacesign 92 10 407 573\n",
            "[['peacesign', '92', '10', '407', '573']]\n",
            "Processing complete for file: peace_5-color0-f1.jpg.txt\n",
            "ok_54-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0-rotate_90.jpg.txt\n",
            "oksign 287 296 612 530\n",
            "[['oksign', '287', '296', '612', '530']]\n",
            "Processing complete for file: ok_54-color0-rotate_90.jpg.txt\n",
            "ok_1-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0-f1.jpg.txt\n",
            "oksign 803 123 984 355\n",
            "[['oksign', '803', '123', '984', '355']]\n",
            "Processing complete for file: ok_1-color0-f1.jpg.txt\n",
            "peace_64-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0-rotate_90.jpg.txt\n",
            "peacesign 97 396 353 870\n",
            "[['peacesign', '97', '396', '353', '870']]\n",
            "Processing complete for file: peace_64-color0-rotate_90.jpg.txt\n",
            "peace_93-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0-rotate_180.jpg.txt\n",
            "peacesign 453 86 695 535\n",
            "[['peacesign', '453', '86', '695', '535']]\n",
            "Processing complete for file: peace_93-color0-rotate_180.jpg.txt\n",
            "peace_78-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0-rotate_270.jpg.txt\n",
            "peacesign 116 397 621 679\n",
            "[['peacesign', '116', '397', '621', '679']]\n",
            "Processing complete for file: peace_78-color0-rotate_270.jpg.txt\n",
            "palm_90-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0-rotate_180.jpg.txt\n",
            "palmhand 250 295 536 606\n",
            "[['palmhand', '250', '295', '536', '606']]\n",
            "Processing complete for file: palm_90-color0-rotate_180.jpg.txt\n",
            "peace_22-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0.jpg.txt\n",
            "peacesign 66 24 911 1018\n",
            "[['peacesign', '66', '24', '911', '1018']]\n",
            "Processing complete for file: peace_22-color0.jpg.txt\n",
            "palm_83-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0-f0.jpg.txt\n",
            "palmhand 498 278 723 526\n",
            "[['palmhand', '498', '278', '723', '526']]\n",
            "Processing complete for file: palm_83-color0-f0.jpg.txt\n",
            "palm_61-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0-f1.jpg.txt\n",
            "palmhand 211 146 573 517\n",
            "[['palmhand', '211', '146', '573', '517']]\n",
            "Processing complete for file: palm_61-color0-f1.jpg.txt\n",
            "ok_18-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0-rotate_90.jpg.txt\n",
            "oksign 9 212 227 356\n",
            "[['oksign', '9', '212', '227', '356']]\n",
            "oksign 3 439 184 625\n",
            "[['oksign', '9', '212', '227', '356'], ['oksign', '3', '439', '184', '625']]\n",
            "Processing complete for file: ok_18-color0-rotate_90.jpg.txt\n",
            "ok_93-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0.jpg.txt\n",
            "oksign 696 244 998 435\n",
            "[['oksign', '696', '244', '998', '435']]\n",
            "Processing complete for file: ok_93-color0.jpg.txt\n",
            "palm_84-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0-rotate_90.jpg.txt\n",
            "palmhand 220 205 445 603\n",
            "[['palmhand', '220', '205', '445', '603']]\n",
            "Processing complete for file: palm_84-color0-rotate_90.jpg.txt\n",
            "ok_31-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0-rotate_90.jpg.txt\n",
            "oksign 14 230 333 435\n",
            "[['oksign', '14', '230', '333', '435']]\n",
            "Processing complete for file: ok_31-color0-rotate_90.jpg.txt\n",
            "peace_95-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0.jpg.txt\n",
            "peacesign 434 107 705 554\n",
            "[['peacesign', '434', '107', '705', '554']]\n",
            "Processing complete for file: peace_95-color0.jpg.txt\n",
            "peace_69-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0-rotate_270.jpg.txt\n",
            "peacesign 200 503 591 898\n",
            "[['peacesign', '200', '503', '591', '898']]\n",
            "Processing complete for file: peace_69-color0-rotate_270.jpg.txt\n",
            "peace_39-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0-f0.jpg.txt\n",
            "peacesign 60 21 268 357\n",
            "[['peacesign', '60', '21', '268', '357']]\n",
            "Processing complete for file: peace_39-color0-f0.jpg.txt\n",
            "palm_38-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0.jpg.txt\n",
            "palmhand 34 27 317 444\n",
            "[['palmhand', '34', '27', '317', '444']]\n",
            "Processing complete for file: palm_38-color0.jpg.txt\n",
            "ok_1-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0-f0.jpg.txt\n",
            "oksign 296 499 477 731\n",
            "[['oksign', '296', '499', '477', '731']]\n",
            "Processing complete for file: ok_1-color0-f0.jpg.txt\n",
            "ok_3-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0-rotate_180.jpg.txt\n",
            "oksign 166 402 366 626\n",
            "[['oksign', '166', '402', '366', '626']]\n",
            "Processing complete for file: ok_3-color0-rotate_180.jpg.txt\n",
            "ok_81-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0-rotate_90.jpg.txt\n",
            "oksign 106 484 501 751\n",
            "[['oksign', '106', '484', '501', '751']]\n",
            "Processing complete for file: ok_81-color0-rotate_90.jpg.txt\n",
            "peace_27-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0-rotate_90.jpg.txt\n",
            "peacesign 258 197 590 367\n",
            "[['peacesign', '258', '197', '590', '367']]\n",
            "Processing complete for file: peace_27-color0-rotate_90.jpg.txt\n",
            "palm_3-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0-rotate_90.jpg.txt\n",
            "palmhand 37 72 569 369\n",
            "[['palmhand', '37', '72', '569', '369']]\n",
            "Processing complete for file: palm_3-color0-rotate_90.jpg.txt\n",
            "peace_85-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0-rotate_270.jpg.txt\n",
            "peacesign 41 88 558 442\n",
            "[['peacesign', '41', '88', '558', '442']]\n",
            "Processing complete for file: peace_85-color0-rotate_270.jpg.txt\n",
            "peace_56-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0-rotate_180.jpg.txt\n",
            "peacesign 513 102 770 542\n",
            "[['peacesign', '513', '102', '770', '542']]\n",
            "Processing complete for file: peace_56-color0-rotate_180.jpg.txt\n",
            "peace_53-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0-rotate_180.jpg.txt\n",
            "peacesign 324 17 755 624\n",
            "[['peacesign', '324', '17', '755', '624']]\n",
            "Processing complete for file: peace_53-color0-rotate_180.jpg.txt\n",
            "palm_96-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0-rotate_90.jpg.txt\n",
            "palmhand 322 426 612 626\n",
            "[['palmhand', '322', '426', '612', '626']]\n",
            "Processing complete for file: palm_96-color0-rotate_90.jpg.txt\n",
            "palm_92-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0-f1.jpg.txt\n",
            "palmhand 467 119 661 408\n",
            "[['palmhand', '467', '119', '661', '408']]\n",
            "Processing complete for file: palm_92-color0-f1.jpg.txt\n",
            "palm_31-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0-f1.jpg.txt\n",
            "palmhand 31 166 583 428\n",
            "[['palmhand', '31', '166', '583', '428']]\n",
            "Processing complete for file: palm_31-color0-f1.jpg.txt\n",
            "peace_66-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0-rotate_180.jpg.txt\n",
            "peacesign 384 148 615 613\n",
            "[['peacesign', '384', '148', '615', '613']]\n",
            "Processing complete for file: peace_66-color0-rotate_180.jpg.txt\n",
            "peace_33-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0-rotate_180.jpg.txt\n",
            "peacesign 588 189 664 311\n",
            "[['peacesign', '588', '189', '664', '311']]\n",
            "peacesign 326 231 393 355\n",
            "[['peacesign', '588', '189', '664', '311'], ['peacesign', '326', '231', '393', '355']]\n",
            "Processing complete for file: peace_33-color0-rotate_180.jpg.txt\n",
            "ok_13-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0-rotate_180.jpg.txt\n",
            "oksign 79 220 323 540\n",
            "[['oksign', '79', '220', '323', '540']]\n",
            "Processing complete for file: ok_13-color0-rotate_180.jpg.txt\n",
            "palm_27-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0-rotate_270.jpg.txt\n",
            "palmhand 30 400 464 666\n",
            "[['palmhand', '30', '400', '464', '666']]\n",
            "Processing complete for file: palm_27-color0-rotate_270.jpg.txt\n",
            "ok_56-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0-rotate_180.jpg.txt\n",
            "oksign 590 247 850 620\n",
            "[['oksign', '590', '247', '850', '620']]\n",
            "Processing complete for file: ok_56-color0-rotate_180.jpg.txt\n",
            "ok_63-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0-rotate_180.jpg.txt\n",
            "oksign 459 264 684 531\n",
            "[['oksign', '459', '264', '684', '531']]\n",
            "Processing complete for file: ok_63-color0-rotate_180.jpg.txt\n",
            "ok_68-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0-f0.jpg.txt\n",
            "oksign 267 347 498 699\n",
            "[['oksign', '267', '347', '498', '699']]\n",
            "Processing complete for file: ok_68-color0-f0.jpg.txt\n",
            "peace_30-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0-rotate_270.jpg.txt\n",
            "peacesign 96 435 249 526\n",
            "[['peacesign', '96', '435', '249', '526']]\n",
            "Processing complete for file: peace_30-color0-rotate_270.jpg.txt\n",
            "palm_14-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0-rotate_270.jpg.txt\n",
            "palmhand 112 64 381 460\n",
            "[['palmhand', '112', '64', '381', '460']]\n",
            "Processing complete for file: palm_14-color0-rotate_270.jpg.txt\n",
            "ok_92-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0-rotate_180.jpg.txt\n",
            "oksign 336 287 559 578\n",
            "[['oksign', '336', '287', '559', '578']]\n",
            "Processing complete for file: ok_92-color0-rotate_180.jpg.txt\n",
            "peace_37-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0.jpg.txt\n",
            "peacesign 643 138 922 575\n",
            "[['peacesign', '643', '138', '922', '575']]\n",
            "Processing complete for file: peace_37-color0.jpg.txt\n",
            "palm_31-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0-rotate_270.jpg.txt\n",
            "palmhand 166 31 428 583\n",
            "[['palmhand', '166', '31', '428', '583']]\n",
            "Processing complete for file: palm_31-color0-rotate_270.jpg.txt\n",
            "palm_63-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0.jpg.txt\n",
            "palmhand 138 364 657 664\n",
            "[['palmhand', '138', '364', '657', '664']]\n",
            "Processing complete for file: palm_63-color0.jpg.txt\n",
            "palm_25-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0-rotate_90.jpg.txt\n",
            "palmhand 202 450 303 514\n",
            "[['palmhand', '202', '450', '303', '514']]\n",
            "palmhand 205 325 305 390\n",
            "[['palmhand', '202', '450', '303', '514'], ['palmhand', '205', '325', '305', '390']]\n",
            "Processing complete for file: palm_25-color0-rotate_90.jpg.txt\n",
            "ok_66-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0.jpg.txt\n",
            "oksign 505 269 805 494\n",
            "[['oksign', '505', '269', '805', '494']]\n",
            "Processing complete for file: ok_66-color0.jpg.txt\n",
            "ok_20-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0-f1.jpg.txt\n",
            "oksign 160 62 368 382\n",
            "[['oksign', '160', '62', '368', '382']]\n",
            "Processing complete for file: ok_20-color0-f1.jpg.txt\n",
            "ok_5-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0-rotate_270.jpg.txt\n",
            "oksign 209 569 493 803\n",
            "[['oksign', '209', '569', '493', '803']]\n",
            "Processing complete for file: ok_5-color0-rotate_270.jpg.txt\n",
            "ok_78-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0-f1.jpg.txt\n",
            "oksign 494 121 807 508\n",
            "[['oksign', '494', '121', '807', '508']]\n",
            "Processing complete for file: ok_78-color0-f1.jpg.txt\n",
            "peace_81-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0-rotate_270.jpg.txt\n",
            "peacesign 163 266 530 590\n",
            "[['peacesign', '163', '266', '530', '590']]\n",
            "Processing complete for file: peace_81-color0-rotate_270.jpg.txt\n",
            "peace_13-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0-rotate_270.jpg.txt\n",
            "peacesign 13 46 466 294\n",
            "[['peacesign', '13', '46', '466', '294']]\n",
            "Processing complete for file: peace_13-color0-rotate_270.jpg.txt\n",
            "peace_24-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0-rotate_90.jpg.txt\n",
            "peacesign 258 526 613 718\n",
            "[['peacesign', '258', '526', '613', '718']]\n",
            "Processing complete for file: peace_24-color0-rotate_90.jpg.txt\n",
            "palm_80-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0-rotate_180.jpg.txt\n",
            "palmhand 92 183 384 683\n",
            "[['palmhand', '92', '183', '384', '683']]\n",
            "Processing complete for file: palm_80-color0-rotate_180.jpg.txt\n",
            "peace_58-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0-rotate_90.jpg.txt\n",
            "peacesign 104 470 595 932\n",
            "[['peacesign', '104', '470', '595', '932']]\n",
            "Processing complete for file: peace_58-color0-rotate_90.jpg.txt\n",
            "palm_83-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0.jpg.txt\n",
            "palmhand 498 194 723 442\n",
            "[['palmhand', '498', '194', '723', '442']]\n",
            "Processing complete for file: palm_83-color0.jpg.txt\n",
            "palm_59-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0-rotate_270.jpg.txt\n",
            "palmhand 394 127 635 542\n",
            "[['palmhand', '394', '127', '635', '542']]\n",
            "Processing complete for file: palm_59-color0-rotate_270.jpg.txt\n",
            "palm_79-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0-rotate_180.jpg.txt\n",
            "palmhand 569 156 779 516\n",
            "[['palmhand', '569', '156', '779', '516']]\n",
            "Processing complete for file: palm_79-color0-rotate_180.jpg.txt\n",
            "palm_59-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0-rotate_180.jpg.txt\n",
            "palmhand 127 85 542 326\n",
            "[['palmhand', '127', '85', '542', '326']]\n",
            "Processing complete for file: palm_59-color0-rotate_180.jpg.txt\n",
            "peace_35-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0-f0.jpg.txt\n",
            "peacesign 463 309 575 519\n",
            "[['peacesign', '463', '309', '575', '519']]\n",
            "Processing complete for file: peace_35-color0-f0.jpg.txt\n",
            "peace_72-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0-rotate_270.jpg.txt\n",
            "peacesign 104 521 539 852\n",
            "[['peacesign', '104', '521', '539', '852']]\n",
            "Processing complete for file: peace_72-color0-rotate_270.jpg.txt\n",
            "peace_76-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0-rotate_270.jpg.txt\n",
            "peacesign 314 390 650 1004\n",
            "[['peacesign', '314', '390', '650', '1004']]\n",
            "Processing complete for file: peace_76-color0-rotate_270.jpg.txt\n",
            "ok_56-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0-rotate_90.jpg.txt\n",
            "oksign 247 230 620 490\n",
            "[['oksign', '247', '230', '620', '490']]\n",
            "Processing complete for file: ok_56-color0-rotate_90.jpg.txt\n",
            "ok_66-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0-f1.jpg.txt\n",
            "oksign 275 269 575 494\n",
            "[['oksign', '275', '269', '575', '494']]\n",
            "Processing complete for file: ok_66-color0-f1.jpg.txt\n",
            "ok_55-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_55-color0-f0.jpg.txt\n",
            "oksign 362 281 582 627\n",
            "[['oksign', '362', '281', '582', '627']]\n",
            "Processing complete for file: ok_55-color0-f0.jpg.txt\n",
            "palm_15-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0-rotate_90.jpg.txt\n",
            "palmhand 37 54 428 355\n",
            "[['palmhand', '37', '54', '428', '355']]\n",
            "palmhand 37 364 428 675\n",
            "[['palmhand', '37', '54', '428', '355'], ['palmhand', '37', '364', '428', '675']]\n",
            "Processing complete for file: palm_15-color0-rotate_90.jpg.txt\n",
            "palm_70-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0-rotate_180.jpg.txt\n",
            "palmhand 159 283 550 512\n",
            "[['palmhand', '159', '283', '550', '512']]\n",
            "Processing complete for file: palm_70-color0-rotate_180.jpg.txt\n",
            "peace_59-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0-rotate_90.jpg.txt\n",
            "peacesign 162 436 495 987\n",
            "[['peacesign', '162', '436', '495', '987']]\n",
            "Processing complete for file: peace_59-color0-rotate_90.jpg.txt\n",
            "palm_86-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0-rotate_270.jpg.txt\n",
            "palmhand 100 400 419 719\n",
            "[['palmhand', '100', '400', '419', '719']]\n",
            "Processing complete for file: palm_86-color0-rotate_270.jpg.txt\n",
            "ok_92-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0-f1.jpg.txt\n",
            "oksign 336 142 559 433\n",
            "[['oksign', '336', '142', '559', '433']]\n",
            "Processing complete for file: ok_92-color0-f1.jpg.txt\n",
            "peace_65-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0-rotate_180.jpg.txt\n",
            "peacesign 252 117 659 517\n",
            "[['peacesign', '252', '117', '659', '517']]\n",
            "Processing complete for file: peace_65-color0-rotate_180.jpg.txt\n",
            "palm_5-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0-f0.jpg.txt\n",
            "palmhand 72 19 378 568\n",
            "[['palmhand', '72', '19', '378', '568']]\n",
            "Processing complete for file: palm_5-color0-f0.jpg.txt\n",
            "palm_19-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0.jpg.txt\n",
            "palmhand 82 1 494 401\n",
            "[['palmhand', '82', '1', '494', '401']]\n",
            "Processing complete for file: palm_19-color0.jpg.txt\n",
            "peace_24-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0-rotate_270.jpg.txt\n",
            "peacesign 240 562 595 754\n",
            "[['peacesign', '240', '562', '595', '754']]\n",
            "Processing complete for file: peace_24-color0-rotate_270.jpg.txt\n",
            "ok_57-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0-rotate_270.jpg.txt\n",
            "oksign 108 529 479 790\n",
            "[['oksign', '108', '529', '479', '790']]\n",
            "Processing complete for file: ok_57-color0-rotate_270.jpg.txt\n",
            "peace_21-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0-rotate_270.jpg.txt\n",
            "peacesign 155 793 639 1033\n",
            "[['peacesign', '155', '793', '639', '1033']]\n",
            "Processing complete for file: peace_21-color0-rotate_270.jpg.txt\n",
            "palm_61-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0.jpg.txt\n",
            "palmhand 507 146 869 517\n",
            "[['palmhand', '507', '146', '869', '517']]\n",
            "Processing complete for file: palm_61-color0.jpg.txt\n",
            "peace_44-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0-rotate_270.jpg.txt\n",
            "peacesign 243 564 422 665\n",
            "[['peacesign', '243', '564', '422', '665']]\n",
            "Processing complete for file: peace_44-color0-rotate_270.jpg.txt\n",
            "peace_91-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0-f0.jpg.txt\n",
            "peacesign 112 115 501 535\n",
            "[['peacesign', '112', '115', '501', '535']]\n",
            "Processing complete for file: peace_91-color0-f0.jpg.txt\n",
            "ok_71-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_71-color0-f1.jpg.txt\n",
            "oksign 525 50 759 402\n",
            "[['oksign', '525', '50', '759', '402']]\n",
            "Processing complete for file: ok_71-color0-f1.jpg.txt\n",
            "palm_27-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0-rotate_90.jpg.txt\n",
            "palmhand 16 54 450 320\n",
            "[['palmhand', '16', '54', '450', '320']]\n",
            "Processing complete for file: palm_27-color0-rotate_90.jpg.txt\n",
            "ok_17-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0-f0.jpg.txt\n",
            "oksign 215 197 787 982\n",
            "[['oksign', '215', '197', '787', '982']]\n",
            "Processing complete for file: ok_17-color0-f0.jpg.txt\n",
            "peace_44-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0-rotate_180.jpg.txt\n",
            "peacesign 564 178 665 357\n",
            "[['peacesign', '564', '178', '665', '357']]\n",
            "Processing complete for file: peace_44-color0-rotate_180.jpg.txt\n",
            "peace_8-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0.jpg.txt\n",
            "peacesign 23 8 341 577\n",
            "[['peacesign', '23', '8', '341', '577']]\n",
            "Processing complete for file: peace_8-color0.jpg.txt\n",
            "palm_3-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0.jpg.txt\n",
            "palmhand 72 50 369 582\n",
            "[['palmhand', '72', '50', '369', '582']]\n",
            "Processing complete for file: palm_3-color0.jpg.txt\n",
            "peace_77-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0-rotate_270.jpg.txt\n",
            "peacesign 116 426 650 926\n",
            "[['peacesign', '116', '426', '650', '926']]\n",
            "Processing complete for file: peace_77-color0-rotate_270.jpg.txt\n",
            "peace_22-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0-rotate_180.jpg.txt\n",
            "peacesign 47 262 892 1256\n",
            "[['peacesign', '47', '262', '892', '1256']]\n",
            "Processing complete for file: peace_22-color0-rotate_180.jpg.txt\n",
            "peace_41-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0-f0.jpg.txt\n",
            "peacesign 391 27 568 343\n",
            "[['peacesign', '391', '27', '568', '343']]\n",
            "Processing complete for file: peace_41-color0-f0.jpg.txt\n",
            "ok_67-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0-f1.jpg.txt\n",
            "oksign 375 114 629 431\n",
            "[['oksign', '375', '114', '629', '431']]\n",
            "Processing complete for file: ok_67-color0-f1.jpg.txt\n",
            "peace_67-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0-f0.jpg.txt\n",
            "peacesign 254 170 645 597\n",
            "[['peacesign', '254', '170', '645', '597']]\n",
            "Processing complete for file: peace_67-color0-f0.jpg.txt\n",
            "palm_93-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0.jpg.txt\n",
            "palmhand 594 144 801 335\n",
            "[['palmhand', '594', '144', '801', '335']]\n",
            "Processing complete for file: palm_93-color0.jpg.txt\n",
            "palm_92-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0-f0.jpg.txt\n",
            "palmhand 419 312 613 601\n",
            "[['palmhand', '419', '312', '613', '601']]\n",
            "Processing complete for file: palm_92-color0-f0.jpg.txt\n",
            "peace_34-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0-rotate_180.jpg.txt\n",
            "peacesign 518 313 699 589\n",
            "[['peacesign', '518', '313', '699', '589']]\n",
            "Processing complete for file: peace_34-color0-rotate_180.jpg.txt\n",
            "palm_96-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0-rotate_180.jpg.txt\n",
            "palmhand 454 322 654 612\n",
            "[['palmhand', '454', '322', '654', '612']]\n",
            "Processing complete for file: palm_96-color0-rotate_180.jpg.txt\n",
            "palm_17-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0-f1.jpg.txt\n",
            "palmhand 199 172 514 345\n",
            "[['palmhand', '199', '172', '514', '345']]\n",
            "Processing complete for file: palm_17-color0-f1.jpg.txt\n",
            "ok_85-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0-f1.jpg.txt\n",
            "oksign 223 231 415 483\n",
            "[['oksign', '223', '231', '415', '483']]\n",
            "Processing complete for file: ok_85-color0-f1.jpg.txt\n",
            "palm_59-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0.jpg.txt\n",
            "palmhand 538 394 953 635\n",
            "[['palmhand', '538', '394', '953', '635']]\n",
            "Processing complete for file: palm_59-color0.jpg.txt\n",
            "palm_13-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0-rotate_180.jpg.txt\n",
            "palmhand 282 166 585 697\n",
            "[['palmhand', '282', '166', '585', '697']]\n",
            "palmhand 591 100 925 652\n",
            "[['palmhand', '282', '166', '585', '697'], ['palmhand', '591', '100', '925', '652']]\n",
            "Processing complete for file: palm_13-color0-rotate_180.jpg.txt\n",
            "peace_67-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0-f1.jpg.txt\n",
            "peacesign 435 123 826 550\n",
            "[['peacesign', '435', '123', '826', '550']]\n",
            "Processing complete for file: peace_67-color0-f1.jpg.txt\n",
            "palm_72-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0.jpg.txt\n",
            "palmhand 265 196 513 471\n",
            "[['palmhand', '265', '196', '513', '471']]\n",
            "Processing complete for file: palm_72-color0.jpg.txt\n",
            "peace_58-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0-rotate_180.jpg.txt\n",
            "peacesign 148 104 610 595\n",
            "[['peacesign', '148', '104', '610', '595']]\n",
            "Processing complete for file: peace_58-color0-rotate_180.jpg.txt\n",
            "palm_42-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0-f1.jpg.txt\n",
            "palmhand 151 166 388 303\n",
            "[['palmhand', '151', '166', '388', '303']]\n",
            "Processing complete for file: palm_42-color0-f1.jpg.txt\n",
            "peace_72-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0.jpg.txt\n",
            "peacesign 228 104 559 539\n",
            "[['peacesign', '228', '104', '559', '539']]\n",
            "Processing complete for file: peace_72-color0.jpg.txt\n",
            "palm_36-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0-rotate_270.jpg.txt\n",
            "palmhand 6 81 413 290\n",
            "[['palmhand', '6', '81', '413', '290']]\n",
            "Processing complete for file: palm_36-color0-rotate_270.jpg.txt\n",
            "peace_90-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0-rotate_270.jpg.txt\n",
            "peacesign 147 462 598 722\n",
            "[['peacesign', '147', '462', '598', '722']]\n",
            "Processing complete for file: peace_90-color0-rotate_270.jpg.txt\n",
            "ok_15-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0-f1.jpg.txt\n",
            "oksign 129 11 392 403\n",
            "[['oksign', '129', '11', '392', '403']]\n",
            "Processing complete for file: ok_15-color0-f1.jpg.txt\n",
            "palm_44-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0-rotate_90.jpg.txt\n",
            "palmhand 41 29 415 581\n",
            "[['palmhand', '41', '29', '415', '581']]\n",
            "Processing complete for file: palm_44-color0-rotate_90.jpg.txt\n",
            "palm_3-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_3-color0-f1.jpg.txt\n",
            "palmhand 102 50 399 582\n",
            "[['palmhand', '102', '50', '399', '582']]\n",
            "Processing complete for file: palm_3-color0-f1.jpg.txt\n",
            "peace_78-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0.jpg.txt\n",
            "peacesign 401 116 683 621\n",
            "[['peacesign', '401', '116', '683', '621']]\n",
            "Processing complete for file: peace_78-color0.jpg.txt\n",
            "ok_25-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0-rotate_270.jpg.txt\n",
            "oksign 376 1126 1663 2226\n",
            "[['oksign', '376', '1126', '1663', '2226']]\n",
            "Processing complete for file: ok_25-color0-rotate_270.jpg.txt\n",
            "ok_17-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0-rotate_90.jpg.txt\n",
            "oksign 197 215 982 787\n",
            "[['oksign', '197', '215', '982', '787']]\n",
            "Processing complete for file: ok_17-color0-rotate_90.jpg.txt\n",
            "ok_52-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0-rotate_90.jpg.txt\n",
            "oksign 203 476 595 746\n",
            "[['oksign', '203', '476', '595', '746']]\n",
            "Processing complete for file: ok_52-color0-rotate_90.jpg.txt\n",
            "peace_23-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0-f1.jpg.txt\n",
            "peacesign 513 40 981 799\n",
            "[['peacesign', '513', '40', '981', '799']]\n",
            "Processing complete for file: peace_23-color0-f1.jpg.txt\n",
            "peace_33-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0.jpg.txt\n",
            "peacesign 56 94 132 216\n",
            "[['peacesign', '56', '94', '132', '216']]\n",
            "peacesign 327 50 394 174\n",
            "[['peacesign', '56', '94', '132', '216'], ['peacesign', '327', '50', '394', '174']]\n",
            "Processing complete for file: peace_33-color0.jpg.txt\n",
            "peace_37-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0-f1.jpg.txt\n",
            "peacesign 262 138 541 575\n",
            "[['peacesign', '262', '138', '541', '575']]\n",
            "Processing complete for file: peace_37-color0-f1.jpg.txt\n",
            "peace_21-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0-rotate_180.jpg.txt\n",
            "peacesign 793 214 1033 698\n",
            "[['peacesign', '793', '214', '1033', '698']]\n",
            "Processing complete for file: peace_21-color0-rotate_180.jpg.txt\n",
            "palm_88-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0-f0.jpg.txt\n",
            "palmhand 607 197 978 401\n",
            "[['palmhand', '607', '197', '978', '401']]\n",
            "Processing complete for file: palm_88-color0-f0.jpg.txt\n",
            "palm_56-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0-rotate_270.jpg.txt\n",
            "palmhand 108 313 521 582\n",
            "[['palmhand', '108', '313', '521', '582']]\n",
            "Processing complete for file: palm_56-color0-rotate_270.jpg.txt\n",
            "ok_22-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0-f1.jpg.txt\n",
            "oksign 305 51 557 435\n",
            "[['oksign', '305', '51', '557', '435']]\n",
            "Processing complete for file: ok_22-color0-f1.jpg.txt\n",
            "palm_69-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0-f0.jpg.txt\n",
            "palmhand 384 310 707 628\n",
            "[['palmhand', '384', '310', '707', '628']]\n",
            "Processing complete for file: palm_69-color0-f0.jpg.txt\n",
            "palm_80-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0-f1.jpg.txt\n",
            "palmhand 92 37 384 537\n",
            "[['palmhand', '92', '37', '384', '537']]\n",
            "Processing complete for file: palm_80-color0-f1.jpg.txt\n",
            "ok_79-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0-rotate_270.jpg.txt\n",
            "oksign 158 534 531 809\n",
            "[['oksign', '158', '534', '531', '809']]\n",
            "Processing complete for file: ok_79-color0-rotate_270.jpg.txt\n",
            "peace_96-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0-f0.jpg.txt\n",
            "peacesign 310 159 547 642\n",
            "[['peacesign', '310', '159', '547', '642']]\n",
            "Processing complete for file: peace_96-color0-f0.jpg.txt\n",
            "palm_26-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0-rotate_270.jpg.txt\n",
            "palmhand 23 72 424 277\n",
            "[['palmhand', '23', '72', '424', '277']]\n",
            "Processing complete for file: palm_26-color0-rotate_270.jpg.txt\n",
            "palm_78-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0-rotate_90.jpg.txt\n",
            "palmhand 201 401 572 648\n",
            "[['palmhand', '201', '401', '572', '648']]\n",
            "Processing complete for file: palm_78-color0-rotate_90.jpg.txt\n",
            "peace_13-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0-rotate_90.jpg.txt\n",
            "peacesign 21 53 474 301\n",
            "[['peacesign', '21', '53', '474', '301']]\n",
            "Processing complete for file: peace_13-color0-rotate_90.jpg.txt\n",
            "palm_24-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0-rotate_270.jpg.txt\n",
            "palmhand 8 292 480 602\n",
            "[['palmhand', '8', '292', '480', '602']]\n",
            "Processing complete for file: palm_24-color0-rotate_270.jpg.txt\n",
            "ok_66-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0-rotate_270.jpg.txt\n",
            "oksign 269 275 494 575\n",
            "[['oksign', '269', '275', '494', '575']]\n",
            "Processing complete for file: ok_66-color0-rotate_270.jpg.txt\n",
            "palm_85-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0.jpg.txt\n",
            "palmhand 242 223 603 475\n",
            "[['palmhand', '242', '223', '603', '475']]\n",
            "Processing complete for file: palm_85-color0.jpg.txt\n",
            "palm_91-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0-f0.jpg.txt\n",
            "palmhand 511 322 730 647\n",
            "[['palmhand', '511', '322', '730', '647']]\n",
            "Processing complete for file: palm_91-color0-f0.jpg.txt\n",
            "ok_90-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0.jpg.txt\n",
            "oksign 323 302 588 504\n",
            "[['oksign', '323', '302', '588', '504']]\n",
            "Processing complete for file: ok_90-color0.jpg.txt\n",
            "peace_64-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0.jpg.txt\n",
            "peacesign 396 367 870 623\n",
            "[['peacesign', '396', '367', '870', '623']]\n",
            "Processing complete for file: peace_64-color0.jpg.txt\n",
            "peace_85-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0-f1.jpg.txt\n",
            "peacesign 88 41 442 558\n",
            "[['peacesign', '88', '41', '442', '558']]\n",
            "Processing complete for file: peace_85-color0-f1.jpg.txt\n",
            "peace_20-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0-f0.jpg.txt\n",
            "peacesign 213 184 823 713\n",
            "[['peacesign', '213', '184', '823', '713']]\n",
            "Processing complete for file: peace_20-color0-f0.jpg.txt\n",
            "ok_56-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0-f1.jpg.txt\n",
            "oksign 590 100 850 473\n",
            "[['oksign', '590', '100', '850', '473']]\n",
            "Processing complete for file: ok_56-color0-f1.jpg.txt\n",
            "ok_9-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0-f1.jpg.txt\n",
            "oksign 405 442 539 600\n",
            "[['oksign', '405', '442', '539', '600']]\n",
            "Processing complete for file: ok_9-color0-f1.jpg.txt\n",
            "ok_23-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0-f0.jpg.txt\n",
            "oksign 120 168 339 480\n",
            "[['oksign', '120', '168', '339', '480']]\n",
            "Processing complete for file: ok_23-color0-f0.jpg.txt\n",
            "ok_18-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0-rotate_270.jpg.txt\n",
            "oksign 144 304 362 448\n",
            "[['oksign', '144', '304', '362', '448']]\n",
            "oksign 187 35 368 221\n",
            "[['oksign', '144', '304', '362', '448'], ['oksign', '187', '35', '368', '221']]\n",
            "Processing complete for file: ok_18-color0-rotate_270.jpg.txt\n",
            "peace_52-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0-rotate_180.jpg.txt\n",
            "peacesign 330 68 775 662\n",
            "[['peacesign', '330', '68', '775', '662']]\n",
            "Processing complete for file: peace_52-color0-rotate_180.jpg.txt\n",
            "peace_96-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0-rotate_180.jpg.txt\n",
            "peacesign 533 159 770 642\n",
            "[['peacesign', '533', '159', '770', '642']]\n",
            "Processing complete for file: peace_96-color0-rotate_180.jpg.txt\n",
            "palm_32-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0-f1.jpg.txt\n",
            "palmhand 223 14 465 452\n",
            "[['palmhand', '223', '14', '465', '452']]\n",
            "Processing complete for file: palm_32-color0-f1.jpg.txt\n",
            "peace_82-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0.jpg.txt\n",
            "peacesign 592 307 992 587\n",
            "[['peacesign', '592', '307', '992', '587']]\n",
            "Processing complete for file: peace_82-color0.jpg.txt\n",
            "palm_10-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0.jpg.txt\n",
            "palmhand 41 23 345 564\n",
            "[['palmhand', '41', '23', '345', '564']]\n",
            "Processing complete for file: palm_10-color0.jpg.txt\n",
            "peace_21-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0-rotate_90.jpg.txt\n",
            "peacesign 214 247 698 487\n",
            "[['peacesign', '214', '247', '698', '487']]\n",
            "Processing complete for file: peace_21-color0-rotate_90.jpg.txt\n",
            "ok_91-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0-f1.jpg.txt\n",
            "oksign 425 212 690 439\n",
            "[['oksign', '425', '212', '690', '439']]\n",
            "Processing complete for file: ok_91-color0-f1.jpg.txt\n",
            "palm_4-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_4-color0-rotate_90.jpg.txt\n",
            "palmhand 8 58 579 371\n",
            "[['palmhand', '8', '58', '579', '371']]\n",
            "Processing complete for file: palm_4-color0-rotate_90.jpg.txt\n",
            "peace_36-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0.jpg.txt\n",
            "peacesign 416 113 624 482\n",
            "[['peacesign', '416', '113', '624', '482']]\n",
            "Processing complete for file: peace_36-color0.jpg.txt\n",
            "ok_85-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0-f0.jpg.txt\n",
            "oksign 665 237 857 489\n",
            "[['oksign', '665', '237', '857', '489']]\n",
            "Processing complete for file: ok_85-color0-f0.jpg.txt\n",
            "peace_79-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0-rotate_270.jpg.txt\n",
            "peacesign 123 142 563 535\n",
            "[['peacesign', '123', '142', '563', '535']]\n",
            "Processing complete for file: peace_79-color0-rotate_270.jpg.txt\n",
            "ok_28-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0-f1.jpg.txt\n",
            "oksign 388 66 480 164\n",
            "[['oksign', '388', '66', '480', '164']]\n",
            "oksign 154 57 246 157\n",
            "[['oksign', '388', '66', '480', '164'], ['oksign', '154', '57', '246', '157']]\n",
            "Processing complete for file: ok_28-color0-f1.jpg.txt\n",
            "ok_76-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0-rotate_180.jpg.txt\n",
            "oksign 252 206 490 606\n",
            "[['oksign', '252', '206', '490', '606']]\n",
            "Processing complete for file: ok_76-color0-rotate_180.jpg.txt\n",
            "ok_35-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0-rotate_180.jpg.txt\n",
            "oksign 363 7 456 148\n",
            "[['oksign', '363', '7', '456', '148']]\n",
            "Processing complete for file: ok_35-color0-rotate_180.jpg.txt\n",
            "ok_54-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0.jpg.txt\n",
            "oksign 296 108 530 433\n",
            "[['oksign', '296', '108', '530', '433']]\n",
            "Processing complete for file: ok_54-color0.jpg.txt\n",
            "peace_80-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0-rotate_270.jpg.txt\n",
            "peacesign 187 497 563 713\n",
            "[['peacesign', '187', '497', '563', '713']]\n",
            "Processing complete for file: peace_80-color0-rotate_270.jpg.txt\n",
            "palm_78-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0.jpg.txt\n",
            "palmhand 401 148 648 519\n",
            "[['palmhand', '401', '148', '648', '519']]\n",
            "Processing complete for file: palm_78-color0.jpg.txt\n",
            "palm_35-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0-rotate_270.jpg.txt\n",
            "palmhand 23 83 463 487\n",
            "[['palmhand', '23', '83', '463', '487']]\n",
            "Processing complete for file: palm_35-color0-rotate_270.jpg.txt\n",
            "palm_33-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0.jpg.txt\n",
            "palmhand 378 129 500 329\n",
            "[['palmhand', '378', '129', '500', '329']]\n",
            "palmhand 203 151 351 335\n",
            "[['palmhand', '378', '129', '500', '329'], ['palmhand', '203', '151', '351', '335']]\n",
            "Processing complete for file: palm_33-color0.jpg.txt\n",
            "ok_20-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0-rotate_180.jpg.txt\n",
            "oksign 160 147 368 467\n",
            "[['oksign', '160', '147', '368', '467']]\n",
            "Processing complete for file: ok_20-color0-rotate_180.jpg.txt\n",
            "ok_60-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0-rotate_90.jpg.txt\n",
            "oksign 197 376 635 659\n",
            "[['oksign', '197', '376', '635', '659']]\n",
            "Processing complete for file: ok_60-color0-rotate_90.jpg.txt\n",
            "peace_26-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0-rotate_90.jpg.txt\n",
            "peacesign 322 175 1149 673\n",
            "[['peacesign', '322', '175', '1149', '673']]\n",
            "Processing complete for file: peace_26-color0-rotate_90.jpg.txt\n",
            "ok_36-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0-rotate_270.jpg.txt\n",
            "oksign 87 235 247 344\n",
            "[['oksign', '87', '235', '247', '344']]\n",
            "Processing complete for file: ok_36-color0-rotate_270.jpg.txt\n",
            "palm_30-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0-rotate_180.jpg.txt\n",
            "palmhand 119 35 394 474\n",
            "[['palmhand', '119', '35', '394', '474']]\n",
            "Processing complete for file: palm_30-color0-rotate_180.jpg.txt\n",
            "palm_86-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0-rotate_180.jpg.txt\n",
            "palmhand 400 301 719 620\n",
            "[['palmhand', '400', '301', '719', '620']]\n",
            "Processing complete for file: palm_86-color0-rotate_180.jpg.txt\n",
            "palm_59-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0-f1.jpg.txt\n",
            "palmhand 127 394 542 635\n",
            "[['palmhand', '127', '394', '542', '635']]\n",
            "Processing complete for file: palm_59-color0-f1.jpg.txt\n",
            "ok_47-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0.jpg.txt\n",
            "oksign 80 239 204 393\n",
            "[['oksign', '80', '239', '204', '393']]\n",
            "oksign 349 267 501 434\n",
            "[['oksign', '80', '239', '204', '393'], ['oksign', '349', '267', '501', '434']]\n",
            "Processing complete for file: ok_47-color0.jpg.txt\n",
            "palm_28-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0-rotate_270.jpg.txt\n",
            "palmhand 194 51 437 591\n",
            "[['palmhand', '194', '51', '437', '591']]\n",
            "Processing complete for file: palm_28-color0-rotate_270.jpg.txt\n",
            "palm_64-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0-f1.jpg.txt\n",
            "palmhand 407 217 888 596\n",
            "[['palmhand', '407', '217', '888', '596']]\n",
            "Processing complete for file: palm_64-color0-f1.jpg.txt\n",
            "peace_6-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0-f1.jpg.txt\n",
            "peacesign 91 12 414 565\n",
            "[['peacesign', '91', '12', '414', '565']]\n",
            "Processing complete for file: peace_6-color0-f1.jpg.txt\n",
            "peace_30-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0-rotate_180.jpg.txt\n",
            "peacesign 435 301 526 454\n",
            "[['peacesign', '435', '301', '526', '454']]\n",
            "Processing complete for file: peace_30-color0-rotate_180.jpg.txt\n",
            "peace_7-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0.jpg.txt\n",
            "peacesign 47 1 366 571\n",
            "[['peacesign', '47', '1', '366', '571']]\n",
            "Processing complete for file: peace_7-color0.jpg.txt\n",
            "peace_7-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0-f0.jpg.txt\n",
            "peacesign 47 56 366 626\n",
            "[['peacesign', '47', '56', '366', '626']]\n",
            "Processing complete for file: peace_7-color0-f0.jpg.txt\n",
            "ok_32-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0-rotate_180.jpg.txt\n",
            "oksign 181 19 428 346\n",
            "[['oksign', '181', '19', '428', '346']]\n",
            "Processing complete for file: ok_32-color0-rotate_180.jpg.txt\n",
            "palm_93-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0-rotate_270.jpg.txt\n",
            "palmhand 144 279 335 486\n",
            "[['palmhand', '144', '279', '335', '486']]\n",
            "Processing complete for file: palm_93-color0-rotate_270.jpg.txt\n",
            "palm_45-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0-rotate_270.jpg.txt\n",
            "palmhand 84 114 439 502\n",
            "[['palmhand', '84', '114', '439', '502']]\n",
            "Processing complete for file: palm_45-color0-rotate_270.jpg.txt\n",
            "ok_4-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0-f1.jpg.txt\n",
            "oksign 784 197 953 386\n",
            "[['oksign', '784', '197', '953', '386']]\n",
            "Processing complete for file: ok_4-color0-f1.jpg.txt\n",
            "palm_71-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0-rotate_90.jpg.txt\n",
            "palmhand 197 148 458 407\n",
            "[['palmhand', '197', '148', '458', '407']]\n",
            "Processing complete for file: palm_71-color0-rotate_90.jpg.txt\n",
            "peace_17-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0-rotate_270.jpg.txt\n",
            "peacesign 73 656 381 1201\n",
            "[['peacesign', '73', '656', '381', '1201']]\n",
            "peacesign 259 240 903 727\n",
            "[['peacesign', '73', '656', '381', '1201'], ['peacesign', '259', '240', '903', '727']]\n",
            "Processing complete for file: peace_17-color0-rotate_270.jpg.txt\n",
            "ok_83-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0-rotate_90.jpg.txt\n",
            "oksign 364 576 668 848\n",
            "[['oksign', '364', '576', '668', '848']]\n",
            "Processing complete for file: ok_83-color0-rotate_90.jpg.txt\n",
            "peace_76-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0-f0.jpg.txt\n",
            "peacesign 76 70 690 406\n",
            "[['peacesign', '76', '70', '690', '406']]\n",
            "Processing complete for file: peace_76-color0-f0.jpg.txt\n",
            "peace_82-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0-rotate_90.jpg.txt\n",
            "peacesign 133 592 413 992\n",
            "[['peacesign', '133', '592', '413', '992']]\n",
            "Processing complete for file: peace_82-color0-rotate_90.jpg.txt\n",
            "ok_40-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0.jpg.txt\n",
            "oksign 313 161 562 407\n",
            "[['oksign', '313', '161', '562', '407']]\n",
            "Processing complete for file: ok_40-color0.jpg.txt\n",
            "palm_94-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0-f1.jpg.txt\n",
            "palmhand 202 131 465 402\n",
            "[['palmhand', '202', '131', '465', '402']]\n",
            "Processing complete for file: palm_94-color0-f1.jpg.txt\n",
            "ok_34-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0-rotate_270.jpg.txt\n",
            "oksign 104 72 362 252\n",
            "[['oksign', '104', '72', '362', '252']]\n",
            "Processing complete for file: ok_34-color0-rotate_270.jpg.txt\n",
            "peace_10-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0.jpg.txt\n",
            "peacesign 45 9 374 622\n",
            "[['peacesign', '45', '9', '374', '622']]\n",
            "Processing complete for file: peace_10-color0.jpg.txt\n",
            "peace_33-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0-f0.jpg.txt\n",
            "peacesign 56 189 132 311\n",
            "[['peacesign', '56', '189', '132', '311']]\n",
            "peacesign 327 231 394 355\n",
            "[['peacesign', '56', '189', '132', '311'], ['peacesign', '327', '231', '394', '355']]\n",
            "Processing complete for file: peace_33-color0-f0.jpg.txt\n",
            "ok_64-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0-rotate_270.jpg.txt\n",
            "oksign 260 334 469 563\n",
            "[['oksign', '260', '334', '469', '563']]\n",
            "Processing complete for file: ok_64-color0-rotate_270.jpg.txt\n",
            "ok_68-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0-rotate_90.jpg.txt\n",
            "oksign 347 267 699 498\n",
            "[['oksign', '347', '267', '699', '498']]\n",
            "Processing complete for file: ok_68-color0-rotate_90.jpg.txt\n",
            "palm_10-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0-rotate_90.jpg.txt\n",
            "palmhand 43 41 584 345\n",
            "[['palmhand', '43', '41', '584', '345']]\n",
            "Processing complete for file: palm_10-color0-rotate_90.jpg.txt\n",
            "ok_7-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0-rotate_90.jpg.txt\n",
            "oksign 321 146 768 422\n",
            "[['oksign', '321', '146', '768', '422']]\n",
            "Processing complete for file: ok_7-color0-rotate_90.jpg.txt\n",
            "palm_45-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0-rotate_90.jpg.txt\n",
            "palmhand 41 222 396 610\n",
            "[['palmhand', '41', '222', '396', '610']]\n",
            "Processing complete for file: palm_45-color0-rotate_90.jpg.txt\n",
            "palm_9-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0-f0.jpg.txt\n",
            "palmhand 43 33 352 594\n",
            "[['palmhand', '43', '33', '352', '594']]\n",
            "Processing complete for file: palm_9-color0-f0.jpg.txt\n",
            "ok_62-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0.jpg.txt\n",
            "oksign 182 252 409 481\n",
            "[['oksign', '182', '252', '409', '481']]\n",
            "Processing complete for file: ok_62-color0.jpg.txt\n",
            "ok_79-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0.jpg.txt\n",
            "oksign 271 158 546 531\n",
            "[['oksign', '271', '158', '546', '531']]\n",
            "Processing complete for file: ok_79-color0.jpg.txt\n",
            "palm_31-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0.jpg.txt\n",
            "palmhand 57 166 609 428\n",
            "[['palmhand', '57', '166', '609', '428']]\n",
            "Processing complete for file: palm_31-color0.jpg.txt\n",
            "ok_21-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0.jpg.txt\n",
            "oksign 252 85 397 299\n",
            "[['oksign', '252', '85', '397', '299']]\n",
            "Processing complete for file: ok_21-color0.jpg.txt\n",
            "ok_82-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0.jpg.txt\n",
            "oksign 415 158 655 544\n",
            "[['oksign', '415', '158', '655', '544']]\n",
            "Processing complete for file: ok_82-color0.jpg.txt\n",
            "palm_60-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0.jpg.txt\n",
            "palmhand 540 337 963 606\n",
            "[['palmhand', '540', '337', '963', '606']]\n",
            "Processing complete for file: palm_60-color0.jpg.txt\n",
            "palm_79-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0-rotate_270.jpg.txt\n",
            "palmhand 204 569 564 779\n",
            "[['palmhand', '204', '569', '564', '779']]\n",
            "Processing complete for file: palm_79-color0-rotate_270.jpg.txt\n",
            "ok_10-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0-f1.jpg.txt\n",
            "oksign 251 47 727 665\n",
            "[['oksign', '251', '47', '727', '665']]\n",
            "Processing complete for file: ok_10-color0-f1.jpg.txt\n",
            "peace_26-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0-f0.jpg.txt\n",
            "peacesign 175 322 673 1149\n",
            "[['peacesign', '175', '322', '673', '1149']]\n",
            "Processing complete for file: peace_26-color0-f0.jpg.txt\n",
            "peace_41-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0-rotate_270.jpg.txt\n",
            "peacesign 57 232 373 409\n",
            "[['peacesign', '57', '232', '373', '409']]\n",
            "Processing complete for file: peace_41-color0-rotate_270.jpg.txt\n",
            "peace_39-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0-rotate_180.jpg.txt\n",
            "peacesign 344 21 552 357\n",
            "[['peacesign', '344', '21', '552', '357']]\n",
            "Processing complete for file: peace_39-color0-rotate_180.jpg.txt\n",
            "palm_68-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0-rotate_90.jpg.txt\n",
            "palmhand 308 253 639 486\n",
            "[['palmhand', '308', '253', '639', '486']]\n",
            "Processing complete for file: palm_68-color0-rotate_90.jpg.txt\n",
            "palm_43-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0-f1.jpg.txt\n",
            "palmhand 63 113 412 351\n",
            "[['palmhand', '63', '113', '412', '351']]\n",
            "Processing complete for file: palm_43-color0-f1.jpg.txt\n",
            "ok_19-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0-f1.jpg.txt\n",
            "oksign 644 19 1173 602\n",
            "[['oksign', '644', '19', '1173', '602']]\n",
            "Processing complete for file: ok_19-color0-f1.jpg.txt\n",
            "ok_69-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0-f1.jpg.txt\n",
            "oksign 709 167 1004 442\n",
            "[['oksign', '709', '167', '1004', '442']]\n",
            "Processing complete for file: ok_69-color0-f1.jpg.txt\n",
            "ok_17-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_17-color0-rotate_180.jpg.txt\n",
            "oksign 88 197 660 982\n",
            "[['oksign', '88', '197', '660', '982']]\n",
            "Processing complete for file: ok_17-color0-rotate_180.jpg.txt\n",
            "ok_40-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0-rotate_180.jpg.txt\n",
            "oksign 738 459 987 705\n",
            "[['oksign', '738', '459', '987', '705']]\n",
            "Processing complete for file: ok_40-color0-rotate_180.jpg.txt\n",
            "ok_39-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0-rotate_270.jpg.txt\n",
            "oksign 54 311 454 566\n",
            "[['oksign', '54', '311', '454', '566']]\n",
            "Processing complete for file: ok_39-color0-rotate_270.jpg.txt\n",
            "palm_36-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0-rotate_180.jpg.txt\n",
            "palmhand 81 67 290 474\n",
            "[['palmhand', '81', '67', '290', '474']]\n",
            "Processing complete for file: palm_36-color0-rotate_180.jpg.txt\n",
            "palm_42-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0.jpg.txt\n",
            "palmhand 332 166 569 303\n",
            "[['palmhand', '332', '166', '569', '303']]\n",
            "Processing complete for file: palm_42-color0.jpg.txt\n",
            "ok_21-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0-rotate_180.jpg.txt\n",
            "oksign 215 109 360 323\n",
            "[['oksign', '215', '109', '360', '323']]\n",
            "Processing complete for file: ok_21-color0-rotate_180.jpg.txt\n",
            "ok_59-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0-f1.jpg.txt\n",
            "oksign 404 114 679 494\n",
            "[['oksign', '404', '114', '679', '494']]\n",
            "Processing complete for file: ok_59-color0-f1.jpg.txt\n",
            "peace_22-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0-f0.jpg.txt\n",
            "peacesign 66 262 911 1256\n",
            "[['peacesign', '66', '262', '911', '1256']]\n",
            "Processing complete for file: peace_22-color0-f0.jpg.txt\n",
            "peace_3-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0-f1.jpg.txt\n",
            "peacesign 84 26 400 583\n",
            "[['peacesign', '84', '26', '400', '583']]\n",
            "Processing complete for file: peace_3-color0-f1.jpg.txt\n",
            "peace_34-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0-f1.jpg.txt\n",
            "peacesign 518 131 699 407\n",
            "[['peacesign', '518', '131', '699', '407']]\n",
            "Processing complete for file: peace_34-color0-f1.jpg.txt\n",
            "peace_39-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0-f1.jpg.txt\n",
            "peacesign 344 51 552 387\n",
            "[['peacesign', '344', '51', '552', '387']]\n",
            "Processing complete for file: peace_39-color0-f1.jpg.txt\n",
            "ok_97-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0-rotate_270.jpg.txt\n",
            "oksign 75 292 381 500\n",
            "[['oksign', '75', '292', '381', '500']]\n",
            "Processing complete for file: ok_97-color0-rotate_270.jpg.txt\n",
            "peace_57-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0-rotate_180.jpg.txt\n",
            "peacesign 433 162 924 497\n",
            "[['peacesign', '433', '162', '924', '497']]\n",
            "Processing complete for file: peace_57-color0-rotate_180.jpg.txt\n",
            "palm_81-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0-f0.jpg.txt\n",
            "palmhand 157 233 565 614\n",
            "[['palmhand', '157', '233', '565', '614']]\n",
            "Processing complete for file: palm_81-color0-f0.jpg.txt\n",
            "peace_27-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0-rotate_270.jpg.txt\n",
            "peacesign 160 169 492 339\n",
            "[['peacesign', '160', '169', '492', '339']]\n",
            "Processing complete for file: peace_27-color0-rotate_270.jpg.txt\n",
            "palm_18-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0-rotate_270.jpg.txt\n",
            "palmhand 95 35 409 605\n",
            "[['palmhand', '95', '35', '409', '605']]\n",
            "Processing complete for file: palm_18-color0-rotate_270.jpg.txt\n",
            "palm_80-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0-rotate_270.jpg.txt\n",
            "palmhand 37 92 537 384\n",
            "[['palmhand', '37', '92', '537', '384']]\n",
            "Processing complete for file: palm_80-color0-rotate_270.jpg.txt\n",
            "palm_85-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0-rotate_270.jpg.txt\n",
            "palmhand 223 477 475 838\n",
            "[['palmhand', '223', '477', '475', '838']]\n",
            "Processing complete for file: palm_85-color0-rotate_270.jpg.txt\n",
            "peace_32-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_32-color0-f0.jpg.txt\n",
            "peacesign 205 96 357 368\n",
            "[['peacesign', '205', '96', '357', '368']]\n",
            "Processing complete for file: peace_32-color0-f0.jpg.txt\n",
            "ok_13-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0-f1.jpg.txt\n",
            "oksign 79 72 323 392\n",
            "[['oksign', '79', '72', '323', '392']]\n",
            "Processing complete for file: ok_13-color0-f1.jpg.txt\n",
            "peace_61-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0-rotate_270.jpg.txt\n",
            "peacesign 72 190 407 459\n",
            "[['peacesign', '72', '190', '407', '459']]\n",
            "Processing complete for file: peace_61-color0-rotate_270.jpg.txt\n",
            "palm_25-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0-f1.jpg.txt\n",
            "palmhand 253 177 317 278\n",
            "[['palmhand', '253', '177', '317', '278']]\n",
            "palmhand 377 175 442 275\n",
            "[['palmhand', '253', '177', '317', '278'], ['palmhand', '377', '175', '442', '275']]\n",
            "Processing complete for file: palm_25-color0-f1.jpg.txt\n",
            "ok_77-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0-rotate_180.jpg.txt\n",
            "oksign 357 183 632 603\n",
            "[['oksign', '357', '183', '632', '603']]\n",
            "Processing complete for file: ok_77-color0-rotate_180.jpg.txt\n",
            "ok_87-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0-f0.jpg.txt\n",
            "oksign 426 201 640 441\n",
            "[['oksign', '426', '201', '640', '441']]\n",
            "Processing complete for file: ok_87-color0-f0.jpg.txt\n",
            "ok_20-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0.jpg.txt\n",
            "oksign 244 62 452 382\n",
            "[['oksign', '244', '62', '452', '382']]\n",
            "Processing complete for file: ok_20-color0.jpg.txt\n",
            "ok_8-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0-f1.jpg.txt\n",
            "oksign 1053 263 1205 442\n",
            "[['oksign', '1053', '263', '1205', '442']]\n",
            "Processing complete for file: ok_8-color0-f1.jpg.txt\n",
            "palm_52-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0-rotate_180.jpg.txt\n",
            "palmhand 259 110 654 653\n",
            "[['palmhand', '259', '110', '654', '653']]\n",
            "Processing complete for file: palm_52-color0-rotate_180.jpg.txt\n",
            "palm_39-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0-f0.jpg.txt\n",
            "palmhand 38 25 331 473\n",
            "[['palmhand', '38', '25', '331', '473']]\n",
            "Processing complete for file: palm_39-color0-f0.jpg.txt\n",
            "palm_54-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0.jpg.txt\n",
            "palmhand 305 39 644 585\n",
            "[['palmhand', '305', '39', '644', '585']]\n",
            "Processing complete for file: palm_54-color0.jpg.txt\n",
            "ok_97-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0-rotate_90.jpg.txt\n",
            "oksign 339 580 645 788\n",
            "[['oksign', '339', '580', '645', '788']]\n",
            "Processing complete for file: ok_97-color0-rotate_90.jpg.txt\n",
            "peace_68-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0-rotate_180.jpg.txt\n",
            "peacesign 488 164 933 375\n",
            "[['peacesign', '488', '164', '933', '375']]\n",
            "Processing complete for file: peace_68-color0-rotate_180.jpg.txt\n",
            "peace_10-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0-f1.jpg.txt\n",
            "peacesign 85 9 414 622\n",
            "[['peacesign', '85', '9', '414', '622']]\n",
            "Processing complete for file: peace_10-color0-f1.jpg.txt\n",
            "palm_94-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0-rotate_270.jpg.txt\n",
            "palmhand 131 202 402 465\n",
            "[['palmhand', '131', '202', '402', '465']]\n",
            "Processing complete for file: palm_94-color0-rotate_270.jpg.txt\n",
            "peace_79-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0-f0.jpg.txt\n",
            "peacesign 545 157 938 597\n",
            "[['peacesign', '545', '157', '938', '597']]\n",
            "Processing complete for file: peace_79-color0-f0.jpg.txt\n",
            "peace_43-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0-f0.jpg.txt\n",
            "peacesign 155 105 594 920\n",
            "[['peacesign', '155', '105', '594', '920']]\n",
            "Processing complete for file: peace_43-color0-f0.jpg.txt\n",
            "ok_64-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0-rotate_180.jpg.txt\n",
            "oksign 334 251 563 460\n",
            "[['oksign', '334', '251', '563', '460']]\n",
            "Processing complete for file: ok_64-color0-rotate_180.jpg.txt\n",
            "peace_90-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0-rotate_180.jpg.txt\n",
            "peacesign 462 122 722 573\n",
            "[['peacesign', '462', '122', '722', '573']]\n",
            "Processing complete for file: peace_90-color0-rotate_180.jpg.txt\n",
            "ok_53-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0-f1.jpg.txt\n",
            "oksign 421 50 682 450\n",
            "[['oksign', '421', '50', '682', '450']]\n",
            "Processing complete for file: ok_53-color0-f1.jpg.txt\n",
            "peace_58-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0-f0.jpg.txt\n",
            "peacesign 470 104 932 595\n",
            "[['peacesign', '470', '104', '932', '595']]\n",
            "Processing complete for file: peace_58-color0-f0.jpg.txt\n",
            "peace_38-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0-rotate_180.jpg.txt\n",
            "peacesign 781 291 1062 690\n",
            "[['peacesign', '781', '291', '1062', '690']]\n",
            "Processing complete for file: peace_38-color0-rotate_180.jpg.txt\n",
            "peace_3-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0-f0.jpg.txt\n",
            "peacesign 21 32 337 589\n",
            "[['peacesign', '21', '32', '337', '589']]\n",
            "Processing complete for file: peace_3-color0-f0.jpg.txt\n",
            "ok_93-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0-f0.jpg.txt\n",
            "oksign 696 285 998 476\n",
            "[['oksign', '696', '285', '998', '476']]\n",
            "Processing complete for file: ok_93-color0-f0.jpg.txt\n",
            "ok_64-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0-rotate_90.jpg.txt\n",
            "oksign 251 517 460 746\n",
            "[['oksign', '251', '517', '460', '746']]\n",
            "Processing complete for file: ok_64-color0-rotate_90.jpg.txt\n",
            "peace_29-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0-f1.jpg.txt\n",
            "peacesign 388 139 848 1043\n",
            "[['peacesign', '388', '139', '848', '1043']]\n",
            "Processing complete for file: peace_29-color0-f1.jpg.txt\n",
            "palm_23-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0-rotate_90.jpg.txt\n",
            "palmhand 147 154 291 581\n",
            "[['palmhand', '147', '154', '291', '581']]\n",
            "Processing complete for file: palm_23-color0-rotate_90.jpg.txt\n",
            "palm_7-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0-rotate_90.jpg.txt\n",
            "palmhand 0 48 677 440\n",
            "[['palmhand', '0', '48', '677', '440']]\n",
            "Processing complete for file: palm_7-color0-rotate_90.jpg.txt\n",
            "ok_5-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0-rotate_180.jpg.txt\n",
            "oksign 569 360 803 644\n",
            "[['oksign', '569', '360', '803', '644']]\n",
            "Processing complete for file: ok_5-color0-rotate_180.jpg.txt\n",
            "peace_95-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0-f0.jpg.txt\n",
            "peacesign 434 166 705 613\n",
            "[['peacesign', '434', '166', '705', '613']]\n",
            "Processing complete for file: peace_95-color0-f0.jpg.txt\n",
            "ok_81-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0-rotate_270.jpg.txt\n",
            "oksign 219 329 614 596\n",
            "[['oksign', '219', '329', '614', '596']]\n",
            "Processing complete for file: ok_81-color0-rotate_270.jpg.txt\n",
            "peace_87-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0-rotate_180.jpg.txt\n",
            "peacesign 384 146 775 577\n",
            "[['peacesign', '384', '146', '775', '577']]\n",
            "Processing complete for file: peace_87-color0-rotate_180.jpg.txt\n",
            "palm_71-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0-f1.jpg.txt\n",
            "palmhand 673 262 932 523\n",
            "[['palmhand', '673', '262', '932', '523']]\n",
            "Processing complete for file: palm_71-color0-f1.jpg.txt\n",
            "peace_2-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0-f0.jpg.txt\n",
            "peacesign 39 30 400 600\n",
            "[['peacesign', '39', '30', '400', '600']]\n",
            "Processing complete for file: peace_2-color0-f0.jpg.txt\n",
            "palm_15-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0-f0.jpg.txt\n",
            "palmhand 54 37 355 428\n",
            "[['palmhand', '54', '37', '355', '428']]\n",
            "palmhand 364 37 675 428\n",
            "[['palmhand', '54', '37', '355', '428'], ['palmhand', '364', '37', '675', '428']]\n",
            "Processing complete for file: palm_15-color0-f0.jpg.txt\n",
            "palm_7-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0.jpg.txt\n",
            "palmhand 48 22 440 699\n",
            "[['palmhand', '48', '22', '440', '699']]\n",
            "Processing complete for file: palm_7-color0.jpg.txt\n",
            "palm_16-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0-rotate_270.jpg.txt\n",
            "palmhand 3 146 318 415\n",
            "[['palmhand', '3', '146', '318', '415']]\n",
            "palmhand 1 423 340 642\n",
            "[['palmhand', '3', '146', '318', '415'], ['palmhand', '1', '423', '340', '642']]\n",
            "Processing complete for file: palm_16-color0-rotate_270.jpg.txt\n",
            "palm_26-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0-f1.jpg.txt\n",
            "palmhand 72 23 277 424\n",
            "[['palmhand', '72', '23', '277', '424']]\n",
            "Processing complete for file: palm_26-color0-f1.jpg.txt\n",
            "palm_19-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0-rotate_270.jpg.txt\n",
            "palmhand 1 0 401 412\n",
            "[['palmhand', '1', '0', '401', '412']]\n",
            "Processing complete for file: palm_19-color0-rotate_270.jpg.txt\n",
            "palm_95-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0-f0.jpg.txt\n",
            "palmhand 519 201 719 508\n",
            "[['palmhand', '519', '201', '719', '508']]\n",
            "Processing complete for file: palm_95-color0-f0.jpg.txt\n",
            "ok_77-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0-f1.jpg.txt\n",
            "oksign 357 117 632 537\n",
            "[['oksign', '357', '117', '632', '537']]\n",
            "Processing complete for file: ok_77-color0-f1.jpg.txt\n",
            "ok_93-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0-f1.jpg.txt\n",
            "oksign 82 244 384 435\n",
            "[['oksign', '82', '244', '384', '435']]\n",
            "Processing complete for file: ok_93-color0-f1.jpg.txt\n",
            "ok_76-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0-rotate_270.jpg.txt\n",
            "oksign 114 252 514 490\n",
            "[['oksign', '114', '252', '514', '490']]\n",
            "Processing complete for file: ok_76-color0-rotate_270.jpg.txt\n",
            "peace_58-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0-rotate_270.jpg.txt\n",
            "peacesign 125 148 616 610\n",
            "[['peacesign', '125', '148', '616', '610']]\n",
            "Processing complete for file: peace_58-color0-rotate_270.jpg.txt\n",
            "palm_40-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0-f0.jpg.txt\n",
            "palmhand 160 51 660 398\n",
            "[['palmhand', '160', '51', '660', '398']]\n",
            "Processing complete for file: palm_40-color0-f0.jpg.txt\n",
            "palm_76-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0-f0.jpg.txt\n",
            "palmhand 540 158 769 564\n",
            "[['palmhand', '540', '158', '769', '564']]\n",
            "Processing complete for file: palm_76-color0-f0.jpg.txt\n",
            "peace_96-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0-rotate_270.jpg.txt\n",
            "peacesign 78 533 561 770\n",
            "[['peacesign', '78', '533', '561', '770']]\n",
            "Processing complete for file: peace_96-color0-rotate_270.jpg.txt\n",
            "palm_29-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0-f1.jpg.txt\n",
            "palmhand 82 30 307 472\n",
            "[['palmhand', '82', '30', '307', '472']]\n",
            "Processing complete for file: palm_29-color0-f1.jpg.txt\n",
            "peace_77-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0-rotate_90.jpg.txt\n",
            "peacesign 70 154 604 654\n",
            "[['peacesign', '70', '154', '604', '654']]\n",
            "Processing complete for file: peace_77-color0-rotate_90.jpg.txt\n",
            "ok_34-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0-f1.jpg.txt\n",
            "oksign 72 104 252 362\n",
            "[['oksign', '72', '104', '252', '362']]\n",
            "Processing complete for file: ok_34-color0-f1.jpg.txt\n",
            "palm_44-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0-f0.jpg.txt\n",
            "palmhand 29 41 581 415\n",
            "[['palmhand', '29', '41', '581', '415']]\n",
            "Processing complete for file: palm_44-color0-f0.jpg.txt\n",
            "peace_82-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0-rotate_270.jpg.txt\n",
            "peacesign 307 88 587 488\n",
            "[['peacesign', '307', '88', '587', '488']]\n",
            "Processing complete for file: peace_82-color0-rotate_270.jpg.txt\n",
            "peace_31-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0.jpg.txt\n",
            "peacesign 191 165 691 1006\n",
            "[['peacesign', '191', '165', '691', '1006']]\n",
            "Processing complete for file: peace_31-color0.jpg.txt\n",
            "peace_77-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0-rotate_180.jpg.txt\n",
            "peacesign 426 70 926 604\n",
            "[['peacesign', '426', '70', '926', '604']]\n",
            "Processing complete for file: peace_77-color0-rotate_180.jpg.txt\n",
            "peace_56-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0-f0.jpg.txt\n",
            "peacesign 310 102 567 542\n",
            "[['peacesign', '310', '102', '567', '542']]\n",
            "Processing complete for file: peace_56-color0-f0.jpg.txt\n",
            "palm_82-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0-f0.jpg.txt\n",
            "palmhand 444 176 753 672\n",
            "[['palmhand', '444', '176', '753', '672']]\n",
            "Processing complete for file: palm_82-color0-f0.jpg.txt\n",
            "palm_8-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0-rotate_270.jpg.txt\n",
            "palmhand 23 83 626 424\n",
            "[['palmhand', '23', '83', '626', '424']]\n",
            "Processing complete for file: palm_8-color0-rotate_270.jpg.txt\n",
            "peace_69-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0-rotate_90.jpg.txt\n",
            "peacesign 129 182 520 577\n",
            "[['peacesign', '129', '182', '520', '577']]\n",
            "Processing complete for file: peace_69-color0-rotate_90.jpg.txt\n",
            "peace_71-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0-f0.jpg.txt\n",
            "peacesign 364 237 698 640\n",
            "[['peacesign', '364', '237', '698', '640']]\n",
            "Processing complete for file: peace_71-color0-f0.jpg.txt\n",
            "palm_40-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0-rotate_180.jpg.txt\n",
            "palmhand 60 51 560 398\n",
            "[['palmhand', '60', '51', '560', '398']]\n",
            "Processing complete for file: palm_40-color0-rotate_180.jpg.txt\n",
            "peace_41-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0.jpg.txt\n",
            "peacesign 391 57 568 373\n",
            "[['peacesign', '391', '57', '568', '373']]\n",
            "Processing complete for file: peace_41-color0.jpg.txt\n",
            "peace_44-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0-rotate_90.jpg.txt\n",
            "peacesign 178 42 357 143\n",
            "[['peacesign', '178', '42', '357', '143']]\n",
            "Processing complete for file: peace_44-color0-rotate_90.jpg.txt\n",
            "ok_16-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0.jpg.txt\n",
            "oksign 191 98 736 932\n",
            "[['oksign', '191', '98', '736', '932']]\n",
            "Processing complete for file: ok_16-color0.jpg.txt\n",
            "palm_63-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0-rotate_90.jpg.txt\n",
            "palmhand 56 138 356 657\n",
            "[['palmhand', '56', '138', '356', '657']]\n",
            "Processing complete for file: palm_63-color0-rotate_90.jpg.txt\n",
            "palm_92-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0.jpg.txt\n",
            "palmhand 419 119 613 408\n",
            "[['palmhand', '419', '119', '613', '408']]\n",
            "Processing complete for file: palm_92-color0.jpg.txt\n",
            "peace_62-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0-rotate_270.jpg.txt\n",
            "peacesign 263 279 607 464\n",
            "[['peacesign', '263', '279', '607', '464']]\n",
            "Processing complete for file: peace_62-color0-rotate_270.jpg.txt\n",
            "peace_4-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0-f0.jpg.txt\n",
            "peacesign 14 26 430 582\n",
            "[['peacesign', '14', '26', '430', '582']]\n",
            "Processing complete for file: peace_4-color0-f0.jpg.txt\n",
            "ok_43-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0-rotate_180.jpg.txt\n",
            "oksign 86 156 214 337\n",
            "[['oksign', '86', '156', '214', '337']]\n",
            "Processing complete for file: ok_43-color0-rotate_180.jpg.txt\n",
            "peace_9-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0-rotate_90.jpg.txt\n",
            "peacesign 32 33 613 351\n",
            "[['peacesign', '32', '33', '613', '351']]\n",
            "Processing complete for file: peace_9-color0-rotate_90.jpg.txt\n",
            "peace_2-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0-rotate_180.jpg.txt\n",
            "peacesign 57 30 418 600\n",
            "[['peacesign', '57', '30', '418', '600']]\n",
            "Processing complete for file: peace_2-color0-rotate_180.jpg.txt\n",
            "ok_43-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0-rotate_90.jpg.txt\n",
            "oksign 156 388 337 516\n",
            "[['oksign', '156', '388', '337', '516']]\n",
            "Processing complete for file: ok_43-color0-rotate_90.jpg.txt\n",
            "peace_54-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0-rotate_270.jpg.txt\n",
            "peacesign 43 302 667 608\n",
            "[['peacesign', '43', '302', '667', '608']]\n",
            "Processing complete for file: peace_54-color0-rotate_270.jpg.txt\n",
            "palm_62-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0-f1.jpg.txt\n",
            "palmhand 419 60 700 498\n",
            "[['palmhand', '419', '60', '700', '498']]\n",
            "Processing complete for file: palm_62-color0-f1.jpg.txt\n",
            "ok_83-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0-f1.jpg.txt\n",
            "oksign 232 52 504 356\n",
            "[['oksign', '232', '52', '504', '356']]\n",
            "Processing complete for file: ok_83-color0-f1.jpg.txt\n",
            "peace_65-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0-f0.jpg.txt\n",
            "peacesign 421 117 828 517\n",
            "[['peacesign', '421', '117', '828', '517']]\n",
            "Processing complete for file: peace_65-color0-f0.jpg.txt\n",
            "peace_5-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0-rotate_90.jpg.txt\n",
            "peacesign 24 38 587 353\n",
            "[['peacesign', '24', '38', '587', '353']]\n",
            "Processing complete for file: peace_5-color0-rotate_90.jpg.txt\n",
            "ok_38-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0-rotate_180.jpg.txt\n",
            "oksign 69 4 304 366\n",
            "[['oksign', '69', '4', '304', '366']]\n",
            "Processing complete for file: ok_38-color0-rotate_180.jpg.txt\n",
            "palm_35-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0-rotate_90.jpg.txt\n",
            "palmhand 17 153 457 557\n",
            "[['palmhand', '17', '153', '457', '557']]\n",
            "Processing complete for file: palm_35-color0-rotate_90.jpg.txt\n",
            "ok_42-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0-rotate_90.jpg.txt\n",
            "oksign 249 775 671 1054\n",
            "[['oksign', '249', '775', '671', '1054']]\n",
            "Processing complete for file: ok_42-color0-rotate_90.jpg.txt\n",
            "ok_80-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0-rotate_90.jpg.txt\n",
            "oksign 131 642 564 915\n",
            "[['oksign', '131', '642', '564', '915']]\n",
            "Processing complete for file: ok_80-color0-rotate_90.jpg.txt\n",
            "peace_41-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0-rotate_180.jpg.txt\n",
            "peacesign 232 27 409 343\n",
            "[['peacesign', '232', '27', '409', '343']]\n",
            "Processing complete for file: peace_41-color0-rotate_180.jpg.txt\n",
            "palm_85-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0-rotate_90.jpg.txt\n",
            "palmhand 245 242 497 603\n",
            "[['palmhand', '245', '242', '497', '603']]\n",
            "Processing complete for file: palm_85-color0-rotate_90.jpg.txt\n",
            "peace_93-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0-f0.jpg.txt\n",
            "peacesign 385 86 627 535\n",
            "[['peacesign', '385', '86', '627', '535']]\n",
            "Processing complete for file: peace_93-color0-f0.jpg.txt\n",
            "palm_95-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0-f1.jpg.txt\n",
            "palmhand 361 212 561 519\n",
            "[['palmhand', '361', '212', '561', '519']]\n",
            "Processing complete for file: palm_95-color0-f1.jpg.txt\n",
            "peace_43-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0-rotate_270.jpg.txt\n",
            "peacesign 51 134 866 573\n",
            "[['peacesign', '51', '134', '866', '573']]\n",
            "Processing complete for file: peace_43-color0-rotate_270.jpg.txt\n",
            "palm_41-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0-rotate_90.jpg.txt\n",
            "palmhand 0 52 375 339\n",
            "[['palmhand', '0', '52', '375', '339']]\n",
            "palmhand 13 344 419 600\n",
            "[['palmhand', '0', '52', '375', '339'], ['palmhand', '13', '344', '419', '600']]\n",
            "Processing complete for file: palm_41-color0-rotate_90.jpg.txt\n",
            "palm_20-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0-rotate_180.jpg.txt\n",
            "palmhand 55 88 309 438\n",
            "[['palmhand', '55', '88', '309', '438']]\n",
            "Processing complete for file: palm_20-color0-rotate_180.jpg.txt\n",
            "peace_2-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0-rotate_90.jpg.txt\n",
            "peacesign 30 39 600 400\n",
            "[['peacesign', '30', '39', '600', '400']]\n",
            "Processing complete for file: peace_2-color0-rotate_90.jpg.txt\n",
            "palm_9-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0-f1.jpg.txt\n",
            "palmhand 49 19 358 580\n",
            "[['palmhand', '49', '19', '358', '580']]\n",
            "Processing complete for file: palm_9-color0-f1.jpg.txt\n",
            "peace_38-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0.jpg.txt\n",
            "peacesign 71 160 352 559\n",
            "[['peacesign', '71', '160', '352', '559']]\n",
            "Processing complete for file: peace_38-color0.jpg.txt\n",
            "ok_18-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_18-color0-f0.jpg.txt\n",
            "oksign 212 9 356 227\n",
            "[['oksign', '212', '9', '356', '227']]\n",
            "oksign 439 3 625 184\n",
            "[['oksign', '212', '9', '356', '227'], ['oksign', '439', '3', '625', '184']]\n",
            "Processing complete for file: ok_18-color0-f0.jpg.txt\n",
            "palm_86-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0-rotate_90.jpg.txt\n",
            "palmhand 301 361 620 680\n",
            "[['palmhand', '301', '361', '620', '680']]\n",
            "Processing complete for file: palm_86-color0-rotate_90.jpg.txt\n",
            "peace_23-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0-rotate_270.jpg.txt\n",
            "peacesign 40 513 799 981\n",
            "[['peacesign', '40', '513', '799', '981']]\n",
            "Processing complete for file: peace_23-color0-rotate_270.jpg.txt\n",
            "peace_69-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0-rotate_180.jpg.txt\n",
            "peacesign 503 129 898 520\n",
            "[['peacesign', '503', '129', '898', '520']]\n",
            "Processing complete for file: peace_69-color0-rotate_180.jpg.txt\n",
            "palm_52-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0-rotate_90.jpg.txt\n",
            "palmhand 110 426 653 821\n",
            "[['palmhand', '110', '426', '653', '821']]\n",
            "Processing complete for file: palm_52-color0-rotate_90.jpg.txt\n",
            "ok_2-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0-rotate_90.jpg.txt\n",
            "oksign 301 340 942 771\n",
            "[['oksign', '301', '340', '942', '771']]\n",
            "Processing complete for file: ok_2-color0-rotate_90.jpg.txt\n",
            "palm_93-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0-rotate_180.jpg.txt\n",
            "palmhand 279 385 486 576\n",
            "[['palmhand', '279', '385', '486', '576']]\n",
            "Processing complete for file: palm_93-color0-rotate_180.jpg.txt\n",
            "palm_89-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0-rotate_180.jpg.txt\n",
            "palmhand 140 226 486 491\n",
            "[['palmhand', '140', '226', '486', '491']]\n",
            "Processing complete for file: palm_89-color0-rotate_180.jpg.txt\n",
            "peace_84-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0-f1.jpg.txt\n",
            "peacesign 342 92 646 561\n",
            "[['peacesign', '342', '92', '646', '561']]\n",
            "Processing complete for file: peace_84-color0-f1.jpg.txt\n",
            "peace_26-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0-rotate_270.jpg.txt\n",
            "peacesign 131 180 958 678\n",
            "[['peacesign', '131', '180', '958', '678']]\n",
            "Processing complete for file: peace_26-color0-rotate_270.jpg.txt\n",
            "ok_80-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0-rotate_270.jpg.txt\n",
            "oksign 156 165 589 438\n",
            "[['oksign', '156', '165', '589', '438']]\n",
            "Processing complete for file: ok_80-color0-rotate_270.jpg.txt\n",
            "palm_35-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0-rotate_180.jpg.txt\n",
            "palmhand 83 17 487 457\n",
            "[['palmhand', '83', '17', '487', '457']]\n",
            "Processing complete for file: palm_35-color0-rotate_180.jpg.txt\n",
            "ok_58-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0-rotate_270.jpg.txt\n",
            "oksign 154 344 487 613\n",
            "[['oksign', '154', '344', '487', '613']]\n",
            "Processing complete for file: ok_58-color0-rotate_270.jpg.txt\n",
            "palm_76-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0-f1.jpg.txt\n",
            "palmhand 311 156 540 562\n",
            "[['palmhand', '311', '156', '540', '562']]\n",
            "Processing complete for file: palm_76-color0-f1.jpg.txt\n",
            "ok_24-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0-rotate_180.jpg.txt\n",
            "oksign 255 83 428 357\n",
            "[['oksign', '255', '83', '428', '357']]\n",
            "Processing complete for file: ok_24-color0-rotate_180.jpg.txt\n",
            "ok_5-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0-f0.jpg.txt\n",
            "oksign 477 360 711 644\n",
            "[['oksign', '477', '360', '711', '644']]\n",
            "Processing complete for file: ok_5-color0-f0.jpg.txt\n",
            "peace_97-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0-f1.jpg.txt\n",
            "peacesign 402 98 642 581\n",
            "[['peacesign', '402', '98', '642', '581']]\n",
            "Processing complete for file: peace_97-color0-f1.jpg.txt\n",
            "palm_94-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0.jpg.txt\n",
            "palmhand 615 131 878 402\n",
            "[['palmhand', '615', '131', '878', '402']]\n",
            "Processing complete for file: palm_94-color0.jpg.txt\n",
            "palm_30-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0-rotate_270.jpg.txt\n",
            "palmhand 6 119 445 394\n",
            "[['palmhand', '6', '119', '445', '394']]\n",
            "Processing complete for file: palm_30-color0-rotate_270.jpg.txt\n",
            "ok_91-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0-rotate_90.jpg.txt\n",
            "oksign 281 390 508 655\n",
            "[['oksign', '281', '390', '508', '655']]\n",
            "Processing complete for file: ok_91-color0-rotate_90.jpg.txt\n",
            "peace_35-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0-rotate_180.jpg.txt\n",
            "peacesign 625 309 737 519\n",
            "[['peacesign', '625', '309', '737', '519']]\n",
            "Processing complete for file: peace_35-color0-rotate_180.jpg.txt\n",
            "palm_66-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0-rotate_270.jpg.txt\n",
            "palmhand 23 371 542 682\n",
            "[['palmhand', '23', '371', '542', '682']]\n",
            "Processing complete for file: palm_66-color0-rotate_270.jpg.txt\n",
            "peace_12-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0-f0.jpg.txt\n",
            "peacesign 28 10 278 432\n",
            "[['peacesign', '28', '10', '278', '432']]\n",
            "Processing complete for file: peace_12-color0-f0.jpg.txt\n",
            "palm_26-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0.jpg.txt\n",
            "palmhand 83 23 288 424\n",
            "[['palmhand', '83', '23', '288', '424']]\n",
            "Processing complete for file: palm_26-color0.jpg.txt\n",
            "palm_5-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0-rotate_270.jpg.txt\n",
            "palmhand 21 73 570 379\n",
            "[['palmhand', '21', '73', '570', '379']]\n",
            "Processing complete for file: palm_5-color0-rotate_270.jpg.txt\n",
            "ok_94-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0-f1.jpg.txt\n",
            "oksign 190 71 492 552\n",
            "[['oksign', '190', '71', '492', '552']]\n",
            "Processing complete for file: ok_94-color0-f1.jpg.txt\n",
            "peace_86-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0-rotate_90.jpg.txt\n",
            "peacesign 130 298 475 725\n",
            "[['peacesign', '130', '298', '475', '725']]\n",
            "Processing complete for file: peace_86-color0-rotate_90.jpg.txt\n",
            "peace_87-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0-f1.jpg.txt\n",
            "peacesign 384 143 775 574\n",
            "[['peacesign', '384', '143', '775', '574']]\n",
            "Processing complete for file: peace_87-color0-f1.jpg.txt\n",
            "palm_88-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0.jpg.txt\n",
            "palmhand 607 319 978 523\n",
            "[['palmhand', '607', '319', '978', '523']]\n",
            "Processing complete for file: palm_88-color0.jpg.txt\n",
            "palm_70-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0-rotate_270.jpg.txt\n",
            "palmhand 208 159 437 550\n",
            "[['palmhand', '208', '159', '437', '550']]\n",
            "Processing complete for file: palm_70-color0-rotate_270.jpg.txt\n",
            "palm_59-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0-rotate_90.jpg.txt\n",
            "palmhand 85 538 326 953\n",
            "[['palmhand', '85', '538', '326', '953']]\n",
            "Processing complete for file: palm_59-color0-rotate_90.jpg.txt\n",
            "ok_72-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0-rotate_180.jpg.txt\n",
            "oksign 367 312 623 670\n",
            "[['oksign', '367', '312', '623', '670']]\n",
            "Processing complete for file: ok_72-color0-rotate_180.jpg.txt\n",
            "palm_30-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0-f0.jpg.txt\n",
            "palmhand 246 35 521 474\n",
            "[['palmhand', '246', '35', '521', '474']]\n",
            "Processing complete for file: palm_30-color0-f0.jpg.txt\n",
            "palm_25-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0-rotate_180.jpg.txt\n",
            "palmhand 253 202 317 303\n",
            "[['palmhand', '253', '202', '317', '303']]\n",
            "palmhand 377 205 442 305\n",
            "[['palmhand', '253', '202', '317', '303'], ['palmhand', '377', '205', '442', '305']]\n",
            "Processing complete for file: palm_25-color0-rotate_180.jpg.txt\n",
            "palm_83-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0-f1.jpg.txt\n",
            "palmhand 357 194 582 442\n",
            "[['palmhand', '357', '194', '582', '442']]\n",
            "Processing complete for file: palm_83-color0-f1.jpg.txt\n",
            "ok_39-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0-rotate_90.jpg.txt\n",
            "oksign 146 334 546 589\n",
            "[['oksign', '146', '334', '546', '589']]\n",
            "Processing complete for file: ok_39-color0-rotate_90.jpg.txt\n",
            "peace_15-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0-f0.jpg.txt\n",
            "peacesign 316 8 609 548\n",
            "[['peacesign', '316', '8', '609', '548']]\n",
            "Processing complete for file: peace_15-color0-f0.jpg.txt\n",
            "palm_24-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0-rotate_90.jpg.txt\n",
            "palmhand 0 118 472 428\n",
            "[['palmhand', '0', '118', '472', '428']]\n",
            "Processing complete for file: palm_24-color0-rotate_90.jpg.txt\n",
            "ok_84-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0-f1.jpg.txt\n",
            "oksign 250 112 479 452\n",
            "[['oksign', '250', '112', '479', '452']]\n",
            "Processing complete for file: ok_84-color0-f1.jpg.txt\n",
            "ok_41-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0-rotate_180.jpg.txt\n",
            "oksign 281 174 357 280\n",
            "[['oksign', '281', '174', '357', '280']]\n",
            "oksign 33 153 113 265\n",
            "[['oksign', '281', '174', '357', '280'], ['oksign', '33', '153', '113', '265']]\n",
            "Processing complete for file: ok_41-color0-rotate_180.jpg.txt\n",
            "palm_70-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0.jpg.txt\n",
            "palmhand 530 208 921 437\n",
            "[['palmhand', '530', '208', '921', '437']]\n",
            "Processing complete for file: palm_70-color0.jpg.txt\n",
            "palm_33-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0-f0.jpg.txt\n",
            "palmhand 378 151 500 351\n",
            "[['palmhand', '378', '151', '500', '351']]\n",
            "palmhand 203 145 351 329\n",
            "[['palmhand', '378', '151', '500', '351'], ['palmhand', '203', '145', '351', '329']]\n",
            "Processing complete for file: palm_33-color0-f0.jpg.txt\n",
            "peace_42-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0.jpg.txt\n",
            "peacesign 201 407 511 769\n",
            "[['peacesign', '201', '407', '511', '769']]\n",
            "peacesign 1186 332 1486 738\n",
            "[['peacesign', '201', '407', '511', '769'], ['peacesign', '1186', '332', '1486', '738']]\n",
            "Processing complete for file: peace_42-color0.jpg.txt\n",
            "ok_41-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0-f1.jpg.txt\n",
            "oksign 281 137 357 243\n",
            "[['oksign', '281', '137', '357', '243']]\n",
            "oksign 33 152 113 264\n",
            "[['oksign', '281', '137', '357', '243'], ['oksign', '33', '152', '113', '264']]\n",
            "Processing complete for file: ok_41-color0-f1.jpg.txt\n",
            "palm_35-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0-f1.jpg.txt\n",
            "palmhand 83 23 487 463\n",
            "[['palmhand', '83', '23', '487', '463']]\n",
            "Processing complete for file: palm_35-color0-f1.jpg.txt\n",
            "peace_89-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0-rotate_270.jpg.txt\n",
            "peacesign 183 295 636 568\n",
            "[['peacesign', '183', '295', '636', '568']]\n",
            "Processing complete for file: peace_89-color0-rotate_270.jpg.txt\n",
            "palm_68-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_68-color0-f1.jpg.txt\n",
            "palmhand 594 81 827 412\n",
            "[['palmhand', '594', '81', '827', '412']]\n",
            "Processing complete for file: palm_68-color0-f1.jpg.txt\n",
            "ok_31-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0-rotate_180.jpg.txt\n",
            "oksign 189 14 394 333\n",
            "[['oksign', '189', '14', '394', '333']]\n",
            "Processing complete for file: ok_31-color0-rotate_180.jpg.txt\n",
            "ok_38-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0-rotate_270.jpg.txt\n",
            "oksign 18 69 380 304\n",
            "[['oksign', '18', '69', '380', '304']]\n",
            "Processing complete for file: ok_38-color0-rotate_270.jpg.txt\n",
            "palm_21-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0.jpg.txt\n",
            "palmhand 317 38 927 782\n",
            "[['palmhand', '317', '38', '927', '782']]\n",
            "Processing complete for file: palm_21-color0.jpg.txt\n",
            "palm_18-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0-rotate_90.jpg.txt\n",
            "palmhand 71 35 385 605\n",
            "[['palmhand', '71', '35', '385', '605']]\n",
            "Processing complete for file: palm_18-color0-rotate_90.jpg.txt\n",
            "palm_43-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0-rotate_90.jpg.txt\n",
            "palmhand 129 68 367 417\n",
            "[['palmhand', '129', '68', '367', '417']]\n",
            "Processing complete for file: palm_43-color0-rotate_90.jpg.txt\n",
            "peace_36-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0-f0.jpg.txt\n",
            "peacesign 416 185 624 554\n",
            "[['peacesign', '416', '185', '624', '554']]\n",
            "Processing complete for file: peace_36-color0-f0.jpg.txt\n",
            "peace_56-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0-rotate_90.jpg.txt\n",
            "peacesign 102 310 542 567\n",
            "[['peacesign', '102', '310', '542', '567']]\n",
            "Processing complete for file: peace_56-color0-rotate_90.jpg.txt\n",
            "palm_22-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0-f0.jpg.txt\n",
            "palmhand 71 66 325 411\n",
            "[['palmhand', '71', '66', '325', '411']]\n",
            "palmhand 330 69 572 414\n",
            "[['palmhand', '71', '66', '325', '411'], ['palmhand', '330', '69', '572', '414']]\n",
            "Processing complete for file: palm_22-color0-f0.jpg.txt\n",
            "peace_78-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0-f0.jpg.txt\n",
            "peacesign 401 99 683 604\n",
            "[['peacesign', '401', '99', '683', '604']]\n",
            "Processing complete for file: peace_78-color0-f0.jpg.txt\n",
            "peace_6-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0-rotate_90.jpg.txt\n",
            "peacesign 38 33 591 356\n",
            "[['peacesign', '38', '33', '591', '356']]\n",
            "Processing complete for file: peace_6-color0-rotate_90.jpg.txt\n",
            "ok_32-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0-rotate_270.jpg.txt\n",
            "oksign 14 181 341 428\n",
            "[['oksign', '14', '181', '341', '428']]\n",
            "Processing complete for file: ok_32-color0-rotate_270.jpg.txt\n",
            "peace_36-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_36-color0-rotate_90.jpg.txt\n",
            "peacesign 185 416 554 624\n",
            "[['peacesign', '185', '416', '554', '624']]\n",
            "Processing complete for file: peace_36-color0-rotate_90.jpg.txt\n",
            "ok_24-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0-f1.jpg.txt\n",
            "oksign 255 51 428 325\n",
            "[['oksign', '255', '51', '428', '325']]\n",
            "Processing complete for file: ok_24-color0-f1.jpg.txt\n",
            "palm_65-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0-f0.jpg.txt\n",
            "palmhand 244 187 648 668\n",
            "[['palmhand', '244', '187', '648', '668']]\n",
            "Processing complete for file: palm_65-color0-f0.jpg.txt\n",
            "palm_83-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0-rotate_270.jpg.txt\n",
            "palmhand 194 357 442 582\n",
            "[['palmhand', '194', '357', '442', '582']]\n",
            "Processing complete for file: palm_83-color0-rotate_270.jpg.txt\n",
            "peace_95-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0-rotate_270.jpg.txt\n",
            "peacesign 107 375 554 646\n",
            "[['peacesign', '107', '375', '554', '646']]\n",
            "Processing complete for file: peace_95-color0-rotate_270.jpg.txt\n",
            "palm_40-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0.jpg.txt\n",
            "palmhand 160 82 660 429\n",
            "[['palmhand', '160', '82', '660', '429']]\n",
            "Processing complete for file: palm_40-color0.jpg.txt\n",
            "palm_13-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0-rotate_270.jpg.txt\n",
            "palmhand 156 282 687 585\n",
            "[['palmhand', '156', '282', '687', '585']]\n",
            "palmhand 201 591 753 925\n",
            "[['palmhand', '156', '282', '687', '585'], ['palmhand', '201', '591', '753', '925']]\n",
            "Processing complete for file: palm_13-color0-rotate_270.jpg.txt\n",
            "peace_15-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_15-color0-rotate_180.jpg.txt\n",
            "peacesign 411 8 704 548\n",
            "[['peacesign', '411', '8', '704', '548']]\n",
            "Processing complete for file: peace_15-color0-rotate_180.jpg.txt\n",
            "palm_94-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0-f0.jpg.txt\n",
            "palmhand 615 318 878 589\n",
            "[['palmhand', '615', '318', '878', '589']]\n",
            "Processing complete for file: palm_94-color0-f0.jpg.txt\n",
            "palm_94-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0-rotate_90.jpg.txt\n",
            "palmhand 318 615 589 878\n",
            "[['palmhand', '318', '615', '589', '878']]\n",
            "Processing complete for file: palm_94-color0-rotate_90.jpg.txt\n",
            "ok_27-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0-rotate_180.jpg.txt\n",
            "oksign 142 220 340 518\n",
            "[['oksign', '142', '220', '340', '518']]\n",
            "Processing complete for file: ok_27-color0-rotate_180.jpg.txt\n",
            "palm_86-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_86-color0-f1.jpg.txt\n",
            "palmhand 400 100 719 419\n",
            "[['palmhand', '400', '100', '719', '419']]\n",
            "Processing complete for file: palm_86-color0-f1.jpg.txt\n",
            "ok_34-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0-rotate_90.jpg.txt\n",
            "oksign 99 298 357 478\n",
            "[['oksign', '99', '298', '357', '478']]\n",
            "Processing complete for file: ok_34-color0-rotate_90.jpg.txt\n",
            "palm_80-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0-f0.jpg.txt\n",
            "palmhand 696 183 988 683\n",
            "[['palmhand', '696', '183', '988', '683']]\n",
            "Processing complete for file: palm_80-color0-f0.jpg.txt\n",
            "ok_90-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0-rotate_270.jpg.txt\n",
            "oksign 302 492 504 757\n",
            "[['oksign', '302', '492', '504', '757']]\n",
            "Processing complete for file: ok_90-color0-rotate_270.jpg.txt\n",
            "palm_64-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0-rotate_180.jpg.txt\n",
            "palmhand 407 124 888 503\n",
            "[['palmhand', '407', '124', '888', '503']]\n",
            "Processing complete for file: palm_64-color0-rotate_180.jpg.txt\n",
            "ok_94-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0-rotate_90.jpg.txt\n",
            "oksign 168 588 649 890\n",
            "[['oksign', '168', '588', '649', '890']]\n",
            "Processing complete for file: ok_94-color0-rotate_90.jpg.txt\n",
            "palm_1-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0-f0.jpg.txt\n",
            "palmhand 112 59 423 623\n",
            "[['palmhand', '112', '59', '423', '623']]\n",
            "Processing complete for file: palm_1-color0-f0.jpg.txt\n",
            "ok_89-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0-rotate_180.jpg.txt\n",
            "oksign 471 199 763 389\n",
            "[['oksign', '471', '199', '763', '389']]\n",
            "Processing complete for file: ok_89-color0-rotate_180.jpg.txt\n",
            "ok_29-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0-rotate_180.jpg.txt\n",
            "oksign 699 238 871 432\n",
            "[['oksign', '699', '238', '871', '432']]\n",
            "Processing complete for file: ok_29-color0-rotate_180.jpg.txt\n",
            "peace_16-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0-rotate_90.jpg.txt\n",
            "peacesign 43 134 383 318\n",
            "[['peacesign', '43', '134', '383', '318']]\n",
            "Processing complete for file: peace_16-color0-rotate_90.jpg.txt\n",
            "palm_57-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0-rotate_90.jpg.txt\n",
            "palmhand 212 359 597 640\n",
            "[['palmhand', '212', '359', '597', '640']]\n",
            "Processing complete for file: palm_57-color0-rotate_90.jpg.txt\n",
            "palm_37-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0-rotate_90.jpg.txt\n",
            "palmhand 37 34 466 308\n",
            "[['palmhand', '37', '34', '466', '308']]\n",
            "Processing complete for file: palm_37-color0-rotate_90.jpg.txt\n",
            "palm_88-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0-rotate_90.jpg.txt\n",
            "palmhand 197 607 401 978\n",
            "[['palmhand', '197', '607', '401', '978']]\n",
            "Processing complete for file: palm_88-color0-rotate_90.jpg.txt\n",
            "ok_52-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0-rotate_180.jpg.txt\n",
            "oksign 334 203 604 595\n",
            "[['oksign', '334', '203', '604', '595']]\n",
            "Processing complete for file: ok_52-color0-rotate_180.jpg.txt\n",
            "ok_15-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0-rotate_270.jpg.txt\n",
            "oksign 11 129 403 392\n",
            "[['oksign', '11', '129', '403', '392']]\n",
            "Processing complete for file: ok_15-color0-rotate_270.jpg.txt\n",
            "ok_67-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0-rotate_180.jpg.txt\n",
            "oksign 375 289 629 606\n",
            "[['oksign', '375', '289', '629', '606']]\n",
            "Processing complete for file: ok_67-color0-rotate_180.jpg.txt\n",
            "palm_82-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0-rotate_180.jpg.txt\n",
            "palmhand 327 176 636 672\n",
            "[['palmhand', '327', '176', '636', '672']]\n",
            "Processing complete for file: palm_82-color0-rotate_180.jpg.txt\n",
            "peace_35-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_35-color0.jpg.txt\n",
            "peacesign 463 281 575 491\n",
            "[['peacesign', '463', '281', '575', '491']]\n",
            "Processing complete for file: peace_35-color0.jpg.txt\n",
            "palm_85-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0-f0.jpg.txt\n",
            "palmhand 242 245 603 497\n",
            "[['palmhand', '242', '245', '603', '497']]\n",
            "Processing complete for file: palm_85-color0-f0.jpg.txt\n",
            "palm_5-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0.jpg.txt\n",
            "palmhand 72 21 378 570\n",
            "[['palmhand', '72', '21', '378', '570']]\n",
            "Processing complete for file: palm_5-color0.jpg.txt\n",
            "palm_93-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0-f1.jpg.txt\n",
            "palmhand 279 144 486 335\n",
            "[['palmhand', '279', '144', '486', '335']]\n",
            "Processing complete for file: palm_93-color0-f1.jpg.txt\n",
            "peace_79-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0-rotate_90.jpg.txt\n",
            "peacesign 157 545 597 938\n",
            "[['peacesign', '157', '545', '597', '938']]\n",
            "Processing complete for file: peace_79-color0-rotate_90.jpg.txt\n",
            "ok_67-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0.jpg.txt\n",
            "oksign 451 114 705 431\n",
            "[['oksign', '451', '114', '705', '431']]\n",
            "Processing complete for file: ok_67-color0.jpg.txt\n",
            "peace_10-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0-rotate_180.jpg.txt\n",
            "peacesign 85 37 414 650\n",
            "[['peacesign', '85', '37', '414', '650']]\n",
            "Processing complete for file: peace_10-color0-rotate_180.jpg.txt\n",
            "palm_1-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0-rotate_90.jpg.txt\n",
            "palmhand 59 112 623 423\n",
            "[['palmhand', '59', '112', '623', '423']]\n",
            "Processing complete for file: palm_1-color0-rotate_90.jpg.txt\n",
            "ok_65-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0-rotate_90.jpg.txt\n",
            "oksign 162 469 385 798\n",
            "[['oksign', '162', '469', '385', '798']]\n",
            "Processing complete for file: ok_65-color0-rotate_90.jpg.txt\n",
            "ok_53-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0-rotate_180.jpg.txt\n",
            "oksign 421 270 682 670\n",
            "[['oksign', '421', '270', '682', '670']]\n",
            "Processing complete for file: ok_53-color0-rotate_180.jpg.txt\n",
            "peace_13-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0-f0.jpg.txt\n",
            "peacesign 53 21 301 474\n",
            "[['peacesign', '53', '21', '301', '474']]\n",
            "Processing complete for file: peace_13-color0-f0.jpg.txt\n",
            "palm_97-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0-rotate_90.jpg.txt\n",
            "palmhand 328 567 606 846\n",
            "[['palmhand', '328', '567', '606', '846']]\n",
            "Processing complete for file: palm_97-color0-rotate_90.jpg.txt\n",
            "ok_78-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0-rotate_270.jpg.txt\n",
            "oksign 121 494 508 807\n",
            "[['oksign', '121', '494', '508', '807']]\n",
            "Processing complete for file: ok_78-color0-rotate_270.jpg.txt\n",
            "peace_5-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0-rotate_180.jpg.txt\n",
            "peacesign 92 24 407 587\n",
            "[['peacesign', '92', '24', '407', '587']]\n",
            "Processing complete for file: peace_5-color0-rotate_180.jpg.txt\n",
            "palm_14-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0-rotate_90.jpg.txt\n",
            "palmhand 99 180 368 576\n",
            "[['palmhand', '99', '180', '368', '576']]\n",
            "Processing complete for file: palm_14-color0-rotate_90.jpg.txt\n",
            "peace_4-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0-rotate_90.jpg.txt\n",
            "peacesign 26 14 582 430\n",
            "[['peacesign', '26', '14', '582', '430']]\n",
            "Processing complete for file: peace_4-color0-rotate_90.jpg.txt\n",
            "ok_96-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0.jpg.txt\n",
            "oksign 655 125 865 383\n",
            "[['oksign', '655', '125', '865', '383']]\n",
            "Processing complete for file: ok_96-color0.jpg.txt\n",
            "ok_33-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0-rotate_90.jpg.txt\n",
            "oksign 520 222 1033 579\n",
            "[['oksign', '520', '222', '1033', '579']]\n",
            "Processing complete for file: ok_33-color0-rotate_90.jpg.txt\n",
            "ok_57-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0.jpg.txt\n",
            "oksign 290 108 551 479\n",
            "[['oksign', '290', '108', '551', '479']]\n",
            "Processing complete for file: ok_57-color0.jpg.txt\n",
            "peace_63-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0-rotate_270.jpg.txt\n",
            "peacesign 156 493 503 724\n",
            "[['peacesign', '156', '493', '503', '724']]\n",
            "Processing complete for file: peace_63-color0-rotate_270.jpg.txt\n",
            "palm_72-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0-rotate_180.jpg.txt\n",
            "palmhand 567 249 815 524\n",
            "[['palmhand', '567', '249', '815', '524']]\n",
            "Processing complete for file: palm_72-color0-rotate_180.jpg.txt\n",
            "peace_68-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0-rotate_90.jpg.txt\n",
            "peacesign 164 147 375 592\n",
            "[['peacesign', '164', '147', '375', '592']]\n",
            "Processing complete for file: peace_68-color0-rotate_90.jpg.txt\n",
            "peace_60-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0.jpg.txt\n",
            "peacesign 245 107 498 418\n",
            "[['peacesign', '245', '107', '498', '418']]\n",
            "Processing complete for file: peace_60-color0.jpg.txt\n",
            "peace_13-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0.jpg.txt\n",
            "peacesign 53 13 301 466\n",
            "[['peacesign', '53', '13', '301', '466']]\n",
            "Processing complete for file: peace_13-color0.jpg.txt\n",
            "peace_1-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0-rotate_270.jpg.txt\n",
            "peacesign 25 70 589 394\n",
            "[['peacesign', '25', '70', '589', '394']]\n",
            "Processing complete for file: peace_1-color0-rotate_270.jpg.txt\n",
            "peace_59-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0-f1.jpg.txt\n",
            "peacesign 93 225 644 558\n",
            "[['peacesign', '93', '225', '644', '558']]\n",
            "Processing complete for file: peace_59-color0-f1.jpg.txt\n",
            "peace_83-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0-f1.jpg.txt\n",
            "peacesign 415 187 657 545\n",
            "[['peacesign', '415', '187', '657', '545']]\n",
            "Processing complete for file: peace_83-color0-f1.jpg.txt\n",
            "peace_83-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0-rotate_270.jpg.txt\n",
            "peacesign 187 415 545 657\n",
            "[['peacesign', '187', '415', '545', '657']]\n",
            "Processing complete for file: peace_83-color0-rotate_270.jpg.txt\n",
            "ok_88-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0.jpg.txt\n",
            "oksign 369 306 584 531\n",
            "[['oksign', '369', '306', '584', '531']]\n",
            "Processing complete for file: ok_88-color0.jpg.txt\n",
            "peace_71-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0-rotate_90.jpg.txt\n",
            "peacesign 237 364 640 698\n",
            "[['peacesign', '237', '364', '640', '698']]\n",
            "Processing complete for file: peace_71-color0-rotate_90.jpg.txt\n",
            "palm_64-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0-rotate_90.jpg.txt\n",
            "palmhand 124 192 503 673\n",
            "[['palmhand', '124', '192', '503', '673']]\n",
            "Processing complete for file: palm_64-color0-rotate_90.jpg.txt\n",
            "peace_38-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0-rotate_90.jpg.txt\n",
            "peacesign 291 71 690 352\n",
            "[['peacesign', '291', '71', '690', '352']]\n",
            "Processing complete for file: peace_38-color0-rotate_90.jpg.txt\n",
            "peace_83-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0-rotate_90.jpg.txt\n",
            "peacesign 175 423 533 665\n",
            "[['peacesign', '175', '423', '533', '665']]\n",
            "Processing complete for file: peace_83-color0-rotate_90.jpg.txt\n",
            "palm_43-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0-f0.jpg.txt\n",
            "palmhand 68 129 417 367\n",
            "[['palmhand', '68', '129', '417', '367']]\n",
            "Processing complete for file: palm_43-color0-f0.jpg.txt\n",
            "palm_20-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_20-color0-rotate_90.jpg.txt\n",
            "palmhand 88 11 438 265\n",
            "[['palmhand', '88', '11', '438', '265']]\n",
            "Processing complete for file: palm_20-color0-rotate_90.jpg.txt\n",
            "ok_13-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0.jpg.txt\n",
            "oksign 85 72 329 392\n",
            "[['oksign', '85', '72', '329', '392']]\n",
            "Processing complete for file: ok_13-color0.jpg.txt\n",
            "palm_32-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0.jpg.txt\n",
            "palmhand 175 14 417 452\n",
            "[['palmhand', '175', '14', '417', '452']]\n",
            "Processing complete for file: palm_32-color0.jpg.txt\n",
            "palm_45-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0-rotate_180.jpg.txt\n",
            "palmhand 114 41 502 396\n",
            "[['palmhand', '114', '41', '502', '396']]\n",
            "Processing complete for file: palm_45-color0-rotate_180.jpg.txt\n",
            "ok_22-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0-f0.jpg.txt\n",
            "oksign 295 45 547 429\n",
            "[['oksign', '295', '45', '547', '429']]\n",
            "Processing complete for file: ok_22-color0-f0.jpg.txt\n",
            "peace_26-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0.jpg.txt\n",
            "peacesign 175 131 673 958\n",
            "[['peacesign', '175', '131', '673', '958']]\n",
            "Processing complete for file: peace_26-color0.jpg.txt\n",
            "peace_88-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0-rotate_90.jpg.txt\n",
            "peacesign 70 618 559 901\n",
            "[['peacesign', '70', '618', '559', '901']]\n",
            "Processing complete for file: peace_88-color0-rotate_90.jpg.txt\n",
            "peace_69-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_69-color0-f0.jpg.txt\n",
            "peacesign 182 129 577 520\n",
            "[['peacesign', '182', '129', '577', '520']]\n",
            "Processing complete for file: peace_69-color0-f0.jpg.txt\n",
            "ok_91-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0-f0.jpg.txt\n",
            "oksign 390 281 655 508\n",
            "[['oksign', '390', '281', '655', '508']]\n",
            "Processing complete for file: ok_91-color0-f0.jpg.txt\n",
            "peace_9-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0.jpg.txt\n",
            "peacesign 33 18 351 599\n",
            "[['peacesign', '33', '18', '351', '599']]\n",
            "Processing complete for file: peace_9-color0.jpg.txt\n",
            "peace_17-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0-f0.jpg.txt\n",
            "peacesign 79 579 624 887\n",
            "[['peacesign', '79', '579', '624', '887']]\n",
            "peacesign 553 57 1040 701\n",
            "[['peacesign', '79', '579', '624', '887'], ['peacesign', '553', '57', '1040', '701']]\n",
            "Processing complete for file: peace_17-color0-f0.jpg.txt\n",
            "ok_19-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0-rotate_90.jpg.txt\n",
            "oksign 30 27 613 556\n",
            "[['oksign', '30', '27', '613', '556']]\n",
            "Processing complete for file: ok_19-color0-rotate_90.jpg.txt\n",
            "peace_57-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_57-color0-rotate_270.jpg.txt\n",
            "peacesign 223 433 558 924\n",
            "[['peacesign', '223', '433', '558', '924']]\n",
            "Processing complete for file: peace_57-color0-rotate_270.jpg.txt\n",
            "peace_95-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0-f1.jpg.txt\n",
            "peacesign 375 107 646 554\n",
            "[['peacesign', '375', '107', '646', '554']]\n",
            "Processing complete for file: peace_95-color0-f1.jpg.txt\n",
            "peace_76-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0-rotate_90.jpg.txt\n",
            "peacesign 70 76 406 690\n",
            "[['peacesign', '70', '76', '406', '690']]\n",
            "Processing complete for file: peace_76-color0-rotate_90.jpg.txt\n",
            "peace_5-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0-rotate_270.jpg.txt\n",
            "peacesign 10 92 573 407\n",
            "[['peacesign', '10', '92', '573', '407']]\n",
            "Processing complete for file: peace_5-color0-rotate_270.jpg.txt\n",
            "palm_24-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0-f1.jpg.txt\n",
            "palmhand 292 8 602 480\n",
            "[['palmhand', '292', '8', '602', '480']]\n",
            "Processing complete for file: palm_24-color0-f1.jpg.txt\n",
            "ok_28-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0-f0.jpg.txt\n",
            "oksign 152 168 244 266\n",
            "[['oksign', '152', '168', '244', '266']]\n",
            "oksign 386 175 478 275\n",
            "[['oksign', '152', '168', '244', '266'], ['oksign', '386', '175', '478', '275']]\n",
            "Processing complete for file: ok_28-color0-f0.jpg.txt\n",
            "palm_72-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0-rotate_270.jpg.txt\n",
            "palmhand 196 567 471 815\n",
            "[['palmhand', '196', '567', '471', '815']]\n",
            "Processing complete for file: palm_72-color0-rotate_270.jpg.txt\n",
            "palm_91-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0-rotate_90.jpg.txt\n",
            "palmhand 322 511 647 730\n",
            "[['palmhand', '322', '511', '647', '730']]\n",
            "Processing complete for file: palm_91-color0-rotate_90.jpg.txt\n",
            "peace_83-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0-rotate_180.jpg.txt\n",
            "peacesign 415 175 657 533\n",
            "[['peacesign', '415', '175', '657', '533']]\n",
            "Processing complete for file: peace_83-color0-rotate_180.jpg.txt\n",
            "peace_4-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0-rotate_180.jpg.txt\n",
            "peacesign 21 26 437 582\n",
            "[['peacesign', '21', '26', '437', '582']]\n",
            "Processing complete for file: peace_4-color0-rotate_180.jpg.txt\n",
            "peace_91-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0-rotate_180.jpg.txt\n",
            "peacesign 579 115 968 535\n",
            "[['peacesign', '579', '115', '968', '535']]\n",
            "Processing complete for file: peace_91-color0-rotate_180.jpg.txt\n",
            "peace_71-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0-rotate_180.jpg.txt\n",
            "peacesign 382 237 716 640\n",
            "[['peacesign', '382', '237', '716', '640']]\n",
            "Processing complete for file: peace_71-color0-rotate_180.jpg.txt\n",
            "peace_60-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0-f0.jpg.txt\n",
            "peacesign 245 302 498 613\n",
            "[['peacesign', '245', '302', '498', '613']]\n",
            "Processing complete for file: peace_60-color0-f0.jpg.txt\n",
            "palm_76-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0-rotate_180.jpg.txt\n",
            "palmhand 311 158 540 564\n",
            "[['palmhand', '311', '158', '540', '564']]\n",
            "Processing complete for file: palm_76-color0-rotate_180.jpg.txt\n",
            "ok_2-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0.jpg.txt\n",
            "oksign 340 338 771 979\n",
            "[['oksign', '340', '338', '771', '979']]\n",
            "Processing complete for file: ok_2-color0.jpg.txt\n",
            "peace_89-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0-rotate_90.jpg.txt\n",
            "peacesign 84 512 537 785\n",
            "[['peacesign', '84', '512', '537', '785']]\n",
            "Processing complete for file: peace_89-color0-rotate_90.jpg.txt\n",
            "palm_95-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0-rotate_270.jpg.txt\n",
            "palmhand 212 361 519 561\n",
            "[['palmhand', '212', '361', '519', '561']]\n",
            "Processing complete for file: palm_95-color0-rotate_270.jpg.txt\n",
            "palm_32-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0-rotate_180.jpg.txt\n",
            "palmhand 223 28 465 466\n",
            "[['palmhand', '223', '28', '465', '466']]\n",
            "Processing complete for file: palm_32-color0-rotate_180.jpg.txt\n",
            "ok_63-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0.jpg.txt\n",
            "oksign 396 189 621 456\n",
            "[['oksign', '396', '189', '621', '456']]\n",
            "Processing complete for file: ok_63-color0.jpg.txt\n",
            "palm_97-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0.jpg.txt\n",
            "palmhand 567 114 846 392\n",
            "[['palmhand', '567', '114', '846', '392']]\n",
            "Processing complete for file: palm_97-color0.jpg.txt\n",
            "ok_67-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0-rotate_270.jpg.txt\n",
            "oksign 114 375 431 629\n",
            "[['oksign', '114', '375', '431', '629']]\n",
            "Processing complete for file: ok_67-color0-rotate_270.jpg.txt\n",
            "peace_34-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0-rotate_90.jpg.txt\n",
            "peacesign 313 581 589 762\n",
            "[['peacesign', '313', '581', '589', '762']]\n",
            "Processing complete for file: peace_34-color0-rotate_90.jpg.txt\n",
            "ok_64-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0-f0.jpg.txt\n",
            "oksign 517 251 746 460\n",
            "[['oksign', '517', '251', '746', '460']]\n",
            "Processing complete for file: ok_64-color0-f0.jpg.txt\n",
            "palm_69-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0.jpg.txt\n",
            "palmhand 384 92 707 410\n",
            "[['palmhand', '384', '92', '707', '410']]\n",
            "Processing complete for file: palm_69-color0.jpg.txt\n",
            "ok_84-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0-rotate_180.jpg.txt\n",
            "oksign 250 268 479 608\n",
            "[['oksign', '250', '268', '479', '608']]\n",
            "Processing complete for file: ok_84-color0-rotate_180.jpg.txt\n",
            "palm_43-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0-rotate_180.jpg.txt\n",
            "palmhand 63 129 412 367\n",
            "[['palmhand', '63', '129', '412', '367']]\n",
            "Processing complete for file: palm_43-color0-rotate_180.jpg.txt\n",
            "palm_22-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0-rotate_90.jpg.txt\n",
            "palmhand 66 71 411 325\n",
            "[['palmhand', '66', '71', '411', '325']]\n",
            "palmhand 69 330 414 572\n",
            "[['palmhand', '66', '71', '411', '325'], ['palmhand', '69', '330', '414', '572']]\n",
            "Processing complete for file: palm_22-color0-rotate_90.jpg.txt\n",
            "ok_44-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0-rotate_270.jpg.txt\n",
            "oksign 16 490 236 647\n",
            "[['oksign', '16', '490', '236', '647']]\n",
            "Processing complete for file: ok_44-color0-rotate_270.jpg.txt\n",
            "peace_41-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0-f1.jpg.txt\n",
            "peacesign 232 57 409 373\n",
            "[['peacesign', '232', '57', '409', '373']]\n",
            "Processing complete for file: peace_41-color0-f1.jpg.txt\n",
            "ok_72-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0-rotate_90.jpg.txt\n",
            "oksign 312 457 670 713\n",
            "[['oksign', '312', '457', '670', '713']]\n",
            "Processing complete for file: ok_72-color0-rotate_90.jpg.txt\n",
            "palm_59-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_59-color0-f0.jpg.txt\n",
            "palmhand 538 85 953 326\n",
            "[['palmhand', '538', '85', '953', '326']]\n",
            "Processing complete for file: palm_59-color0-f0.jpg.txt\n",
            "palm_29-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0-rotate_270.jpg.txt\n",
            "palmhand 30 82 472 307\n",
            "[['palmhand', '30', '82', '472', '307']]\n",
            "Processing complete for file: palm_29-color0-rotate_270.jpg.txt\n",
            "ok_20-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0-f0.jpg.txt\n",
            "oksign 244 147 452 467\n",
            "[['oksign', '244', '147', '452', '467']]\n",
            "Processing complete for file: ok_20-color0-f0.jpg.txt\n",
            "palm_58-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0-rotate_90.jpg.txt\n",
            "palmhand 214 321 601 571\n",
            "[['palmhand', '214', '321', '601', '571']]\n",
            "Processing complete for file: palm_58-color0-rotate_90.jpg.txt\n",
            "peace_33-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_33-color0-rotate_90.jpg.txt\n",
            "peacesign 189 56 311 132\n",
            "[['peacesign', '189', '56', '311', '132']]\n",
            "peacesign 231 327 355 394\n",
            "[['peacesign', '189', '56', '311', '132'], ['peacesign', '231', '327', '355', '394']]\n",
            "Processing complete for file: peace_33-color0-rotate_90.jpg.txt\n",
            "ok_80-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0-rotate_180.jpg.txt\n",
            "oksign 165 131 438 564\n",
            "[['oksign', '165', '131', '438', '564']]\n",
            "Processing complete for file: ok_80-color0-rotate_180.jpg.txt\n",
            "palm_24-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0-rotate_180.jpg.txt\n",
            "palmhand 292 0 602 472\n",
            "[['palmhand', '292', '0', '602', '472']]\n",
            "Processing complete for file: palm_24-color0-rotate_180.jpg.txt\n",
            "peace_31-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0-f1.jpg.txt\n",
            "peacesign 109 165 609 1006\n",
            "[['peacesign', '109', '165', '609', '1006']]\n",
            "Processing complete for file: peace_31-color0-f1.jpg.txt\n",
            "ok_58-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_58-color0-rotate_180.jpg.txt\n",
            "oksign 344 233 613 566\n",
            "[['oksign', '344', '233', '613', '566']]\n",
            "Processing complete for file: ok_58-color0-rotate_180.jpg.txt\n",
            "peace_3-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_3-color0.jpg.txt\n",
            "peacesign 21 26 337 583\n",
            "[['peacesign', '21', '26', '337', '583']]\n",
            "Processing complete for file: peace_3-color0.jpg.txt\n",
            "palm_54-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0-rotate_270.jpg.txt\n",
            "palmhand 39 436 585 775\n",
            "[['palmhand', '39', '436', '585', '775']]\n",
            "Processing complete for file: palm_54-color0-rotate_270.jpg.txt\n",
            "peace_9-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0-f0.jpg.txt\n",
            "peacesign 33 32 351 613\n",
            "[['peacesign', '33', '32', '351', '613']]\n",
            "Processing complete for file: peace_9-color0-f0.jpg.txt\n",
            "peace_54-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0-rotate_180.jpg.txt\n",
            "peacesign 302 53 608 677\n",
            "[['peacesign', '302', '53', '608', '677']]\n",
            "Processing complete for file: peace_54-color0-rotate_180.jpg.txt\n",
            "palm_25-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_25-color0-rotate_270.jpg.txt\n",
            "palmhand 177 253 278 317\n",
            "[['palmhand', '177', '253', '278', '317']]\n",
            "palmhand 175 377 275 442\n",
            "[['palmhand', '177', '253', '278', '317'], ['palmhand', '175', '377', '275', '442']]\n",
            "Processing complete for file: palm_25-color0-rotate_270.jpg.txt\n",
            "ok_96-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0-rotate_270.jpg.txt\n",
            "oksign 125 215 383 425\n",
            "[['oksign', '125', '215', '383', '425']]\n",
            "Processing complete for file: ok_96-color0-rotate_270.jpg.txt\n",
            "palm_6-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0-f1.jpg.txt\n",
            "palmhand 96 14 438 607\n",
            "[['palmhand', '96', '14', '438', '607']]\n",
            "Processing complete for file: palm_6-color0-f1.jpg.txt\n",
            "ok_61-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0-f0.jpg.txt\n",
            "oksign 423 322 678 697\n",
            "[['oksign', '423', '322', '678', '697']]\n",
            "Processing complete for file: ok_61-color0-f0.jpg.txt\n",
            "ok_56-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0.jpg.txt\n",
            "oksign 230 100 490 473\n",
            "[['oksign', '230', '100', '490', '473']]\n",
            "Processing complete for file: ok_56-color0.jpg.txt\n",
            "peace_64-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0-rotate_180.jpg.txt\n",
            "peacesign 210 97 684 353\n",
            "[['peacesign', '210', '97', '684', '353']]\n",
            "Processing complete for file: peace_64-color0-rotate_180.jpg.txt\n",
            "palm_95-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0.jpg.txt\n",
            "palmhand 519 212 719 519\n",
            "[['palmhand', '519', '212', '719', '519']]\n",
            "Processing complete for file: palm_95-color0.jpg.txt\n",
            "palm_58-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0-f1.jpg.txt\n",
            "palmhand 509 119 759 506\n",
            "[['palmhand', '509', '119', '759', '506']]\n",
            "Processing complete for file: palm_58-color0-f1.jpg.txt\n",
            "palm_76-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0.jpg.txt\n",
            "palmhand 540 156 769 562\n",
            "[['palmhand', '540', '156', '769', '562']]\n",
            "Processing complete for file: palm_76-color0.jpg.txt\n",
            "ok_76-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0-f0.jpg.txt\n",
            "oksign 590 206 828 606\n",
            "[['oksign', '590', '206', '828', '606']]\n",
            "Processing complete for file: ok_76-color0-f0.jpg.txt\n",
            "ok_16-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0-rotate_270.jpg.txt\n",
            "oksign 98 288 932 833\n",
            "[['oksign', '98', '288', '932', '833']]\n",
            "Processing complete for file: ok_16-color0-rotate_270.jpg.txt\n",
            "peace_31-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0-rotate_270.jpg.txt\n",
            "peacesign 165 109 1006 609\n",
            "[['peacesign', '165', '109', '1006', '609']]\n",
            "Processing complete for file: peace_31-color0-rotate_270.jpg.txt\n",
            "palm_10-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0-rotate_270.jpg.txt\n",
            "palmhand 23 62 564 366\n",
            "[['palmhand', '23', '62', '564', '366']]\n",
            "Processing complete for file: palm_10-color0-rotate_270.jpg.txt\n",
            "ok_43-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0-f1.jpg.txt\n",
            "oksign 86 58 214 239\n",
            "[['oksign', '86', '58', '214', '239']]\n",
            "Processing complete for file: ok_43-color0-f1.jpg.txt\n",
            "peace_67-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0-rotate_90.jpg.txt\n",
            "peacesign 170 254 597 645\n",
            "[['peacesign', '170', '254', '597', '645']]\n",
            "Processing complete for file: peace_67-color0-rotate_90.jpg.txt\n",
            "ok_21-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_21-color0-f0.jpg.txt\n",
            "oksign 252 109 397 323\n",
            "[['oksign', '252', '109', '397', '323']]\n",
            "Processing complete for file: ok_21-color0-f0.jpg.txt\n",
            "palm_36-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_36-color0-f1.jpg.txt\n",
            "palmhand 81 6 290 413\n",
            "[['palmhand', '81', '6', '290', '413']]\n",
            "Processing complete for file: palm_36-color0-f1.jpg.txt\n",
            "palm_40-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0-f1.jpg.txt\n",
            "palmhand 60 82 560 429\n",
            "[['palmhand', '60', '82', '560', '429']]\n",
            "Processing complete for file: palm_40-color0-f1.jpg.txt\n",
            "palm_77-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0-rotate_90.jpg.txt\n",
            "palmhand 197 457 581 701\n",
            "[['palmhand', '197', '457', '581', '701']]\n",
            "Processing complete for file: palm_77-color0-rotate_90.jpg.txt\n",
            "peace_8-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0-rotate_90.jpg.txt\n",
            "peacesign 28 23 597 341\n",
            "[['peacesign', '28', '23', '597', '341']]\n",
            "Processing complete for file: peace_8-color0-rotate_90.jpg.txt\n",
            "peace_9-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0-rotate_270.jpg.txt\n",
            "peacesign 18 78 599 396\n",
            "[['peacesign', '18', '78', '599', '396']]\n",
            "Processing complete for file: peace_9-color0-rotate_270.jpg.txt\n",
            "palm_76-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_76-color0-rotate_270.jpg.txt\n",
            "palmhand 156 311 562 540\n",
            "[['palmhand', '156', '311', '562', '540']]\n",
            "Processing complete for file: palm_76-color0-rotate_270.jpg.txt\n",
            "peace_11-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0-rotate_90.jpg.txt\n",
            "peacesign 21 48 445 284\n",
            "[['peacesign', '21', '48', '445', '284']]\n",
            "Processing complete for file: peace_11-color0-rotate_90.jpg.txt\n",
            "peace_18-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0-rotate_180.jpg.txt\n",
            "peacesign 791 187 1113 758\n",
            "[['peacesign', '791', '187', '1113', '758']]\n",
            "peacesign 203 112 536 726\n",
            "[['peacesign', '791', '187', '1113', '758'], ['peacesign', '203', '112', '536', '726']]\n",
            "Processing complete for file: peace_18-color0-rotate_180.jpg.txt\n",
            "peace_65-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_65-color0-rotate_270.jpg.txt\n",
            "peacesign 203 252 603 659\n",
            "[['peacesign', '203', '252', '603', '659']]\n",
            "Processing complete for file: peace_65-color0-rotate_270.jpg.txt\n",
            "peace_11-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0-f0.jpg.txt\n",
            "peacesign 48 21 284 445\n",
            "[['peacesign', '48', '21', '284', '445']]\n",
            "Processing complete for file: peace_11-color0-f0.jpg.txt\n",
            "peace_34-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_34-color0-f0.jpg.txt\n",
            "peacesign 581 313 762 589\n",
            "[['peacesign', '581', '313', '762', '589']]\n",
            "Processing complete for file: peace_34-color0-f0.jpg.txt\n",
            "palm_55-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0-f0.jpg.txt\n",
            "palmhand 507 166 773 581\n",
            "[['palmhand', '507', '166', '773', '581']]\n",
            "Processing complete for file: palm_55-color0-f0.jpg.txt\n",
            "ok_24-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0-rotate_90.jpg.txt\n",
            "oksign 83 184 357 357\n",
            "[['oksign', '83', '184', '357', '357']]\n",
            "Processing complete for file: ok_24-color0-rotate_90.jpg.txt\n",
            "ok_27-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0.jpg.txt\n",
            "oksign 272 94 470 392\n",
            "[['oksign', '272', '94', '470', '392']]\n",
            "Processing complete for file: ok_27-color0.jpg.txt\n",
            "ok_28-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0-rotate_90.jpg.txt\n",
            "oksign 168 152 266 244\n",
            "[['oksign', '168', '152', '266', '244']]\n",
            "oksign 175 386 275 478\n",
            "[['oksign', '168', '152', '266', '244'], ['oksign', '175', '386', '275', '478']]\n",
            "Processing complete for file: ok_28-color0-rotate_90.jpg.txt\n",
            "palm_77-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0-rotate_180.jpg.txt\n",
            "palmhand 379 197 623 581\n",
            "[['palmhand', '379', '197', '623', '581']]\n",
            "Processing complete for file: palm_77-color0-rotate_180.jpg.txt\n",
            "palm_77-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0-f0.jpg.txt\n",
            "palmhand 457 197 701 581\n",
            "[['palmhand', '457', '197', '701', '581']]\n",
            "Processing complete for file: palm_77-color0-f0.jpg.txt\n",
            "ok_3-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0-rotate_90.jpg.txt\n",
            "oksign 402 914 626 1114\n",
            "[['oksign', '402', '914', '626', '1114']]\n",
            "Processing complete for file: ok_3-color0-rotate_90.jpg.txt\n",
            "peace_28-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0-f1.jpg.txt\n",
            "peacesign 141 53 226 188\n",
            "[['peacesign', '141', '53', '226', '188']]\n",
            "Processing complete for file: peace_28-color0-f1.jpg.txt\n",
            "palm_90-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0-f1.jpg.txt\n",
            "palmhand 250 114 536 425\n",
            "[['palmhand', '250', '114', '536', '425']]\n",
            "Processing complete for file: palm_90-color0-f1.jpg.txt\n",
            "peace_16-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0-f1.jpg.txt\n",
            "peacesign 308 34 492 374\n",
            "[['peacesign', '308', '34', '492', '374']]\n",
            "Processing complete for file: peace_16-color0-f1.jpg.txt\n",
            "peace_67-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0-rotate_180.jpg.txt\n",
            "peacesign 435 170 826 597\n",
            "[['peacesign', '435', '170', '826', '597']]\n",
            "Processing complete for file: peace_67-color0-rotate_180.jpg.txt\n",
            "ok_86-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0.jpg.txt\n",
            "oksign 526 273 719 487\n",
            "[['oksign', '526', '273', '719', '487']]\n",
            "Processing complete for file: ok_86-color0.jpg.txt\n",
            "palm_57-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0-rotate_180.jpg.txt\n",
            "palmhand 440 212 721 597\n",
            "[['palmhand', '440', '212', '721', '597']]\n",
            "Processing complete for file: palm_57-color0-rotate_180.jpg.txt\n",
            "ok_78-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0-rotate_180.jpg.txt\n",
            "oksign 494 212 807 599\n",
            "[['oksign', '494', '212', '807', '599']]\n",
            "Processing complete for file: ok_78-color0-rotate_180.jpg.txt\n",
            "peace_59-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0-rotate_270.jpg.txt\n",
            "peacesign 225 93 558 644\n",
            "[['peacesign', '225', '93', '558', '644']]\n",
            "Processing complete for file: peace_59-color0-rotate_270.jpg.txt\n",
            "ok_31-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0-f0.jpg.txt\n",
            "oksign 230 14 435 333\n",
            "[['oksign', '230', '14', '435', '333']]\n",
            "Processing complete for file: ok_31-color0-f0.jpg.txt\n",
            "ok_64-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_64-color0.jpg.txt\n",
            "oksign 517 260 746 469\n",
            "[['oksign', '517', '260', '746', '469']]\n",
            "Processing complete for file: ok_64-color0.jpg.txt\n",
            "peace_26-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_26-color0-rotate_180.jpg.txt\n",
            "peacesign 180 322 678 1149\n",
            "[['peacesign', '180', '322', '678', '1149']]\n",
            "Processing complete for file: peace_26-color0-rotate_180.jpg.txt\n",
            "ok_29-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0.jpg.txt\n",
            "oksign 112 82 284 276\n",
            "[['oksign', '112', '82', '284', '276']]\n",
            "Processing complete for file: ok_29-color0.jpg.txt\n",
            "peace_91-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0-f1.jpg.txt\n",
            "peacesign 579 185 968 605\n",
            "[['peacesign', '579', '185', '968', '605']]\n",
            "Processing complete for file: peace_91-color0-f1.jpg.txt\n",
            "palm_65-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0-rotate_180.jpg.txt\n",
            "palmhand 432 187 836 668\n",
            "[['palmhand', '432', '187', '836', '668']]\n",
            "Processing complete for file: palm_65-color0-rotate_180.jpg.txt\n",
            "palm_2-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0-rotate_270.jpg.txt\n",
            "palmhand 27 125 669 482\n",
            "[['palmhand', '27', '125', '669', '482']]\n",
            "Processing complete for file: palm_2-color0-rotate_270.jpg.txt\n",
            "palm_7-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0-f0.jpg.txt\n",
            "palmhand 48 0 440 677\n",
            "[['palmhand', '48', '0', '440', '677']]\n",
            "Processing complete for file: palm_7-color0-f0.jpg.txt\n",
            "ok_19-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0-rotate_270.jpg.txt\n",
            "oksign 19 644 602 1173\n",
            "[['oksign', '19', '644', '602', '1173']]\n",
            "Processing complete for file: ok_19-color0-rotate_270.jpg.txt\n",
            "ok_93-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0-rotate_180.jpg.txt\n",
            "oksign 82 285 384 476\n",
            "[['oksign', '82', '285', '384', '476']]\n",
            "Processing complete for file: ok_93-color0-rotate_180.jpg.txt\n",
            "ok_92-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0.jpg.txt\n",
            "oksign 521 142 744 433\n",
            "[['oksign', '521', '142', '744', '433']]\n",
            "Processing complete for file: ok_92-color0.jpg.txt\n",
            "peace_92-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0-rotate_270.jpg.txt\n",
            "peacesign 143 175 634 439\n",
            "[['peacesign', '143', '175', '634', '439']]\n",
            "Processing complete for file: peace_92-color0-rotate_270.jpg.txt\n",
            "palm_87-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0-f1.jpg.txt\n",
            "palmhand 338 50 563 421\n",
            "[['palmhand', '338', '50', '563', '421']]\n",
            "Processing complete for file: palm_87-color0-f1.jpg.txt\n",
            "palm_77-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0-f1.jpg.txt\n",
            "palmhand 379 139 623 523\n",
            "[['palmhand', '379', '139', '623', '523']]\n",
            "Processing complete for file: palm_77-color0-f1.jpg.txt\n",
            "palm_70-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0-rotate_90.jpg.txt\n",
            "palmhand 283 530 512 921\n",
            "[['palmhand', '283', '530', '512', '921']]\n",
            "Processing complete for file: palm_70-color0-rotate_90.jpg.txt\n",
            "palm_21-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0-f0.jpg.txt\n",
            "palmhand 317 71 927 815\n",
            "[['palmhand', '317', '71', '927', '815']]\n",
            "Processing complete for file: palm_21-color0-f0.jpg.txt\n",
            "peace_71-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0-f1.jpg.txt\n",
            "peacesign 382 80 716 483\n",
            "[['peacesign', '382', '80', '716', '483']]\n",
            "Processing complete for file: peace_71-color0-f1.jpg.txt\n",
            "ok_15-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_15-color0-rotate_90.jpg.txt\n",
            "oksign 77 88 469 351\n",
            "[['oksign', '77', '88', '469', '351']]\n",
            "Processing complete for file: ok_15-color0-rotate_90.jpg.txt\n",
            "ok_86-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0-rotate_270.jpg.txt\n",
            "oksign 273 361 487 554\n",
            "[['oksign', '273', '361', '487', '554']]\n",
            "Processing complete for file: ok_86-color0-rotate_270.jpg.txt\n",
            "palm_26-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0-rotate_90.jpg.txt\n",
            "palmhand 56 83 457 288\n",
            "[['palmhand', '56', '83', '457', '288']]\n",
            "Processing complete for file: palm_26-color0-rotate_90.jpg.txt\n",
            "palm_34-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0-rotate_90.jpg.txt\n",
            "palmhand 73 80 470 287\n",
            "[['palmhand', '73', '80', '470', '287']]\n",
            "Processing complete for file: palm_34-color0-rotate_90.jpg.txt\n",
            "ok_42-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0-f1.jpg.txt\n",
            "oksign 246 196 525 618\n",
            "[['oksign', '246', '196', '525', '618']]\n",
            "Processing complete for file: ok_42-color0-f1.jpg.txt\n",
            "ok_63-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0-rotate_270.jpg.txt\n",
            "oksign 189 459 456 684\n",
            "[['oksign', '189', '459', '456', '684']]\n",
            "Processing complete for file: ok_63-color0-rotate_270.jpg.txt\n",
            "peace_19-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0-rotate_180.jpg.txt\n",
            "peacesign 708 212 770 274\n",
            "[['peacesign', '708', '212', '770', '274']]\n",
            "peacesign 366 270 435 365\n",
            "[['peacesign', '708', '212', '770', '274'], ['peacesign', '366', '270', '435', '365']]\n",
            "Processing complete for file: peace_19-color0-rotate_180.jpg.txt\n",
            "palm_23-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0-rotate_270.jpg.txt\n",
            "palmhand 189 111 333 538\n",
            "[['palmhand', '189', '111', '333', '538']]\n",
            "Processing complete for file: palm_23-color0-rotate_270.jpg.txt\n",
            "palm_40-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_40-color0-rotate_90.jpg.txt\n",
            "palmhand 51 160 398 660\n",
            "[['palmhand', '51', '160', '398', '660']]\n",
            "Processing complete for file: palm_40-color0-rotate_90.jpg.txt\n",
            "ok_88-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0-rotate_90.jpg.txt\n",
            "oksign 189 369 414 584\n",
            "[['oksign', '189', '369', '414', '584']]\n",
            "Processing complete for file: ok_88-color0-rotate_90.jpg.txt\n",
            "peace_72-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0-f0.jpg.txt\n",
            "peacesign 228 181 559 616\n",
            "[['peacesign', '228', '181', '559', '616']]\n",
            "Processing complete for file: peace_72-color0-f0.jpg.txt\n",
            "ok_13-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0-rotate_90.jpg.txt\n",
            "oksign 220 85 540 329\n",
            "[['oksign', '220', '85', '540', '329']]\n",
            "Processing complete for file: ok_13-color0-rotate_90.jpg.txt\n",
            "ok_77-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0.jpg.txt\n",
            "oksign 448 117 723 537\n",
            "[['oksign', '448', '117', '723', '537']]\n",
            "Processing complete for file: ok_77-color0.jpg.txt\n",
            "ok_87-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0-rotate_180.jpg.txt\n",
            "oksign 440 201 654 441\n",
            "[['oksign', '440', '201', '654', '441']]\n",
            "Processing complete for file: ok_87-color0-rotate_180.jpg.txt\n",
            "palm_26-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0-rotate_180.jpg.txt\n",
            "palmhand 72 56 277 457\n",
            "[['palmhand', '72', '56', '277', '457']]\n",
            "Processing complete for file: palm_26-color0-rotate_180.jpg.txt\n",
            "palm_83-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_83-color0-rotate_180.jpg.txt\n",
            "palmhand 357 278 582 526\n",
            "[['palmhand', '357', '278', '582', '526']]\n",
            "Processing complete for file: palm_83-color0-rotate_180.jpg.txt\n",
            "palm_23-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0-f0.jpg.txt\n",
            "palmhand 154 147 581 291\n",
            "[['palmhand', '154', '147', '581', '291']]\n",
            "Processing complete for file: palm_23-color0-f0.jpg.txt\n",
            "palm_63-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0-f0.jpg.txt\n",
            "palmhand 138 56 657 356\n",
            "[['palmhand', '138', '56', '657', '356']]\n",
            "Processing complete for file: palm_63-color0-f0.jpg.txt\n",
            "palm_14-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0-f1.jpg.txt\n",
            "palmhand 64 112 460 381\n",
            "[['palmhand', '64', '112', '460', '381']]\n",
            "Processing complete for file: palm_14-color0-f1.jpg.txt\n",
            "palm_34-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0-rotate_270.jpg.txt\n",
            "palmhand 10 73 407 280\n",
            "[['palmhand', '10', '73', '407', '280']]\n",
            "Processing complete for file: palm_34-color0-rotate_270.jpg.txt\n",
            "palm_39-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0-rotate_90.jpg.txt\n",
            "palmhand 25 38 473 331\n",
            "[['palmhand', '25', '38', '473', '331']]\n",
            "Processing complete for file: palm_39-color0-rotate_90.jpg.txt\n",
            "peace_54-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0-rotate_90.jpg.txt\n",
            "peacesign 53 472 677 778\n",
            "[['peacesign', '53', '472', '677', '778']]\n",
            "Processing complete for file: peace_54-color0-rotate_90.jpg.txt\n",
            "palm_39-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0-rotate_180.jpg.txt\n",
            "palmhand 29 25 322 473\n",
            "[['palmhand', '29', '25', '322', '473']]\n",
            "Processing complete for file: palm_39-color0-rotate_180.jpg.txt\n",
            "ok_56-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_56-color0-rotate_270.jpg.txt\n",
            "oksign 100 590 473 850\n",
            "[['oksign', '100', '590', '473', '850']]\n",
            "Processing complete for file: ok_56-color0-rotate_270.jpg.txt\n",
            "ok_30-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0-f0.jpg.txt\n",
            "oksign 125 153 606 799\n",
            "[['oksign', '125', '153', '606', '799']]\n",
            "Processing complete for file: ok_30-color0-f0.jpg.txt\n",
            "ok_4-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0-f0.jpg.txt\n",
            "oksign 327 468 496 657\n",
            "[['oksign', '327', '468', '496', '657']]\n",
            "Processing complete for file: ok_4-color0-f0.jpg.txt\n",
            "peace_66-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0-rotate_270.jpg.txt\n",
            "peacesign 107 384 572 615\n",
            "[['peacesign', '107', '384', '572', '615']]\n",
            "Processing complete for file: peace_66-color0-rotate_270.jpg.txt\n",
            "peace_80-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0-rotate_90.jpg.txt\n",
            "peacesign 157 367 533 583\n",
            "[['peacesign', '157', '367', '533', '583']]\n",
            "Processing complete for file: peace_80-color0-rotate_90.jpg.txt\n",
            "palm_58-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0-f0.jpg.txt\n",
            "palmhand 321 214 571 601\n",
            "[['palmhand', '321', '214', '571', '601']]\n",
            "Processing complete for file: palm_58-color0-f0.jpg.txt\n",
            "ok_62-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0-rotate_90.jpg.txt\n",
            "oksign 239 182 468 409\n",
            "[['oksign', '239', '182', '468', '409']]\n",
            "Processing complete for file: ok_62-color0-rotate_90.jpg.txt\n",
            "ok_5-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_5-color0-rotate_90.jpg.txt\n",
            "oksign 360 477 644 711\n",
            "[['oksign', '360', '477', '644', '711']]\n",
            "Processing complete for file: ok_5-color0-rotate_90.jpg.txt\n",
            "palm_1-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0-rotate_270.jpg.txt\n",
            "palmhand 58 86 622 397\n",
            "[['palmhand', '58', '86', '622', '397']]\n",
            "Processing complete for file: palm_1-color0-rotate_270.jpg.txt\n",
            "ok_54-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0-rotate_270.jpg.txt\n",
            "oksign 108 550 433 784\n",
            "[['oksign', '108', '550', '433', '784']]\n",
            "Processing complete for file: ok_54-color0-rotate_270.jpg.txt\n",
            "palm_60-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0-rotate_180.jpg.txt\n",
            "palmhand 117 114 540 383\n",
            "[['palmhand', '117', '114', '540', '383']]\n",
            "Processing complete for file: palm_60-color0-rotate_180.jpg.txt\n",
            "peace_87-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0.jpg.txt\n",
            "peacesign 305 143 696 574\n",
            "[['peacesign', '305', '143', '696', '574']]\n",
            "Processing complete for file: peace_87-color0.jpg.txt\n",
            "palm_81-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0.jpg.txt\n",
            "palmhand 157 106 565 487\n",
            "[['palmhand', '157', '106', '565', '487']]\n",
            "Processing complete for file: palm_81-color0.jpg.txt\n",
            "ok_42-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0.jpg.txt\n",
            "oksign 775 196 1054 618\n",
            "[['oksign', '775', '196', '1054', '618']]\n",
            "Processing complete for file: ok_42-color0.jpg.txt\n",
            "peace_23-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0-rotate_180.jpg.txt\n",
            "peacesign 513 56 981 815\n",
            "[['peacesign', '513', '56', '981', '815']]\n",
            "Processing complete for file: peace_23-color0-rotate_180.jpg.txt\n",
            "ok_86-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0-rotate_90.jpg.txt\n",
            "oksign 233 526 447 719\n",
            "[['oksign', '233', '526', '447', '719']]\n",
            "Processing complete for file: ok_86-color0-rotate_90.jpg.txt\n",
            "ok_54-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0-f1.jpg.txt\n",
            "oksign 550 108 784 433\n",
            "[['oksign', '550', '108', '784', '433']]\n",
            "Processing complete for file: ok_54-color0-f1.jpg.txt\n",
            "ok_89-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0.jpg.txt\n",
            "oksign 317 331 609 521\n",
            "[['oksign', '317', '331', '609', '521']]\n",
            "Processing complete for file: ok_89-color0.jpg.txt\n",
            "ok_4-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0-rotate_90.jpg.txt\n",
            "oksign 468 327 657 496\n",
            "[['oksign', '468', '327', '657', '496']]\n",
            "Processing complete for file: ok_4-color0-rotate_90.jpg.txt\n",
            "ok_22-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0-rotate_180.jpg.txt\n",
            "oksign 305 45 557 429\n",
            "[['oksign', '305', '45', '557', '429']]\n",
            "Processing complete for file: ok_22-color0-rotate_180.jpg.txt\n",
            "palm_9-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0-rotate_180.jpg.txt\n",
            "palmhand 49 33 358 594\n",
            "[['palmhand', '49', '33', '358', '594']]\n",
            "Processing complete for file: palm_9-color0-rotate_180.jpg.txt\n",
            "peace_89-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0.jpg.txt\n",
            "peacesign 512 183 785 636\n",
            "[['peacesign', '512', '183', '785', '636']]\n",
            "Processing complete for file: peace_89-color0.jpg.txt\n",
            "ok_93-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_93-color0-rotate_90.jpg.txt\n",
            "oksign 285 696 476 998\n",
            "[['oksign', '285', '696', '476', '998']]\n",
            "Processing complete for file: ok_93-color0-rotate_90.jpg.txt\n",
            "ok_85-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0-rotate_270.jpg.txt\n",
            "oksign 231 223 483 415\n",
            "[['oksign', '231', '223', '483', '415']]\n",
            "Processing complete for file: ok_85-color0-rotate_270.jpg.txt\n",
            "palm_16-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0-f1.jpg.txt\n",
            "palmhand 146 3 415 318\n",
            "[['palmhand', '146', '3', '415', '318']]\n",
            "palmhand 423 1 642 340\n",
            "[['palmhand', '146', '3', '415', '318'], ['palmhand', '423', '1', '642', '340']]\n",
            "Processing complete for file: palm_16-color0-f1.jpg.txt\n",
            "peace_12-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0-f1.jpg.txt\n",
            "peacesign 73 17 323 439\n",
            "[['peacesign', '73', '17', '323', '439']]\n",
            "Processing complete for file: peace_12-color0-f1.jpg.txt\n",
            "peace_63-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0-rotate_180.jpg.txt\n",
            "peacesign 493 217 724 564\n",
            "[['peacesign', '493', '217', '724', '564']]\n",
            "Processing complete for file: peace_63-color0-rotate_180.jpg.txt\n",
            "palm_26-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_26-color0-f0.jpg.txt\n",
            "palmhand 83 56 288 457\n",
            "[['palmhand', '83', '56', '288', '457']]\n",
            "Processing complete for file: palm_26-color0-f0.jpg.txt\n",
            "palm_34-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0-rotate_180.jpg.txt\n",
            "palmhand 73 73 280 470\n",
            "[['palmhand', '73', '73', '280', '470']]\n",
            "Processing complete for file: palm_34-color0-rotate_180.jpg.txt\n",
            "peace_80-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0-f1.jpg.txt\n",
            "peacesign 497 187 713 563\n",
            "[['peacesign', '497', '187', '713', '563']]\n",
            "Processing complete for file: peace_80-color0-f1.jpg.txt\n",
            "peace_77-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_77-color0-f0.jpg.txt\n",
            "peacesign 154 70 654 604\n",
            "[['peacesign', '154', '70', '654', '604']]\n",
            "Processing complete for file: peace_77-color0-f0.jpg.txt\n",
            "ok_82-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0-rotate_180.jpg.txt\n",
            "oksign 425 176 665 562\n",
            "[['oksign', '425', '176', '665', '562']]\n",
            "Processing complete for file: ok_82-color0-rotate_180.jpg.txt\n",
            "peace_21-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0-f0.jpg.txt\n",
            "peacesign 247 214 487 698\n",
            "[['peacesign', '247', '214', '487', '698']]\n",
            "Processing complete for file: peace_21-color0-f0.jpg.txt\n",
            "peace_16-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0.jpg.txt\n",
            "peacesign 134 34 318 374\n",
            "[['peacesign', '134', '34', '318', '374']]\n",
            "Processing complete for file: peace_16-color0.jpg.txt\n",
            "palm_44-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0-rotate_270.jpg.txt\n",
            "palmhand 65 8 439 560\n",
            "[['palmhand', '65', '8', '439', '560']]\n",
            "Processing complete for file: palm_44-color0-rotate_270.jpg.txt\n",
            "peace_44-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0.jpg.txt\n",
            "peacesign 42 243 143 422\n",
            "[['peacesign', '42', '243', '143', '422']]\n",
            "Processing complete for file: peace_44-color0.jpg.txt\n",
            "ok_76-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_76-color0-rotate_90.jpg.txt\n",
            "oksign 206 590 606 828\n",
            "[['oksign', '206', '590', '606', '828']]\n",
            "Processing complete for file: ok_76-color0-rotate_90.jpg.txt\n",
            "peace_54-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_54-color0-f1.jpg.txt\n",
            "peacesign 302 43 608 667\n",
            "[['peacesign', '302', '43', '608', '667']]\n",
            "Processing complete for file: peace_54-color0-f1.jpg.txt\n",
            "peace_28-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0-rotate_90.jpg.txt\n",
            "peacesign 52 134 187 219\n",
            "[['peacesign', '52', '134', '187', '219']]\n",
            "Processing complete for file: peace_28-color0-rotate_90.jpg.txt\n",
            "ok_70-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0-rotate_90.jpg.txt\n",
            "oksign 314 228 639 463\n",
            "[['oksign', '314', '228', '639', '463']]\n",
            "Processing complete for file: ok_70-color0-rotate_90.jpg.txt\n",
            "ok_68-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0-rotate_180.jpg.txt\n",
            "oksign 582 347 813 699\n",
            "[['oksign', '582', '347', '813', '699']]\n",
            "Processing complete for file: ok_68-color0-rotate_180.jpg.txt\n",
            "palm_58-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0-rotate_270.jpg.txt\n",
            "palmhand 119 509 506 759\n",
            "[['palmhand', '119', '509', '506', '759']]\n",
            "Processing complete for file: palm_58-color0-rotate_270.jpg.txt\n",
            "ok_97-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0-f1.jpg.txt\n",
            "oksign 292 75 500 381\n",
            "[['oksign', '292', '75', '500', '381']]\n",
            "Processing complete for file: ok_97-color0-f1.jpg.txt\n",
            "peace_24-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0-rotate_180.jpg.txt\n",
            "peacesign 562 258 754 613\n",
            "[['peacesign', '562', '258', '754', '613']]\n",
            "Processing complete for file: peace_24-color0-rotate_180.jpg.txt\n",
            "peace_68-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0-f1.jpg.txt\n",
            "peacesign 488 345 933 556\n",
            "[['peacesign', '488', '345', '933', '556']]\n",
            "Processing complete for file: peace_68-color0-f1.jpg.txt\n",
            "palm_15-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_15-color0-f1.jpg.txt\n",
            "palmhand 366 52 667 443\n",
            "[['palmhand', '366', '52', '667', '443']]\n",
            "palmhand 46 52 357 443\n",
            "[['palmhand', '366', '52', '667', '443'], ['palmhand', '46', '52', '357', '443']]\n",
            "Processing complete for file: palm_15-color0-f1.jpg.txt\n",
            "peace_29-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0-rotate_90.jpg.txt\n",
            "peacesign 207 402 1111 862\n",
            "[['peacesign', '207', '402', '1111', '862']]\n",
            "Processing complete for file: peace_29-color0-rotate_90.jpg.txt\n",
            "palm_29-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0-rotate_180.jpg.txt\n",
            "palmhand 82 8 307 450\n",
            "[['palmhand', '82', '8', '307', '450']]\n",
            "Processing complete for file: palm_29-color0-rotate_180.jpg.txt\n",
            "peace_85-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0.jpg.txt\n",
            "peacesign 638 41 992 558\n",
            "[['peacesign', '638', '41', '992', '558']]\n",
            "Processing complete for file: peace_85-color0.jpg.txt\n",
            "palm_85-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_85-color0-f1.jpg.txt\n",
            "palmhand 477 223 838 475\n",
            "[['palmhand', '477', '223', '838', '475']]\n",
            "Processing complete for file: palm_85-color0-f1.jpg.txt\n",
            "ok_80-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_80-color0.jpg.txt\n",
            "oksign 642 156 915 589\n",
            "[['oksign', '642', '156', '915', '589']]\n",
            "Processing complete for file: ok_80-color0.jpg.txt\n",
            "palm_79-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0.jpg.txt\n",
            "palmhand 301 204 511 564\n",
            "[['palmhand', '301', '204', '511', '564']]\n",
            "Processing complete for file: palm_79-color0.jpg.txt\n",
            "palm_39-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0-rotate_270.jpg.txt\n",
            "palmhand 7 29 455 322\n",
            "[['palmhand', '7', '29', '455', '322']]\n",
            "Processing complete for file: palm_39-color0-rotate_270.jpg.txt\n",
            "peace_82-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_82-color0-rotate_180.jpg.txt\n",
            "peacesign 88 133 488 413\n",
            "[['peacesign', '88', '133', '488', '413']]\n",
            "Processing complete for file: peace_82-color0-rotate_180.jpg.txt\n",
            "peace_9-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_9-color0-f1.jpg.txt\n",
            "peacesign 78 18 396 599\n",
            "[['peacesign', '78', '18', '396', '599']]\n",
            "Processing complete for file: peace_9-color0-f1.jpg.txt\n",
            "palm_53-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0-f0.jpg.txt\n",
            "palmhand 498 89 836 628\n",
            "[['palmhand', '498', '89', '836', '628']]\n",
            "Processing complete for file: palm_53-color0-f0.jpg.txt\n",
            "palm_53-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0-rotate_270.jpg.txt\n",
            "palmhand 92 244 631 582\n",
            "[['palmhand', '92', '244', '631', '582']]\n",
            "Processing complete for file: palm_53-color0-rotate_270.jpg.txt\n",
            "ok_90-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0-rotate_90.jpg.txt\n",
            "oksign 216 323 418 588\n",
            "[['oksign', '216', '323', '418', '588']]\n",
            "Processing complete for file: ok_90-color0-rotate_90.jpg.txt\n",
            "palm_54-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0-rotate_90.jpg.txt\n",
            "palmhand 135 305 681 644\n",
            "[['palmhand', '135', '305', '681', '644']]\n",
            "Processing complete for file: palm_54-color0-rotate_90.jpg.txt\n",
            "peace_64-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0-rotate_270.jpg.txt\n",
            "peacesign 367 210 623 684\n",
            "[['peacesign', '367', '210', '623', '684']]\n",
            "Processing complete for file: peace_64-color0-rotate_270.jpg.txt\n",
            "ok_79-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0-rotate_180.jpg.txt\n",
            "oksign 534 189 809 562\n",
            "[['oksign', '534', '189', '809', '562']]\n",
            "Processing complete for file: ok_79-color0-rotate_180.jpg.txt\n",
            "palm_89-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0-rotate_90.jpg.txt\n",
            "palmhand 226 594 491 940\n",
            "[['palmhand', '226', '594', '491', '940']]\n",
            "Processing complete for file: palm_89-color0-rotate_90.jpg.txt\n",
            "peace_40-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0-f0.jpg.txt\n",
            "peacesign 250 128 372 308\n",
            "[['peacesign', '250', '128', '372', '308']]\n",
            "Processing complete for file: peace_40-color0-f0.jpg.txt\n",
            "peace_92-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0-f0.jpg.txt\n",
            "peacesign 641 86 905 577\n",
            "[['peacesign', '641', '86', '905', '577']]\n",
            "Processing complete for file: peace_92-color0-f0.jpg.txt\n",
            "ok_95-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0.jpg.txt\n",
            "oksign 617 175 905 400\n",
            "[['oksign', '617', '175', '905', '400']]\n",
            "Processing complete for file: ok_95-color0.jpg.txt\n",
            "ok_67-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_67-color0-rotate_90.jpg.txt\n",
            "oksign 289 451 606 705\n",
            "[['oksign', '289', '451', '606', '705']]\n",
            "Processing complete for file: ok_67-color0-rotate_90.jpg.txt\n",
            "palm_66-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0.jpg.txt\n",
            "palmhand 398 23 709 542\n",
            "[['palmhand', '398', '23', '709', '542']]\n",
            "Processing complete for file: palm_66-color0.jpg.txt\n",
            "palm_13-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_13-color0-f0.jpg.txt\n",
            "palmhand 695 166 998 697\n",
            "[['palmhand', '695', '166', '998', '697']]\n",
            "palmhand 355 100 689 652\n",
            "[['palmhand', '695', '166', '998', '697'], ['palmhand', '355', '100', '689', '652']]\n",
            "Processing complete for file: palm_13-color0-f0.jpg.txt\n",
            "peace_92-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0-rotate_90.jpg.txt\n",
            "peacesign 86 641 577 905\n",
            "[['peacesign', '86', '641', '577', '905']]\n",
            "Processing complete for file: peace_92-color0-rotate_90.jpg.txt\n",
            "palm_63-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0-rotate_180.jpg.txt\n",
            "palmhand 423 56 942 356\n",
            "[['palmhand', '423', '56', '942', '356']]\n",
            "Processing complete for file: palm_63-color0-rotate_180.jpg.txt\n",
            "palm_14-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0-rotate_180.jpg.txt\n",
            "palmhand 64 99 460 368\n",
            "[['palmhand', '64', '99', '460', '368']]\n",
            "Processing complete for file: palm_14-color0-rotate_180.jpg.txt\n",
            "palm_52-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0-rotate_270.jpg.txt\n",
            "palmhand 67 259 610 654\n",
            "[['palmhand', '67', '259', '610', '654']]\n",
            "Processing complete for file: palm_52-color0-rotate_270.jpg.txt\n",
            "palm_10-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0-rotate_180.jpg.txt\n",
            "palmhand 62 43 366 584\n",
            "[['palmhand', '62', '43', '366', '584']]\n",
            "Processing complete for file: palm_10-color0-rotate_180.jpg.txt\n",
            "palm_79-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0-rotate_90.jpg.txt\n",
            "palmhand 156 301 516 511\n",
            "[['palmhand', '156', '301', '516', '511']]\n",
            "Processing complete for file: palm_79-color0-rotate_90.jpg.txt\n",
            "peace_78-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0-f1.jpg.txt\n",
            "peacesign 397 116 679 621\n",
            "[['peacesign', '397', '116', '679', '621']]\n",
            "Processing complete for file: peace_78-color0-f1.jpg.txt\n",
            "palm_31-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_31-color0-rotate_180.jpg.txt\n",
            "palmhand 31 52 583 314\n",
            "[['palmhand', '31', '52', '583', '314']]\n",
            "Processing complete for file: palm_31-color0-rotate_180.jpg.txt\n",
            "peace_16-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0-rotate_270.jpg.txt\n",
            "peacesign 34 308 374 492\n",
            "[['peacesign', '34', '308', '374', '492']]\n",
            "Processing complete for file: peace_16-color0-rotate_270.jpg.txt\n",
            "palm_28-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0-f1.jpg.txt\n",
            "palmhand 51 194 591 437\n",
            "[['palmhand', '51', '194', '591', '437']]\n",
            "Processing complete for file: palm_28-color0-f1.jpg.txt\n",
            "peace_20-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_20-color0-rotate_180.jpg.txt\n",
            "peacesign 457 184 1067 713\n",
            "[['peacesign', '457', '184', '1067', '713']]\n",
            "Processing complete for file: peace_20-color0-rotate_180.jpg.txt\n",
            "ok_97-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_97-color0.jpg.txt\n",
            "oksign 580 75 788 381\n",
            "[['oksign', '580', '75', '788', '381']]\n",
            "Processing complete for file: ok_97-color0.jpg.txt\n",
            "peace_28-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_28-color0-f0.jpg.txt\n",
            "peacesign 134 52 219 187\n",
            "[['peacesign', '134', '52', '219', '187']]\n",
            "Processing complete for file: peace_28-color0-f0.jpg.txt\n",
            "palm_34-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0.jpg.txt\n",
            "palmhand 80 10 287 407\n",
            "[['palmhand', '80', '10', '287', '407']]\n",
            "Processing complete for file: palm_34-color0.jpg.txt\n",
            "peace_84-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_84-color0-f0.jpg.txt\n",
            "peacesign 434 159 738 628\n",
            "[['peacesign', '434', '159', '738', '628']]\n",
            "Processing complete for file: peace_84-color0-f0.jpg.txt\n",
            "peace_68-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0-f0.jpg.txt\n",
            "peacesign 147 164 592 375\n",
            "[['peacesign', '147', '164', '592', '375']]\n",
            "Processing complete for file: peace_68-color0-f0.jpg.txt\n",
            "ok_91-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0.jpg.txt\n",
            "oksign 390 212 655 439\n",
            "[['oksign', '390', '212', '655', '439']]\n",
            "Processing complete for file: ok_91-color0.jpg.txt\n",
            "peace_25-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0-f0.jpg.txt\n",
            "peacesign 533 321 774 715\n",
            "[['peacesign', '533', '321', '774', '715']]\n",
            "Processing complete for file: peace_25-color0-f0.jpg.txt\n",
            "palm_71-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0-f0.jpg.txt\n",
            "palmhand 148 197 407 458\n",
            "[['palmhand', '148', '197', '407', '458']]\n",
            "Processing complete for file: palm_71-color0-f0.jpg.txt\n",
            "peace_70-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0-rotate_180.jpg.txt\n",
            "peacesign 526 204 793 644\n",
            "[['peacesign', '526', '204', '793', '644']]\n",
            "Processing complete for file: peace_70-color0-rotate_180.jpg.txt\n",
            "palm_23-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0.jpg.txt\n",
            "palmhand 154 189 581 333\n",
            "[['palmhand', '154', '189', '581', '333']]\n",
            "Processing complete for file: palm_23-color0.jpg.txt\n",
            "peace_4-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0-rotate_270.jpg.txt\n",
            "peacesign 21 21 577 437\n",
            "[['peacesign', '21', '21', '577', '437']]\n",
            "Processing complete for file: peace_4-color0-rotate_270.jpg.txt\n",
            "peace_79-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0-f1.jpg.txt\n",
            "peacesign 142 123 535 563\n",
            "[['peacesign', '142', '123', '535', '563']]\n",
            "Processing complete for file: peace_79-color0-f1.jpg.txt\n",
            "palm_71-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0.jpg.txt\n",
            "palmhand 148 262 407 523\n",
            "[['palmhand', '148', '262', '407', '523']]\n",
            "Processing complete for file: palm_71-color0.jpg.txt\n",
            "palm_9-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0-rotate_90.jpg.txt\n",
            "palmhand 33 43 594 352\n",
            "[['palmhand', '33', '43', '594', '352']]\n",
            "Processing complete for file: palm_9-color0-rotate_90.jpg.txt\n",
            "palm_41-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0.jpg.txt\n",
            "palmhand 52 105 339 480\n",
            "[['palmhand', '52', '105', '339', '480']]\n",
            "palmhand 344 61 600 467\n",
            "[['palmhand', '52', '105', '339', '480'], ['palmhand', '344', '61', '600', '467']]\n",
            "Processing complete for file: palm_41-color0.jpg.txt\n",
            "peace_25-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0-rotate_180.jpg.txt\n",
            "peacesign 506 321 747 715\n",
            "[['peacesign', '506', '321', '747', '715']]\n",
            "Processing complete for file: peace_25-color0-rotate_180.jpg.txt\n",
            "ok_57-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_57-color0-rotate_180.jpg.txt\n",
            "oksign 529 241 790 612\n",
            "[['oksign', '529', '241', '790', '612']]\n",
            "Processing complete for file: ok_57-color0-rotate_180.jpg.txt\n",
            "ok_52-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0-rotate_270.jpg.txt\n",
            "oksign 125 334 517 604\n",
            "[['oksign', '125', '334', '517', '604']]\n",
            "Processing complete for file: ok_52-color0-rotate_270.jpg.txt\n",
            "palm_93-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0-rotate_90.jpg.txt\n",
            "palmhand 385 594 576 801\n",
            "[['palmhand', '385', '594', '576', '801']]\n",
            "Processing complete for file: palm_93-color0-rotate_90.jpg.txt\n",
            "palm_38-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0-rotate_180.jpg.txt\n",
            "palmhand 43 36 326 453\n",
            "[['palmhand', '43', '36', '326', '453']]\n",
            "Processing complete for file: palm_38-color0-rotate_180.jpg.txt\n",
            "peace_93-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0-f1.jpg.txt\n",
            "peacesign 453 185 695 634\n",
            "[['peacesign', '453', '185', '695', '634']]\n",
            "Processing complete for file: peace_93-color0-f1.jpg.txt\n",
            "ok_66-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0-f0.jpg.txt\n",
            "oksign 505 226 805 451\n",
            "[['oksign', '505', '226', '805', '451']]\n",
            "Processing complete for file: ok_66-color0-f0.jpg.txt\n",
            "peace_42-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0-rotate_180.jpg.txt\n",
            "peacesign 1089 386 1399 748\n",
            "[['peacesign', '1089', '386', '1399', '748']]\n",
            "peacesign 114 417 414 823\n",
            "[['peacesign', '1089', '386', '1399', '748'], ['peacesign', '114', '417', '414', '823']]\n",
            "Processing complete for file: peace_42-color0-rotate_180.jpg.txt\n",
            "ok_14-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0-f1.jpg.txt\n",
            "oksign 277 7 596 407\n",
            "[['oksign', '277', '7', '596', '407']]\n",
            "Processing complete for file: ok_14-color0-f1.jpg.txt\n",
            "ok_24-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_24-color0-f0.jpg.txt\n",
            "oksign 184 83 357 357\n",
            "[['oksign', '184', '83', '357', '357']]\n",
            "Processing complete for file: ok_24-color0-f0.jpg.txt\n",
            "ok_88-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_88-color0-f1.jpg.txt\n",
            "oksign 496 306 711 531\n",
            "[['oksign', '496', '306', '711', '531']]\n",
            "Processing complete for file: ok_88-color0-f1.jpg.txt\n",
            "peace_93-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0.jpg.txt\n",
            "peacesign 385 185 627 634\n",
            "[['peacesign', '385', '185', '627', '634']]\n",
            "Processing complete for file: peace_93-color0.jpg.txt\n",
            "peace_95-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0-rotate_180.jpg.txt\n",
            "peacesign 375 166 646 613\n",
            "[['peacesign', '375', '166', '646', '613']]\n",
            "Processing complete for file: peace_95-color0-rotate_180.jpg.txt\n",
            "peace_79-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_79-color0.jpg.txt\n",
            "peacesign 545 123 938 563\n",
            "[['peacesign', '545', '123', '938', '563']]\n",
            "Processing complete for file: peace_79-color0.jpg.txt\n",
            "palm_22-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_22-color0.jpg.txt\n",
            "palmhand 71 69 325 414\n",
            "[['palmhand', '71', '69', '325', '414']]\n",
            "palmhand 330 66 572 411\n",
            "[['palmhand', '71', '69', '325', '414'], ['palmhand', '330', '66', '572', '411']]\n",
            "Processing complete for file: palm_22-color0.jpg.txt\n",
            "palm_44-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0-rotate_180.jpg.txt\n",
            "palmhand 8 41 560 415\n",
            "[['palmhand', '8', '41', '560', '415']]\n",
            "Processing complete for file: palm_44-color0-rotate_180.jpg.txt\n",
            "peace_61-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_61-color0-f1.jpg.txt\n",
            "peacesign 190 72 459 407\n",
            "[['peacesign', '190', '72', '459', '407']]\n",
            "Processing complete for file: peace_61-color0-f1.jpg.txt\n",
            "ok_35-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0-rotate_90.jpg.txt\n",
            "oksign 7 224 148 317\n",
            "[['oksign', '7', '224', '148', '317']]\n",
            "Processing complete for file: ok_35-color0-rotate_90.jpg.txt\n",
            "peace_16-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_16-color0-rotate_180.jpg.txt\n",
            "peacesign 308 43 492 383\n",
            "[['peacesign', '308', '43', '492', '383']]\n",
            "Processing complete for file: peace_16-color0-rotate_180.jpg.txt\n",
            "peace_4-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_4-color0-f1.jpg.txt\n",
            "peacesign 21 21 437 577\n",
            "[['peacesign', '21', '21', '437', '577']]\n",
            "Processing complete for file: peace_4-color0-f1.jpg.txt\n",
            "ok_82-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0-f1.jpg.txt\n",
            "oksign 425 158 665 544\n",
            "[['oksign', '425', '158', '665', '544']]\n",
            "Processing complete for file: ok_82-color0-f1.jpg.txt\n",
            "peace_66-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0.jpg.txt\n",
            "peacesign 465 107 696 572\n",
            "[['peacesign', '465', '107', '696', '572']]\n",
            "Processing complete for file: peace_66-color0.jpg.txt\n",
            "peace_5-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0-f0.jpg.txt\n",
            "peacesign 38 24 353 587\n",
            "[['peacesign', '38', '24', '353', '587']]\n",
            "Processing complete for file: peace_5-color0-f0.jpg.txt\n",
            "ok_23-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0-f1.jpg.txt\n",
            "oksign 120 132 339 444\n",
            "[['oksign', '120', '132', '339', '444']]\n",
            "Processing complete for file: ok_23-color0-f1.jpg.txt\n",
            "peace_90-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0-rotate_90.jpg.txt\n",
            "peacesign 122 358 573 618\n",
            "[['peacesign', '122', '358', '573', '618']]\n",
            "Processing complete for file: peace_90-color0-rotate_90.jpg.txt\n",
            "ok_35-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0-f0.jpg.txt\n",
            "oksign 224 7 317 148\n",
            "[['oksign', '224', '7', '317', '148']]\n",
            "Processing complete for file: ok_35-color0-f0.jpg.txt\n",
            "peace_86-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0-f0.jpg.txt\n",
            "peacesign 298 130 725 475\n",
            "[['peacesign', '298', '130', '725', '475']]\n",
            "Processing complete for file: peace_86-color0-f0.jpg.txt\n",
            "ok_30-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_30-color0-f1.jpg.txt\n",
            "oksign 94 247 575 893\n",
            "[['oksign', '94', '247', '575', '893']]\n",
            "Processing complete for file: ok_30-color0-f1.jpg.txt\n",
            "palm_57-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0-f0.jpg.txt\n",
            "palmhand 359 212 640 597\n",
            "[['palmhand', '359', '212', '640', '597']]\n",
            "Processing complete for file: palm_57-color0-f0.jpg.txt\n",
            "ok_40-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0-rotate_90.jpg.txt\n",
            "oksign 459 313 705 562\n",
            "[['oksign', '459', '313', '705', '562']]\n",
            "Processing complete for file: ok_40-color0-rotate_90.jpg.txt\n",
            "palm_91-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0-f1.jpg.txt\n",
            "palmhand 350 73 569 398\n",
            "[['palmhand', '350', '73', '569', '398']]\n",
            "Processing complete for file: palm_91-color0-f1.jpg.txt\n",
            "palm_62-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0-f0.jpg.txt\n",
            "palmhand 380 222 661 660\n",
            "[['palmhand', '380', '222', '661', '660']]\n",
            "Processing complete for file: palm_62-color0-f0.jpg.txt\n",
            "peace_56-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_56-color0-f1.jpg.txt\n",
            "peacesign 513 178 770 618\n",
            "[['peacesign', '513', '178', '770', '618']]\n",
            "Processing complete for file: peace_56-color0-f1.jpg.txt\n",
            "palm_65-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0.jpg.txt\n",
            "palmhand 244 52 648 533\n",
            "[['palmhand', '244', '52', '648', '533']]\n",
            "Processing complete for file: palm_65-color0.jpg.txt\n",
            "ok_16-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0-f0.jpg.txt\n",
            "oksign 191 92 736 926\n",
            "[['oksign', '191', '92', '736', '926']]\n",
            "Processing complete for file: ok_16-color0-f0.jpg.txt\n",
            "ok_6-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0-rotate_270.jpg.txt\n",
            "oksign 138 245 715 705\n",
            "[['oksign', '138', '245', '715', '705']]\n",
            "Processing complete for file: ok_6-color0-rotate_270.jpg.txt\n",
            "ok_79-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_79-color0-rotate_90.jpg.txt\n",
            "oksign 189 271 562 546\n",
            "[['oksign', '189', '271', '562', '546']]\n",
            "Processing complete for file: ok_79-color0-rotate_90.jpg.txt\n",
            "peace_7-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_7-color0-f1.jpg.txt\n",
            "peacesign 61 1 380 571\n",
            "[['peacesign', '61', '1', '380', '571']]\n",
            "Processing complete for file: peace_7-color0-f1.jpg.txt\n",
            "peace_30-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0-f1.jpg.txt\n",
            "peacesign 435 96 526 249\n",
            "[['peacesign', '435', '96', '526', '249']]\n",
            "Processing complete for file: peace_30-color0-f1.jpg.txt\n",
            "palm_80-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_80-color0-rotate_90.jpg.txt\n",
            "palmhand 183 696 683 988\n",
            "[['palmhand', '183', '696', '683', '988']]\n",
            "Processing complete for file: palm_80-color0-rotate_90.jpg.txt\n",
            "ok_60-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0-f0.jpg.txt\n",
            "oksign 376 197 659 635\n",
            "[['oksign', '376', '197', '659', '635']]\n",
            "Processing complete for file: ok_60-color0-f0.jpg.txt\n",
            "peace_19-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0-rotate_90.jpg.txt\n",
            "peacesign 212 510 274 572\n",
            "[['peacesign', '212', '510', '274', '572']]\n",
            "peacesign 270 845 365 914\n",
            "[['peacesign', '212', '510', '274', '572'], ['peacesign', '270', '845', '365', '914']]\n",
            "Processing complete for file: peace_19-color0-rotate_90.jpg.txt\n",
            "peace_52-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0-rotate_270.jpg.txt\n",
            "peacesign 58 330 652 775\n",
            "[['peacesign', '58', '330', '652', '775']]\n",
            "Processing complete for file: peace_52-color0-rotate_270.jpg.txt\n",
            "ok_47-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0-f0.jpg.txt\n",
            "oksign 80 207 204 361\n",
            "[['oksign', '80', '207', '204', '361']]\n",
            "oksign 349 166 501 333\n",
            "[['oksign', '80', '207', '204', '361'], ['oksign', '349', '166', '501', '333']]\n",
            "Processing complete for file: ok_47-color0-f0.jpg.txt\n",
            "ok_69-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0-rotate_180.jpg.txt\n",
            "oksign 709 278 1004 553\n",
            "[['oksign', '709', '278', '1004', '553']]\n",
            "Processing complete for file: ok_69-color0-rotate_180.jpg.txt\n",
            "ok_25-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0-rotate_90.jpg.txt\n",
            "oksign 497 1006 1784 2106\n",
            "[['oksign', '497', '1006', '1784', '2106']]\n",
            "Processing complete for file: ok_25-color0-rotate_90.jpg.txt\n",
            "ok_39-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0-f1.jpg.txt\n",
            "oksign 311 54 566 454\n",
            "[['oksign', '311', '54', '566', '454']]\n",
            "Processing complete for file: ok_39-color0-f1.jpg.txt\n",
            "peace_66-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_66-color0-rotate_90.jpg.txt\n",
            "peacesign 148 465 613 696\n",
            "[['peacesign', '148', '465', '613', '696']]\n",
            "Processing complete for file: peace_66-color0-rotate_90.jpg.txt\n",
            "ok_61-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0-rotate_180.jpg.txt\n",
            "oksign 402 322 657 697\n",
            "[['oksign', '402', '322', '657', '697']]\n",
            "Processing complete for file: ok_61-color0-rotate_180.jpg.txt\n",
            "palm_17-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0-f0.jpg.txt\n",
            "palmhand 206 135 521 308\n",
            "[['palmhand', '206', '135', '521', '308']]\n",
            "Processing complete for file: palm_17-color0-f0.jpg.txt\n",
            "peace_44-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_44-color0-f1.jpg.txt\n",
            "peacesign 564 243 665 422\n",
            "[['peacesign', '564', '243', '665', '422']]\n",
            "Processing complete for file: peace_44-color0-f1.jpg.txt\n",
            "ok_35-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0-rotate_270.jpg.txt\n",
            "oksign 230 363 371 456\n",
            "[['oksign', '230', '363', '371', '456']]\n",
            "Processing complete for file: ok_35-color0-rotate_270.jpg.txt\n",
            "peace_18-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0-f1.jpg.txt\n",
            "peacesign 791 95 1113 666\n",
            "[['peacesign', '791', '95', '1113', '666']]\n",
            "peacesign 203 127 536 741\n",
            "[['peacesign', '791', '95', '1113', '666'], ['peacesign', '203', '127', '536', '741']]\n",
            "Processing complete for file: peace_18-color0-f1.jpg.txt\n",
            "ok_34-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0-rotate_180.jpg.txt\n",
            "oksign 72 99 252 357\n",
            "[['oksign', '72', '99', '252', '357']]\n",
            "Processing complete for file: ok_34-color0-rotate_180.jpg.txt\n",
            "ok_23-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0-rotate_270.jpg.txt\n",
            "oksign 132 120 444 339\n",
            "[['oksign', '132', '120', '444', '339']]\n",
            "Processing complete for file: ok_23-color0-rotate_270.jpg.txt\n",
            "palm_42-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0-rotate_180.jpg.txt\n",
            "palmhand 151 177 388 314\n",
            "[['palmhand', '151', '177', '388', '314']]\n",
            "Processing complete for file: palm_42-color0-rotate_180.jpg.txt\n",
            "peace_83-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_83-color0-f0.jpg.txt\n",
            "peacesign 423 175 665 533\n",
            "[['peacesign', '423', '175', '665', '533']]\n",
            "Processing complete for file: peace_83-color0-f0.jpg.txt\n",
            "palm_35-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_35-color0-f0.jpg.txt\n",
            "palmhand 153 17 557 457\n",
            "[['palmhand', '153', '17', '557', '457']]\n",
            "Processing complete for file: palm_35-color0-f0.jpg.txt\n",
            "palm_37-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0-rotate_180.jpg.txt\n",
            "palmhand 52 37 326 466\n",
            "[['palmhand', '52', '37', '326', '466']]\n",
            "Processing complete for file: palm_37-color0-rotate_180.jpg.txt\n",
            "ok_65-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0-rotate_180.jpg.txt\n",
            "oksign 282 162 611 385\n",
            "[['oksign', '282', '162', '611', '385']]\n",
            "Processing complete for file: ok_65-color0-rotate_180.jpg.txt\n",
            "ok_69-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0-rotate_90.jpg.txt\n",
            "oksign 278 76 553 371\n",
            "[['oksign', '278', '76', '553', '371']]\n",
            "Processing complete for file: ok_69-color0-rotate_90.jpg.txt\n",
            "palm_67-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0-f1.jpg.txt\n",
            "palmhand 652 129 957 423\n",
            "[['palmhand', '652', '129', '957', '423']]\n",
            "Processing complete for file: palm_67-color0-f1.jpg.txt\n",
            "palm_43-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_43-color0.jpg.txt\n",
            "palmhand 68 113 417 351\n",
            "[['palmhand', '68', '113', '417', '351']]\n",
            "Processing complete for file: palm_43-color0.jpg.txt\n",
            "peace_6-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0-f0.jpg.txt\n",
            "peacesign 33 38 356 591\n",
            "[['peacesign', '33', '38', '356', '591']]\n",
            "Processing complete for file: peace_6-color0-f0.jpg.txt\n",
            "ok_20-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_20-color0-rotate_270.jpg.txt\n",
            "oksign 62 160 382 368\n",
            "[['oksign', '62', '160', '382', '368']]\n",
            "Processing complete for file: ok_20-color0-rotate_270.jpg.txt\n",
            "peace_21-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0.jpg.txt\n",
            "peacesign 247 155 487 639\n",
            "[['peacesign', '247', '155', '487', '639']]\n",
            "Processing complete for file: peace_21-color0.jpg.txt\n",
            "palm_88-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0-rotate_270.jpg.txt\n",
            "palmhand 319 102 523 473\n",
            "[['palmhand', '319', '102', '523', '473']]\n",
            "Processing complete for file: palm_88-color0-rotate_270.jpg.txt\n",
            "palm_58-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0-rotate_180.jpg.txt\n",
            "palmhand 509 214 759 601\n",
            "[['palmhand', '509', '214', '759', '601']]\n",
            "Processing complete for file: palm_58-color0-rotate_180.jpg.txt\n",
            "peace_92-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0-f1.jpg.txt\n",
            "peacesign 175 143 439 634\n",
            "[['peacesign', '175', '143', '439', '634']]\n",
            "Processing complete for file: peace_92-color0-f1.jpg.txt\n",
            "palm_70-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_70-color0-f1.jpg.txt\n",
            "palmhand 159 208 550 437\n",
            "[['palmhand', '159', '208', '550', '437']]\n",
            "Processing complete for file: palm_70-color0-f1.jpg.txt\n",
            "peace_85-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0-f0.jpg.txt\n",
            "peacesign 638 162 992 679\n",
            "[['peacesign', '638', '162', '992', '679']]\n",
            "Processing complete for file: peace_85-color0-f0.jpg.txt\n",
            "ok_66-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_66-color0-rotate_180.jpg.txt\n",
            "oksign 275 226 575 451\n",
            "[['oksign', '275', '226', '575', '451']]\n",
            "Processing complete for file: ok_66-color0-rotate_180.jpg.txt\n",
            "palm_66-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0-f1.jpg.txt\n",
            "palmhand 371 23 682 542\n",
            "[['palmhand', '371', '23', '682', '542']]\n",
            "Processing complete for file: palm_66-color0-f1.jpg.txt\n",
            "palm_17-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0.jpg.txt\n",
            "palmhand 206 172 521 345\n",
            "[['palmhand', '206', '172', '521', '345']]\n",
            "Processing complete for file: palm_17-color0.jpg.txt\n",
            "peace_81-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0-rotate_180.jpg.txt\n",
            "peacesign 266 190 590 557\n",
            "[['peacesign', '266', '190', '590', '557']]\n",
            "Processing complete for file: peace_81-color0-rotate_180.jpg.txt\n",
            "palm_32-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0-f0.jpg.txt\n",
            "palmhand 175 28 417 466\n",
            "[['palmhand', '175', '28', '417', '466']]\n",
            "Processing complete for file: palm_32-color0-f0.jpg.txt\n",
            "peace_27-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0-f1.jpg.txt\n",
            "peacesign 169 160 339 492\n",
            "[['peacesign', '169', '160', '339', '492']]\n",
            "Processing complete for file: peace_27-color0-f1.jpg.txt\n",
            "ok_36-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_36-color0-f1.jpg.txt\n",
            "oksign 235 87 344 247\n",
            "[['oksign', '235', '87', '344', '247']]\n",
            "Processing complete for file: ok_36-color0-f1.jpg.txt\n",
            "ok_62-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_62-color0-rotate_180.jpg.txt\n",
            "oksign 671 239 898 468\n",
            "[['oksign', '671', '239', '898', '468']]\n",
            "Processing complete for file: ok_62-color0-rotate_180.jpg.txt\n",
            "palm_8-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0.jpg.txt\n",
            "palmhand 61 23 402 626\n",
            "[['palmhand', '61', '23', '402', '626']]\n",
            "Processing complete for file: palm_8-color0.jpg.txt\n",
            "palm_67-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0-rotate_90.jpg.txt\n",
            "palmhand 297 123 591 428\n",
            "[['palmhand', '297', '123', '591', '428']]\n",
            "Processing complete for file: palm_67-color0-rotate_90.jpg.txt\n",
            "ok_31-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_31-color0.jpg.txt\n",
            "oksign 230 18 435 337\n",
            "[['oksign', '230', '18', '435', '337']]\n",
            "Processing complete for file: ok_31-color0.jpg.txt\n",
            "peace_24-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_24-color0-f0.jpg.txt\n",
            "peacesign 526 258 718 613\n",
            "[['peacesign', '526', '258', '718', '613']]\n",
            "Processing complete for file: peace_24-color0-f0.jpg.txt\n",
            "peace_29-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_29-color0-rotate_180.jpg.txt\n",
            "peacesign 388 207 848 1111\n",
            "[['peacesign', '388', '207', '848', '1111']]\n",
            "Processing complete for file: peace_29-color0-rotate_180.jpg.txt\n",
            "ok_40-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0-rotate_270.jpg.txt\n",
            "oksign 161 738 407 987\n",
            "[['oksign', '161', '738', '407', '987']]\n",
            "Processing complete for file: ok_40-color0-rotate_270.jpg.txt\n",
            "palm_66-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0-f0.jpg.txt\n",
            "palmhand 398 178 709 697\n",
            "[['palmhand', '398', '178', '709', '697']]\n",
            "Processing complete for file: palm_66-color0-f0.jpg.txt\n",
            "ok_3-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0-f0.jpg.txt\n",
            "oksign 914 402 1114 626\n",
            "[['oksign', '914', '402', '1114', '626']]\n",
            "Processing complete for file: ok_3-color0-f0.jpg.txt\n",
            "ok_77-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0-rotate_90.jpg.txt\n",
            "oksign 183 448 603 723\n",
            "[['oksign', '183', '448', '603', '723']]\n",
            "Processing complete for file: ok_77-color0-rotate_90.jpg.txt\n",
            "palm_91-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_91-color0-rotate_180.jpg.txt\n",
            "palmhand 350 322 569 647\n",
            "[['palmhand', '350', '322', '569', '647']]\n",
            "Processing complete for file: palm_91-color0-rotate_180.jpg.txt\n",
            "peace_31-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0-rotate_180.jpg.txt\n",
            "peacesign 109 194 609 1035\n",
            "[['peacesign', '109', '194', '609', '1035']]\n",
            "Processing complete for file: peace_31-color0-rotate_180.jpg.txt\n",
            "ok_96-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_96-color0-rotate_180.jpg.txt\n",
            "oksign 215 337 425 595\n",
            "[['oksign', '215', '337', '425', '595']]\n",
            "Processing complete for file: ok_96-color0-rotate_180.jpg.txt\n",
            "peace_64-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0-f1.jpg.txt\n",
            "peacesign 210 367 684 623\n",
            "[['peacesign', '210', '367', '684', '623']]\n",
            "Processing complete for file: peace_64-color0-f1.jpg.txt\n",
            "ok_19-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_19-color0-f0.jpg.txt\n",
            "oksign 27 30 556 613\n",
            "[['oksign', '27', '30', '556', '613']]\n",
            "Processing complete for file: ok_19-color0-f0.jpg.txt\n",
            "peace_6-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0.jpg.txt\n",
            "peacesign 33 12 356 565\n",
            "[['peacesign', '33', '12', '356', '565']]\n",
            "Processing complete for file: peace_6-color0.jpg.txt\n",
            "palm_62-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0-rotate_270.jpg.txt\n",
            "palmhand 60 419 498 700\n",
            "[['palmhand', '60', '419', '498', '700']]\n",
            "Processing complete for file: palm_62-color0-rotate_270.jpg.txt\n",
            "ok_43-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0-f0.jpg.txt\n",
            "oksign 388 156 516 337\n",
            "[['oksign', '388', '156', '516', '337']]\n",
            "Processing complete for file: ok_43-color0-f0.jpg.txt\n",
            "peace_38-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0-f1.jpg.txt\n",
            "peacesign 781 160 1062 559\n",
            "[['peacesign', '781', '160', '1062', '559']]\n",
            "Processing complete for file: peace_38-color0-f1.jpg.txt\n",
            "palm_57-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0.jpg.txt\n",
            "palmhand 359 123 640 508\n",
            "[['palmhand', '359', '123', '640', '508']]\n",
            "Processing complete for file: palm_57-color0.jpg.txt\n",
            "ok_25-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0-rotate_180.jpg.txt\n",
            "oksign 1126 497 2226 1784\n",
            "[['oksign', '1126', '497', '2226', '1784']]\n",
            "Processing complete for file: ok_25-color0-rotate_180.jpg.txt\n",
            "ok_2-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0-f0.jpg.txt\n",
            "oksign 340 301 771 942\n",
            "[['oksign', '340', '301', '771', '942']]\n",
            "Processing complete for file: ok_2-color0-f0.jpg.txt\n",
            "peace_1-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0.jpg.txt\n",
            "peacesign 31 25 355 589\n",
            "[['peacesign', '31', '25', '355', '589']]\n",
            "Processing complete for file: peace_1-color0.jpg.txt\n",
            "ok_90-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0-rotate_180.jpg.txt\n",
            "oksign 492 216 757 418\n",
            "[['oksign', '492', '216', '757', '418']]\n",
            "Processing complete for file: ok_90-color0-rotate_180.jpg.txt\n",
            "palm_2-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_2-color0-f1.jpg.txt\n",
            "palmhand 125 27 482 669\n",
            "[['palmhand', '125', '27', '482', '669']]\n",
            "Processing complete for file: palm_2-color0-f1.jpg.txt\n",
            "peace_96-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_96-color0-rotate_90.jpg.txt\n",
            "peacesign 159 310 642 547\n",
            "[['peacesign', '159', '310', '642', '547']]\n",
            "Processing complete for file: peace_96-color0-rotate_90.jpg.txt\n",
            "ok_44-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0.jpg.txt\n",
            "oksign 153 16 310 236\n",
            "[['oksign', '153', '16', '310', '236']]\n",
            "Processing complete for file: ok_44-color0.jpg.txt\n",
            "peace_12-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_12-color0.jpg.txt\n",
            "peacesign 28 17 278 439\n",
            "[['peacesign', '28', '17', '278', '439']]\n",
            "Processing complete for file: peace_12-color0.jpg.txt\n",
            "peace_94-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0-rotate_180.jpg.txt\n",
            "peacesign 615 99 848 510\n",
            "[['peacesign', '615', '99', '848', '510']]\n",
            "Processing complete for file: peace_94-color0-rotate_180.jpg.txt\n",
            "palm_10-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_10-color0-f0.jpg.txt\n",
            "palmhand 41 43 345 584\n",
            "[['palmhand', '41', '43', '345', '584']]\n",
            "Processing complete for file: palm_10-color0-f0.jpg.txt\n",
            "palm_92-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0-rotate_180.jpg.txt\n",
            "palmhand 467 312 661 601\n",
            "[['palmhand', '467', '312', '661', '601']]\n",
            "Processing complete for file: palm_92-color0-rotate_180.jpg.txt\n",
            "palm_37-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0.jpg.txt\n",
            "palmhand 34 14 308 443\n",
            "[['palmhand', '34', '14', '308', '443']]\n",
            "Processing complete for file: palm_37-color0.jpg.txt\n",
            "palm_27-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0-f1.jpg.txt\n",
            "palmhand 400 30 666 464\n",
            "[['palmhand', '400', '30', '666', '464']]\n",
            "Processing complete for file: palm_27-color0-f1.jpg.txt\n",
            "peace_18-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_18-color0.jpg.txt\n",
            "peacesign 167 95 489 666\n",
            "[['peacesign', '167', '95', '489', '666']]\n",
            "peacesign 744 127 1077 741\n",
            "[['peacesign', '167', '95', '489', '666'], ['peacesign', '744', '127', '1077', '741']]\n",
            "Processing complete for file: peace_18-color0.jpg.txt\n",
            "ok_34-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_34-color0.jpg.txt\n",
            "oksign 298 104 478 362\n",
            "[['oksign', '298', '104', '478', '362']]\n",
            "Processing complete for file: ok_34-color0.jpg.txt\n",
            "palm_39-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0.jpg.txt\n",
            "palmhand 38 7 331 455\n",
            "[['palmhand', '38', '7', '331', '455']]\n",
            "Processing complete for file: palm_39-color0.jpg.txt\n",
            "ok_35-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_35-color0.jpg.txt\n",
            "oksign 224 230 317 371\n",
            "[['oksign', '224', '230', '317', '371']]\n",
            "Processing complete for file: ok_35-color0.jpg.txt\n",
            "peace_21-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_21-color0-f1.jpg.txt\n",
            "peacesign 793 155 1033 639\n",
            "[['peacesign', '793', '155', '1033', '639']]\n",
            "Processing complete for file: peace_21-color0-f1.jpg.txt\n",
            "ok_72-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0.jpg.txt\n",
            "oksign 457 50 713 408\n",
            "[['oksign', '457', '50', '713', '408']]\n",
            "Processing complete for file: ok_72-color0.jpg.txt\n",
            "palm_18-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_18-color0-rotate_180.jpg.txt\n",
            "palmhand 35 71 605 385\n",
            "[['palmhand', '35', '71', '605', '385']]\n",
            "Processing complete for file: palm_18-color0-rotate_180.jpg.txt\n",
            "peace_88-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0-f1.jpg.txt\n",
            "peacesign 179 161 462 650\n",
            "[['peacesign', '179', '161', '462', '650']]\n",
            "Processing complete for file: peace_88-color0-f1.jpg.txt\n",
            "palm_64-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_64-color0.jpg.txt\n",
            "palmhand 192 217 673 596\n",
            "[['palmhand', '192', '217', '673', '596']]\n",
            "Processing complete for file: palm_64-color0.jpg.txt\n",
            "ok_43-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0-rotate_270.jpg.txt\n",
            "oksign 58 86 239 214\n",
            "[['oksign', '58', '86', '239', '214']]\n",
            "Processing complete for file: ok_43-color0-rotate_270.jpg.txt\n",
            "peace_55-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0-rotate_270.jpg.txt\n",
            "peacesign 41 157 610 648\n",
            "[['peacesign', '41', '157', '610', '648']]\n",
            "Processing complete for file: peace_55-color0-rotate_270.jpg.txt\n",
            "palm_79-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_79-color0-f0.jpg.txt\n",
            "palmhand 301 156 511 516\n",
            "[['palmhand', '301', '156', '511', '516']]\n",
            "Processing complete for file: palm_79-color0-f0.jpg.txt\n",
            "palm_84-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0-f0.jpg.txt\n",
            "palmhand 205 220 603 445\n",
            "[['palmhand', '205', '220', '603', '445']]\n",
            "Processing complete for file: palm_84-color0-f0.jpg.txt\n",
            "palm_17-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_17-color0-rotate_270.jpg.txt\n",
            "palmhand 172 199 345 514\n",
            "[['palmhand', '172', '199', '345', '514']]\n",
            "Processing complete for file: palm_17-color0-rotate_270.jpg.txt\n",
            "palm_52-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0-f1.jpg.txt\n",
            "palmhand 259 67 654 610\n",
            "[['palmhand', '259', '67', '654', '610']]\n",
            "Processing complete for file: palm_52-color0-f1.jpg.txt\n",
            "ok_14-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0-f0.jpg.txt\n",
            "oksign 172 25 491 425\n",
            "[['oksign', '172', '25', '491', '425']]\n",
            "Processing complete for file: ok_14-color0-f0.jpg.txt\n",
            "peace_94-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0-f0.jpg.txt\n",
            "peacesign 232 99 465 510\n",
            "[['peacesign', '232', '99', '465', '510']]\n",
            "Processing complete for file: peace_94-color0-f0.jpg.txt\n",
            "palm_90-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0-rotate_90.jpg.txt\n",
            "palmhand 295 544 606 830\n",
            "[['palmhand', '295', '544', '606', '830']]\n",
            "Processing complete for file: palm_90-color0-rotate_90.jpg.txt\n",
            "ok_44-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0-rotate_180.jpg.txt\n",
            "oksign 490 209 647 429\n",
            "[['oksign', '490', '209', '647', '429']]\n",
            "Processing complete for file: ok_44-color0-rotate_180.jpg.txt\n",
            "palm_8-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0-f1.jpg.txt\n",
            "palmhand 83 23 424 626\n",
            "[['palmhand', '83', '23', '424', '626']]\n",
            "Processing complete for file: palm_8-color0-f1.jpg.txt\n",
            "peace_80-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_80-color0.jpg.txt\n",
            "peacesign 367 187 583 563\n",
            "[['peacesign', '367', '187', '583', '563']]\n",
            "Processing complete for file: peace_80-color0.jpg.txt\n",
            "ok_70-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0-f1.jpg.txt\n",
            "oksign 617 81 852 406\n",
            "[['oksign', '617', '81', '852', '406']]\n",
            "Processing complete for file: ok_70-color0-f1.jpg.txt\n",
            "palm_77-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0.jpg.txt\n",
            "palmhand 457 139 701 523\n",
            "[['palmhand', '457', '139', '701', '523']]\n",
            "Processing complete for file: palm_77-color0.jpg.txt\n",
            "palm_57-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_57-color0-rotate_270.jpg.txt\n",
            "palmhand 123 440 508 721\n",
            "[['palmhand', '123', '440', '508', '721']]\n",
            "Processing complete for file: palm_57-color0-rotate_270.jpg.txt\n",
            "peace_11-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_11-color0-f1.jpg.txt\n",
            "peacesign 67 36 303 460\n",
            "[['peacesign', '67', '36', '303', '460']]\n",
            "Processing complete for file: peace_11-color0-f1.jpg.txt\n",
            "ok_13-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_13-color0-f0.jpg.txt\n",
            "oksign 85 220 329 540\n",
            "[['oksign', '85', '220', '329', '540']]\n",
            "Processing complete for file: ok_13-color0-f0.jpg.txt\n",
            "peace_88-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_88-color0-f0.jpg.txt\n",
            "peacesign 618 70 901 559\n",
            "[['peacesign', '618', '70', '901', '559']]\n",
            "Processing complete for file: peace_88-color0-f0.jpg.txt\n",
            "palm_52-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0.jpg.txt\n",
            "palmhand 426 67 821 610\n",
            "[['palmhand', '426', '67', '821', '610']]\n",
            "Processing complete for file: palm_52-color0.jpg.txt\n",
            "ok_25-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_25-color0-f1.jpg.txt\n",
            "oksign 1126 376 2226 1663\n",
            "[['oksign', '1126', '376', '2226', '1663']]\n",
            "Processing complete for file: ok_25-color0-f1.jpg.txt\n",
            "peace_95-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_95-color0-rotate_90.jpg.txt\n",
            "peacesign 166 434 613 705\n",
            "[['peacesign', '166', '434', '613', '705']]\n",
            "Processing complete for file: peace_95-color0-rotate_90.jpg.txt\n",
            "peace_86-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0.jpg.txt\n",
            "peacesign 298 245 725 590\n",
            "[['peacesign', '298', '245', '725', '590']]\n",
            "Processing complete for file: peace_86-color0.jpg.txt\n",
            "peace_78-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0-rotate_180.jpg.txt\n",
            "peacesign 397 99 679 604\n",
            "[['peacesign', '397', '99', '679', '604']]\n",
            "Processing complete for file: peace_78-color0-rotate_180.jpg.txt\n",
            "ok_52-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_52-color0-f1.jpg.txt\n",
            "oksign 334 125 604 517\n",
            "[['oksign', '334', '125', '604', '517']]\n",
            "Processing complete for file: ok_52-color0-f1.jpg.txt\n",
            "ok_32-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_32-color0.jpg.txt\n",
            "oksign 212 14 459 341\n",
            "[['oksign', '212', '14', '459', '341']]\n",
            "Processing complete for file: ok_32-color0.jpg.txt\n",
            "ok_33-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0-rotate_180.jpg.txt\n",
            "oksign 378 520 735 1033\n",
            "[['oksign', '378', '520', '735', '1033']]\n",
            "Processing complete for file: ok_33-color0-rotate_180.jpg.txt\n",
            "ok_37-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0-rotate_90.jpg.txt\n",
            "oksign 175 191 497 415\n",
            "[['oksign', '175', '191', '497', '415']]\n",
            "Processing complete for file: ok_37-color0-rotate_90.jpg.txt\n",
            "peace_68-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0.jpg.txt\n",
            "peacesign 147 345 592 556\n",
            "[['peacesign', '147', '345', '592', '556']]\n",
            "Processing complete for file: peace_68-color0.jpg.txt\n",
            "peace_72-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0-f1.jpg.txt\n",
            "peacesign 521 104 852 539\n",
            "[['peacesign', '521', '104', '852', '539']]\n",
            "Processing complete for file: peace_72-color0-f1.jpg.txt\n",
            "ok_59-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_59-color0-rotate_90.jpg.txt\n",
            "oksign 226 401 606 676\n",
            "[['oksign', '226', '401', '606', '676']]\n",
            "Processing complete for file: ok_59-color0-rotate_90.jpg.txt\n",
            "ok_78-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0-f0.jpg.txt\n",
            "oksign 273 212 586 599\n",
            "[['oksign', '273', '212', '586', '599']]\n",
            "Processing complete for file: ok_78-color0-f0.jpg.txt\n",
            "ok_28-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_28-color0-rotate_270.jpg.txt\n",
            "oksign 66 388 164 480\n",
            "[['oksign', '66', '388', '164', '480']]\n",
            "oksign 57 154 157 246\n",
            "[['oksign', '66', '388', '164', '480'], ['oksign', '57', '154', '157', '246']]\n",
            "Processing complete for file: ok_28-color0-rotate_270.jpg.txt\n",
            "palm_88-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0-f1.jpg.txt\n",
            "palmhand 102 319 473 523\n",
            "[['palmhand', '102', '319', '473', '523']]\n",
            "Processing complete for file: palm_88-color0-f1.jpg.txt\n",
            "palm_30-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0.jpg.txt\n",
            "palmhand 246 6 521 445\n",
            "[['palmhand', '246', '6', '521', '445']]\n",
            "Processing complete for file: palm_30-color0.jpg.txt\n",
            "ok_72-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0-rotate_270.jpg.txt\n",
            "oksign 50 367 408 623\n",
            "[['oksign', '50', '367', '408', '623']]\n",
            "Processing complete for file: ok_72-color0-rotate_270.jpg.txt\n",
            "peace_22-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_22-color0-rotate_270.jpg.txt\n",
            "peacesign 24 47 1018 892\n",
            "[['peacesign', '24', '47', '1018', '892']]\n",
            "Processing complete for file: peace_22-color0-rotate_270.jpg.txt\n",
            "ok_10-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0-rotate_90.jpg.txt\n",
            "oksign 16 241 634 717\n",
            "[['oksign', '16', '241', '634', '717']]\n",
            "Processing complete for file: ok_10-color0-rotate_90.jpg.txt\n",
            "palm_34-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_34-color0-f0.jpg.txt\n",
            "palmhand 80 73 287 470\n",
            "[['palmhand', '80', '73', '287', '470']]\n",
            "Processing complete for file: palm_34-color0-f0.jpg.txt\n",
            "peace_58-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_58-color0.jpg.txt\n",
            "peacesign 470 125 932 616\n",
            "[['peacesign', '470', '125', '932', '616']]\n",
            "Processing complete for file: peace_58-color0.jpg.txt\n",
            "palm_69-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_69-color0-rotate_180.jpg.txt\n",
            "palmhand 373 310 696 628\n",
            "[['palmhand', '373', '310', '696', '628']]\n",
            "Processing complete for file: palm_69-color0-rotate_180.jpg.txt\n",
            "peace_68-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_68-color0-rotate_270.jpg.txt\n",
            "peacesign 345 488 556 933\n",
            "[['peacesign', '345', '488', '556', '933']]\n",
            "Processing complete for file: peace_68-color0-rotate_270.jpg.txt\n",
            "palm_30-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_30-color0-f1.jpg.txt\n",
            "palmhand 119 6 394 445\n",
            "[['palmhand', '119', '6', '394', '445']]\n",
            "Processing complete for file: palm_30-color0-f1.jpg.txt\n",
            "ok_61-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0-rotate_90.jpg.txt\n",
            "oksign 322 423 697 678\n",
            "[['oksign', '322', '423', '697', '678']]\n",
            "Processing complete for file: ok_61-color0-rotate_90.jpg.txt\n",
            "peace_92-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0.jpg.txt\n",
            "peacesign 641 143 905 634\n",
            "[['peacesign', '641', '143', '905', '634']]\n",
            "Processing complete for file: peace_92-color0.jpg.txt\n",
            "peace_38-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0-rotate_270.jpg.txt\n",
            "peacesign 160 781 559 1062\n",
            "[['peacesign', '160', '781', '559', '1062']]\n",
            "Processing complete for file: peace_38-color0-rotate_270.jpg.txt\n",
            "ok_37-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0.jpg.txt\n",
            "oksign 191 115 415 437\n",
            "[['oksign', '191', '115', '415', '437']]\n",
            "Processing complete for file: ok_37-color0.jpg.txt\n",
            "peace_81-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_81-color0-f1.jpg.txt\n",
            "peacesign 266 163 590 530\n",
            "[['peacesign', '266', '163', '590', '530']]\n",
            "Processing complete for file: peace_81-color0-f1.jpg.txt\n",
            "ok_37-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0-f0.jpg.txt\n",
            "oksign 191 175 415 497\n",
            "[['oksign', '191', '175', '415', '497']]\n",
            "Processing complete for file: ok_37-color0-f0.jpg.txt\n",
            "peace_8-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0-rotate_270.jpg.txt\n",
            "peacesign 8 58 577 376\n",
            "[['peacesign', '8', '58', '577', '376']]\n",
            "Processing complete for file: peace_8-color0-rotate_270.jpg.txt\n",
            "ok_70-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_70-color0-rotate_180.jpg.txt\n",
            "oksign 617 314 852 639\n",
            "[['oksign', '617', '314', '852', '639']]\n",
            "Processing complete for file: ok_70-color0-rotate_180.jpg.txt\n",
            "palm_84-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0-rotate_270.jpg.txt\n",
            "palmhand 275 477 500 875\n",
            "[['palmhand', '275', '477', '500', '875']]\n",
            "Processing complete for file: palm_84-color0-rotate_270.jpg.txt\n",
            "ok_10-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0.jpg.txt\n",
            "oksign 241 47 717 665\n",
            "[['oksign', '241', '47', '717', '665']]\n",
            "Processing complete for file: ok_10-color0.jpg.txt\n",
            "ok_8-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0-rotate_90.jpg.txt\n",
            "oksign 409 75 588 227\n",
            "[['oksign', '409', '75', '588', '227']]\n",
            "Processing complete for file: ok_8-color0-rotate_90.jpg.txt\n",
            "peace_40-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0.jpg.txt\n",
            "peacesign 250 125 372 305\n",
            "[['peacesign', '250', '125', '372', '305']]\n",
            "Processing complete for file: peace_40-color0.jpg.txt\n",
            "ok_6-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0-rotate_90.jpg.txt\n",
            "oksign 450 575 1027 1035\n",
            "[['oksign', '450', '575', '1027', '1035']]\n",
            "Processing complete for file: ok_6-color0-rotate_90.jpg.txt\n",
            "peace_37-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_37-color0-rotate_90.jpg.txt\n",
            "peacesign 211 643 648 922\n",
            "[['peacesign', '211', '643', '648', '922']]\n",
            "Processing complete for file: peace_37-color0-rotate_90.jpg.txt\n",
            "peace_1-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0-f0.jpg.txt\n",
            "peacesign 31 48 355 612\n",
            "[['peacesign', '31', '48', '355', '612']]\n",
            "Processing complete for file: peace_1-color0-f0.jpg.txt\n",
            "ok_82-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_82-color0-rotate_270.jpg.txt\n",
            "oksign 158 425 544 665\n",
            "[['oksign', '158', '425', '544', '665']]\n",
            "Processing complete for file: ok_82-color0-rotate_270.jpg.txt\n",
            "palm_53-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0.jpg.txt\n",
            "palmhand 498 92 836 631\n",
            "[['palmhand', '498', '92', '836', '631']]\n",
            "Processing complete for file: palm_53-color0.jpg.txt\n",
            "palm_54-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0-rotate_180.jpg.txt\n",
            "palmhand 436 135 775 681\n",
            "[['palmhand', '436', '135', '775', '681']]\n",
            "Processing complete for file: palm_54-color0-rotate_180.jpg.txt\n",
            "palm_41-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0-f1.jpg.txt\n",
            "palmhand 381 105 668 480\n",
            "[['palmhand', '381', '105', '668', '480']]\n",
            "palmhand 120 61 376 467\n",
            "[['palmhand', '381', '105', '668', '480'], ['palmhand', '120', '61', '376', '467']]\n",
            "Processing complete for file: palm_41-color0-f1.jpg.txt\n",
            "ok_27-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_27-color0-f0.jpg.txt\n",
            "oksign 272 220 470 518\n",
            "[['oksign', '272', '220', '470', '518']]\n",
            "Processing complete for file: ok_27-color0-f0.jpg.txt\n",
            "peace_67-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_67-color0-rotate_270.jpg.txt\n",
            "peacesign 123 435 550 826\n",
            "[['peacesign', '123', '435', '550', '826']]\n",
            "Processing complete for file: peace_67-color0-rotate_270.jpg.txt\n",
            "peace_8-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_8-color0-rotate_180.jpg.txt\n",
            "peacesign 58 28 376 597\n",
            "[['peacesign', '58', '28', '376', '597']]\n",
            "Processing complete for file: peace_8-color0-rotate_180.jpg.txt\n",
            "palm_42-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_42-color0-f0.jpg.txt\n",
            "palmhand 332 177 569 314\n",
            "[['palmhand', '332', '177', '569', '314']]\n",
            "Processing complete for file: palm_42-color0-f0.jpg.txt\n",
            "peace_25-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0-f1.jpg.txt\n",
            "peacesign 506 138 747 532\n",
            "[['peacesign', '506', '138', '747', '532']]\n",
            "Processing complete for file: peace_25-color0-f1.jpg.txt\n",
            "ok_39-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_39-color0-f0.jpg.txt\n",
            "oksign 334 146 589 546\n",
            "[['oksign', '334', '146', '589', '546']]\n",
            "Processing complete for file: ok_39-color0-f0.jpg.txt\n",
            "ok_89-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0-f1.jpg.txt\n",
            "oksign 471 331 763 521\n",
            "[['oksign', '471', '331', '763', '521']]\n",
            "Processing complete for file: ok_89-color0-f1.jpg.txt\n",
            "peace_86-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0-f1.jpg.txt\n",
            "peacesign 355 245 782 590\n",
            "[['peacesign', '355', '245', '782', '590']]\n",
            "Processing complete for file: peace_86-color0-f1.jpg.txt\n",
            "palm_77-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_77-color0-rotate_270.jpg.txt\n",
            "palmhand 139 379 523 623\n",
            "[['palmhand', '139', '379', '523', '623']]\n",
            "Processing complete for file: palm_77-color0-rotate_270.jpg.txt\n",
            "palm_1-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_1-color0-rotate_180.jpg.txt\n",
            "palmhand 86 59 397 623\n",
            "[['palmhand', '86', '59', '397', '623']]\n",
            "Processing complete for file: palm_1-color0-rotate_180.jpg.txt\n",
            "palm_94-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_94-color0-rotate_180.jpg.txt\n",
            "palmhand 202 318 465 589\n",
            "[['palmhand', '202', '318', '465', '589']]\n",
            "Processing complete for file: palm_94-color0-rotate_180.jpg.txt\n",
            "peace_94-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0-f1.jpg.txt\n",
            "peacesign 615 210 848 621\n",
            "[['peacesign', '615', '210', '848', '621']]\n",
            "Processing complete for file: peace_94-color0-f1.jpg.txt\n",
            "palm_21-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_21-color0-rotate_180.jpg.txt\n",
            "palmhand 353 71 963 815\n",
            "[['palmhand', '353', '71', '963', '815']]\n",
            "Processing complete for file: palm_21-color0-rotate_180.jpg.txt\n",
            "palm_56-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0.jpg.txt\n",
            "palmhand 498 108 767 521\n",
            "[['palmhand', '498', '108', '767', '521']]\n",
            "Processing complete for file: palm_56-color0.jpg.txt\n",
            "peace_59-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0-f0.jpg.txt\n",
            "peacesign 436 162 987 495\n",
            "[['peacesign', '436', '162', '987', '495']]\n",
            "Processing complete for file: peace_59-color0-f0.jpg.txt\n",
            "palm_78-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0-rotate_180.jpg.txt\n",
            "palmhand 432 201 679 572\n",
            "[['palmhand', '432', '201', '679', '572']]\n",
            "Processing complete for file: palm_78-color0-rotate_180.jpg.txt\n",
            "peace_97-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0-rotate_90.jpg.txt\n",
            "peacesign 139 438 622 678\n",
            "[['peacesign', '139', '438', '622', '678']]\n",
            "Processing complete for file: peace_97-color0-rotate_90.jpg.txt\n",
            "peace_59-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_59-color0.jpg.txt\n",
            "peacesign 436 225 987 558\n",
            "[['peacesign', '436', '225', '987', '558']]\n",
            "Processing complete for file: peace_59-color0.jpg.txt\n",
            "peace_64-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_64-color0-f0.jpg.txt\n",
            "peacesign 396 97 870 353\n",
            "[['peacesign', '396', '97', '870', '353']]\n",
            "Processing complete for file: peace_64-color0-f0.jpg.txt\n",
            "ok_83-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0-f0.jpg.txt\n",
            "oksign 576 364 848 668\n",
            "[['oksign', '576', '364', '848', '668']]\n",
            "Processing complete for file: ok_83-color0-f0.jpg.txt\n",
            "peace_43-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_43-color0-rotate_180.jpg.txt\n",
            "peacesign 134 105 573 920\n",
            "[['peacesign', '134', '105', '573', '920']]\n",
            "Processing complete for file: peace_43-color0-rotate_180.jpg.txt\n",
            "peace_38-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_38-color0-f0.jpg.txt\n",
            "peacesign 71 291 352 690\n",
            "[['peacesign', '71', '291', '352', '690']]\n",
            "Processing complete for file: peace_38-color0-f0.jpg.txt\n",
            "palm_60-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0-f1.jpg.txt\n",
            "palmhand 117 337 540 606\n",
            "[['palmhand', '117', '337', '540', '606']]\n",
            "Processing complete for file: palm_60-color0-f1.jpg.txt\n",
            "palm_16-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_16-color0-rotate_180.jpg.txt\n",
            "palmhand 146 162 415 477\n",
            "[['palmhand', '146', '162', '415', '477']]\n",
            "palmhand 423 140 642 479\n",
            "[['palmhand', '146', '162', '415', '477'], ['palmhand', '423', '140', '642', '479']]\n",
            "Processing complete for file: palm_16-color0-rotate_180.jpg.txt\n",
            "palm_23-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_23-color0-f1.jpg.txt\n",
            "palmhand 111 189 538 333\n",
            "[['palmhand', '111', '189', '538', '333']]\n",
            "Processing complete for file: palm_23-color0-f1.jpg.txt\n",
            "peace_10-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_10-color0-f0.jpg.txt\n",
            "peacesign 45 37 374 650\n",
            "[['peacesign', '45', '37', '374', '650']]\n",
            "Processing complete for file: peace_10-color0-f0.jpg.txt\n",
            "ok_54-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0-rotate_180.jpg.txt\n",
            "oksign 550 287 784 612\n",
            "[['oksign', '550', '287', '784', '612']]\n",
            "Processing complete for file: ok_54-color0-rotate_180.jpg.txt\n",
            "palm_8-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0-rotate_90.jpg.txt\n",
            "palmhand 43 61 646 402\n",
            "[['palmhand', '43', '61', '646', '402']]\n",
            "Processing complete for file: palm_8-color0-rotate_90.jpg.txt\n",
            "palm_97-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0-rotate_180.jpg.txt\n",
            "palmhand 234 328 513 606\n",
            "[['palmhand', '234', '328', '513', '606']]\n",
            "Processing complete for file: palm_97-color0-rotate_180.jpg.txt\n",
            "ok_1-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0.jpg.txt\n",
            "oksign 296 123 477 355\n",
            "[['oksign', '296', '123', '477', '355']]\n",
            "Processing complete for file: ok_1-color0.jpg.txt\n",
            "ok_85-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0-rotate_180.jpg.txt\n",
            "oksign 223 237 415 489\n",
            "[['oksign', '223', '237', '415', '489']]\n",
            "Processing complete for file: ok_85-color0-rotate_180.jpg.txt\n",
            "peace_92-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_92-color0-rotate_180.jpg.txt\n",
            "peacesign 175 86 439 577\n",
            "[['peacesign', '175', '86', '439', '577']]\n",
            "Processing complete for file: peace_92-color0-rotate_180.jpg.txt\n",
            "palm_38-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_38-color0-f0.jpg.txt\n",
            "palmhand 34 36 317 453\n",
            "[['palmhand', '34', '36', '317', '453']]\n",
            "Processing complete for file: palm_38-color0-f0.jpg.txt\n",
            "peace_86-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_86-color0-rotate_270.jpg.txt\n",
            "peacesign 245 355 590 782\n",
            "[['peacesign', '245', '355', '590', '782']]\n",
            "Processing complete for file: peace_86-color0-rotate_270.jpg.txt\n",
            "palm_41-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_41-color0-rotate_270.jpg.txt\n",
            "palmhand 105 381 480 668\n",
            "[['palmhand', '105', '381', '480', '668']]\n",
            "palmhand 61 120 467 376\n",
            "[['palmhand', '105', '381', '480', '668'], ['palmhand', '61', '120', '467', '376']]\n",
            "Processing complete for file: palm_41-color0-rotate_270.jpg.txt\n",
            "peace_90-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0-f1.jpg.txt\n",
            "peacesign 462 147 722 598\n",
            "[['peacesign', '462', '147', '722', '598']]\n",
            "Processing complete for file: peace_90-color0-f1.jpg.txt\n",
            "peace_6-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_6-color0-rotate_180.jpg.txt\n",
            "peacesign 91 38 414 591\n",
            "[['peacesign', '91', '38', '414', '591']]\n",
            "Processing complete for file: peace_6-color0-rotate_180.jpg.txt\n",
            "palm_53-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_53-color0-f1.jpg.txt\n",
            "palmhand 244 92 582 631\n",
            "[['palmhand', '244', '92', '582', '631']]\n",
            "Processing complete for file: palm_53-color0-f1.jpg.txt\n",
            "ok_90-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_90-color0-f1.jpg.txt\n",
            "oksign 492 302 757 504\n",
            "[['oksign', '492', '302', '757', '504']]\n",
            "Processing complete for file: ok_90-color0-f1.jpg.txt\n",
            "ok_14-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_14-color0-rotate_270.jpg.txt\n",
            "oksign 7 277 407 596\n",
            "[['oksign', '7', '277', '407', '596']]\n",
            "Processing complete for file: ok_14-color0-rotate_270.jpg.txt\n",
            "palm_5-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0-f1.jpg.txt\n",
            "palmhand 73 21 379 570\n",
            "[['palmhand', '73', '21', '379', '570']]\n",
            "Processing complete for file: palm_5-color0-f1.jpg.txt\n",
            "palm_93-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_93-color0-f0.jpg.txt\n",
            "palmhand 594 385 801 576\n",
            "[['palmhand', '594', '385', '801', '576']]\n",
            "Processing complete for file: palm_93-color0-f0.jpg.txt\n",
            "ok_29-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0-f1.jpg.txt\n",
            "oksign 699 82 871 276\n",
            "[['oksign', '699', '82', '871', '276']]\n",
            "Processing complete for file: ok_29-color0-f1.jpg.txt\n",
            "palm_71-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0-rotate_180.jpg.txt\n",
            "palmhand 673 197 932 458\n",
            "[['palmhand', '673', '197', '932', '458']]\n",
            "Processing complete for file: palm_71-color0-rotate_180.jpg.txt\n",
            "palm_54-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0-f0.jpg.txt\n",
            "palmhand 305 135 644 681\n",
            "[['palmhand', '305', '135', '644', '681']]\n",
            "Processing complete for file: palm_54-color0-f0.jpg.txt\n",
            "ok_10-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_10-color0-rotate_180.jpg.txt\n",
            "oksign 251 16 727 634\n",
            "[['oksign', '251', '16', '727', '634']]\n",
            "Processing complete for file: ok_10-color0-rotate_180.jpg.txt\n",
            "palm_96-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0-rotate_270.jpg.txt\n",
            "palmhand 108 454 398 654\n",
            "[['palmhand', '108', '454', '398', '654']]\n",
            "Processing complete for file: palm_96-color0-rotate_270.jpg.txt\n",
            "peace_91-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_91-color0-rotate_90.jpg.txt\n",
            "peacesign 115 112 535 501\n",
            "[['peacesign', '115', '112', '535', '501']]\n",
            "Processing complete for file: peace_91-color0-rotate_90.jpg.txt\n",
            "ok_91-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_91-color0-rotate_270.jpg.txt\n",
            "oksign 212 425 439 690\n",
            "[['oksign', '212', '425', '439', '690']]\n",
            "Processing complete for file: ok_91-color0-rotate_270.jpg.txt\n",
            "ok_84-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0-f0.jpg.txt\n",
            "oksign 601 268 830 608\n",
            "[['oksign', '601', '268', '830', '608']]\n",
            "Processing complete for file: ok_84-color0-f0.jpg.txt\n",
            "ok_6-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0.jpg.txt\n",
            "oksign 575 138 1035 715\n",
            "[['oksign', '575', '138', '1035', '715']]\n",
            "Processing complete for file: ok_6-color0.jpg.txt\n",
            "peace_31-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_31-color0-rotate_90.jpg.txt\n",
            "peacesign 194 191 1035 691\n",
            "[['peacesign', '194', '191', '1035', '691']]\n",
            "Processing complete for file: peace_31-color0-rotate_90.jpg.txt\n",
            "ok_23-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0-rotate_180.jpg.txt\n",
            "oksign 120 168 339 480\n",
            "[['oksign', '120', '168', '339', '480']]\n",
            "Processing complete for file: ok_23-color0-rotate_180.jpg.txt\n",
            "peace_41-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_41-color0-rotate_90.jpg.txt\n",
            "peacesign 27 391 343 568\n",
            "[['peacesign', '27', '391', '343', '568']]\n",
            "Processing complete for file: peace_41-color0-rotate_90.jpg.txt\n",
            "ok_29-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0-f0.jpg.txt\n",
            "oksign 112 238 284 432\n",
            "[['oksign', '112', '238', '284', '432']]\n",
            "Processing complete for file: ok_29-color0-f0.jpg.txt\n",
            "peace_17-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0.jpg.txt\n",
            "peacesign 79 73 624 381\n",
            "[['peacesign', '79', '73', '624', '381']]\n",
            "peacesign 553 259 1040 903\n",
            "[['peacesign', '79', '73', '624', '381'], ['peacesign', '553', '259', '1040', '903']]\n",
            "Processing complete for file: peace_17-color0.jpg.txt\n",
            "ok_7-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0-rotate_270.jpg.txt\n",
            "oksign 85 858 532 1134\n",
            "[['oksign', '85', '858', '532', '1134']]\n",
            "Processing complete for file: ok_7-color0-rotate_270.jpg.txt\n",
            "ok_1-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0-rotate_270.jpg.txt\n",
            "oksign 123 803 355 984\n",
            "[['oksign', '123', '803', '355', '984']]\n",
            "Processing complete for file: ok_1-color0-rotate_270.jpg.txt\n",
            "ok_42-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_42-color0-rotate_270.jpg.txt\n",
            "oksign 196 246 618 525\n",
            "[['oksign', '196', '246', '618', '525']]\n",
            "Processing complete for file: ok_42-color0-rotate_270.jpg.txt\n",
            "palm_82-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0-rotate_90.jpg.txt\n",
            "palmhand 176 444 672 753\n",
            "[['palmhand', '176', '444', '672', '753']]\n",
            "Processing complete for file: palm_82-color0-rotate_90.jpg.txt\n",
            "ok_83-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_83-color0-rotate_270.jpg.txt\n",
            "oksign 52 232 356 504\n",
            "[['oksign', '52', '232', '356', '504']]\n",
            "Processing complete for file: ok_83-color0-rotate_270.jpg.txt\n",
            "peace_93-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_93-color0-rotate_90.jpg.txt\n",
            "peacesign 86 385 535 627\n",
            "[['peacesign', '86', '385', '535', '627']]\n",
            "Processing complete for file: peace_93-color0-rotate_90.jpg.txt\n",
            "palm_87-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_87-color0.jpg.txt\n",
            "palmhand 517 50 742 421\n",
            "[['palmhand', '517', '50', '742', '421']]\n",
            "Processing complete for file: palm_87-color0.jpg.txt\n",
            "peace_52-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_52-color0-f1.jpg.txt\n",
            "peacesign 330 58 775 652\n",
            "[['peacesign', '330', '58', '775', '652']]\n",
            "Processing complete for file: peace_52-color0-f1.jpg.txt\n",
            "palm_63-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0-rotate_270.jpg.txt\n",
            "palmhand 364 423 664 942\n",
            "[['palmhand', '364', '423', '664', '942']]\n",
            "Processing complete for file: palm_63-color0-rotate_270.jpg.txt\n",
            "palm_27-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0.jpg.txt\n",
            "palmhand 54 30 320 464\n",
            "[['palmhand', '54', '30', '320', '464']]\n",
            "Processing complete for file: palm_27-color0.jpg.txt\n",
            "peace_90-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_90-color0.jpg.txt\n",
            "peacesign 358 147 618 598\n",
            "[['peacesign', '358', '147', '618', '598']]\n",
            "Processing complete for file: peace_90-color0.jpg.txt\n",
            "palm_78-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_78-color0-f0.jpg.txt\n",
            "palmhand 401 201 648 572\n",
            "[['palmhand', '401', '201', '648', '572']]\n",
            "Processing complete for file: palm_78-color0-f0.jpg.txt\n",
            "ok_94-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_94-color0-rotate_180.jpg.txt\n",
            "oksign 190 168 492 649\n",
            "[['oksign', '190', '168', '492', '649']]\n",
            "Processing complete for file: ok_94-color0-rotate_180.jpg.txt\n",
            "ok_84-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0.jpg.txt\n",
            "oksign 601 112 830 452\n",
            "[['oksign', '601', '112', '830', '452']]\n",
            "Processing complete for file: ok_84-color0.jpg.txt\n",
            "peace_89-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0-f1.jpg.txt\n",
            "peacesign 295 183 568 636\n",
            "[['peacesign', '295', '183', '568', '636']]\n",
            "Processing complete for file: peace_89-color0-f1.jpg.txt\n",
            "palm_39-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_39-color0-f1.jpg.txt\n",
            "palmhand 29 7 322 455\n",
            "[['palmhand', '29', '7', '322', '455']]\n",
            "Processing complete for file: palm_39-color0-f1.jpg.txt\n",
            "peace_27-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0-f0.jpg.txt\n",
            "peacesign 197 258 367 590\n",
            "[['peacesign', '197', '258', '367', '590']]\n",
            "Processing complete for file: peace_27-color0-f0.jpg.txt\n",
            "peace_87-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0-rotate_90.jpg.txt\n",
            "peacesign 146 305 577 696\n",
            "[['peacesign', '146', '305', '577', '696']]\n",
            "Processing complete for file: peace_87-color0-rotate_90.jpg.txt\n",
            "ok_16-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_16-color0-f1.jpg.txt\n",
            "oksign 288 98 833 932\n",
            "[['oksign', '288', '98', '833', '932']]\n",
            "Processing complete for file: ok_16-color0-f1.jpg.txt\n",
            "peace_87-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0-rotate_270.jpg.txt\n",
            "peacesign 143 384 574 775\n",
            "[['peacesign', '143', '384', '574', '775']]\n",
            "Processing complete for file: peace_87-color0-rotate_270.jpg.txt\n",
            "palm_56-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_56-color0-rotate_90.jpg.txt\n",
            "palmhand 199 498 612 767\n",
            "[['palmhand', '199', '498', '612', '767']]\n",
            "Processing complete for file: palm_56-color0-rotate_90.jpg.txt\n",
            "palm_67-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0-rotate_180.jpg.txt\n",
            "palmhand 652 297 957 591\n",
            "[['palmhand', '652', '297', '957', '591']]\n",
            "Processing complete for file: palm_67-color0-rotate_180.jpg.txt\n",
            "ok_3-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0.jpg.txt\n",
            "oksign 914 227 1114 451\n",
            "[['oksign', '914', '227', '1114', '451']]\n",
            "Processing complete for file: ok_3-color0.jpg.txt\n",
            "ok_63-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_63-color0-f1.jpg.txt\n",
            "oksign 459 189 684 456\n",
            "[['oksign', '459', '189', '684', '456']]\n",
            "Processing complete for file: ok_63-color0-f1.jpg.txt\n",
            "palm_67-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_67-color0.jpg.txt\n",
            "palmhand 123 129 428 423\n",
            "[['palmhand', '123', '129', '428', '423']]\n",
            "Processing complete for file: palm_67-color0.jpg.txt\n",
            "palm_89-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0-rotate_270.jpg.txt\n",
            "palmhand 229 140 494 486\n",
            "[['palmhand', '229', '140', '494', '486']]\n",
            "Processing complete for file: palm_89-color0-rotate_270.jpg.txt\n",
            "palm_62-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0-rotate_180.jpg.txt\n",
            "palmhand 419 222 700 660\n",
            "[['palmhand', '419', '222', '700', '660']]\n",
            "Processing complete for file: palm_62-color0-rotate_180.jpg.txt\n",
            "ok_72-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_72-color0-f0.jpg.txt\n",
            "oksign 457 312 713 670\n",
            "[['oksign', '457', '312', '713', '670']]\n",
            "Processing complete for file: ok_72-color0-f0.jpg.txt\n",
            "peace_25-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0.jpg.txt\n",
            "peacesign 533 138 774 532\n",
            "[['peacesign', '533', '138', '774', '532']]\n",
            "Processing complete for file: peace_25-color0.jpg.txt\n",
            "palm_14-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_14-color0.jpg.txt\n",
            "palmhand 180 112 576 381\n",
            "[['palmhand', '180', '112', '576', '381']]\n",
            "Processing complete for file: palm_14-color0.jpg.txt\n",
            "ok_2-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0-f1.jpg.txt\n",
            "oksign 125 338 556 979\n",
            "[['oksign', '125', '338', '556', '979']]\n",
            "Processing complete for file: ok_2-color0-f1.jpg.txt\n",
            "peace_89-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_89-color0-f0.jpg.txt\n",
            "peacesign 512 84 785 537\n",
            "[['peacesign', '512', '84', '785', '537']]\n",
            "Processing complete for file: peace_89-color0-f0.jpg.txt\n",
            "peace_70-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0-rotate_90.jpg.txt\n",
            "peacesign 204 287 644 554\n",
            "[['peacesign', '204', '287', '644', '554']]\n",
            "Processing complete for file: peace_70-color0-rotate_90.jpg.txt\n",
            "palm_72-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_72-color0-f0.jpg.txt\n",
            "palmhand 265 249 513 524\n",
            "[['palmhand', '265', '249', '513', '524']]\n",
            "Processing complete for file: palm_72-color0-f0.jpg.txt\n",
            "peace_30-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_30-color0-rotate_90.jpg.txt\n",
            "peacesign 301 24 454 115\n",
            "[['peacesign', '301', '24', '454', '115']]\n",
            "Processing complete for file: peace_30-color0-rotate_90.jpg.txt\n",
            "palm_45-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_45-color0-f0.jpg.txt\n",
            "palmhand 222 41 610 396\n",
            "[['palmhand', '222', '41', '610', '396']]\n",
            "Processing complete for file: palm_45-color0-f0.jpg.txt\n",
            "palm_33-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_33-color0-rotate_90.jpg.txt\n",
            "palmhand 151 378 351 500\n",
            "[['palmhand', '151', '378', '351', '500']]\n",
            "palmhand 145 203 329 351\n",
            "[['palmhand', '151', '378', '351', '500'], ['palmhand', '145', '203', '329', '351']]\n",
            "Processing complete for file: palm_33-color0-rotate_90.jpg.txt\n",
            "ok_77-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_77-color0-f0.jpg.txt\n",
            "oksign 448 183 723 603\n",
            "[['oksign', '448', '183', '723', '603']]\n",
            "Processing complete for file: ok_77-color0-f0.jpg.txt\n",
            "palm_29-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_29-color0.jpg.txt\n",
            "palmhand 53 30 278 472\n",
            "[['palmhand', '53', '30', '278', '472']]\n",
            "Processing complete for file: palm_29-color0.jpg.txt\n",
            "ok_43-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_43-color0.jpg.txt\n",
            "oksign 388 58 516 239\n",
            "[['oksign', '388', '58', '516', '239']]\n",
            "Processing complete for file: ok_43-color0.jpg.txt\n",
            "peace_62-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_62-color0.jpg.txt\n",
            "peacesign 616 263 801 607\n",
            "[['peacesign', '616', '263', '801', '607']]\n",
            "Processing complete for file: peace_62-color0.jpg.txt\n",
            "peace_2-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0-rotate_270.jpg.txt\n",
            "peacesign 13 57 583 418\n",
            "[['peacesign', '13', '57', '583', '418']]\n",
            "Processing complete for file: peace_2-color0-rotate_270.jpg.txt\n",
            "ok_23-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_23-color0-rotate_90.jpg.txt\n",
            "oksign 168 120 480 339\n",
            "[['oksign', '168', '120', '480', '339']]\n",
            "Processing complete for file: ok_23-color0-rotate_90.jpg.txt\n",
            "ok_4-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_4-color0.jpg.txt\n",
            "oksign 327 197 496 386\n",
            "[['oksign', '327', '197', '496', '386']]\n",
            "Processing complete for file: ok_4-color0.jpg.txt\n",
            "palm_32-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_32-color0-rotate_90.jpg.txt\n",
            "palmhand 28 175 466 417\n",
            "[['palmhand', '28', '175', '466', '417']]\n",
            "Processing complete for file: palm_32-color0-rotate_90.jpg.txt\n",
            "ok_84-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_84-color0-rotate_90.jpg.txt\n",
            "oksign 268 601 608 830\n",
            "[['oksign', '268', '601', '608', '830']]\n",
            "Processing complete for file: ok_84-color0-rotate_90.jpg.txt\n",
            "ok_65-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0-f1.jpg.txt\n",
            "oksign 282 335 611 558\n",
            "[['oksign', '282', '335', '611', '558']]\n",
            "Processing complete for file: ok_65-color0-f1.jpg.txt\n",
            "palm_96-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_96-color0-f0.jpg.txt\n",
            "palmhand 426 322 626 612\n",
            "[['palmhand', '426', '322', '626', '612']]\n",
            "Processing complete for file: palm_96-color0-f0.jpg.txt\n",
            "peace_2-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_2-color0.jpg.txt\n",
            "peacesign 39 13 400 583\n",
            "[['peacesign', '39', '13', '400', '583']]\n",
            "Processing complete for file: peace_2-color0.jpg.txt\n",
            "ok_9-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_9-color0-rotate_270.jpg.txt\n",
            "oksign 442 405 600 539\n",
            "[['oksign', '442', '405', '600', '539']]\n",
            "Processing complete for file: ok_9-color0-rotate_270.jpg.txt\n",
            "peace_42-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_42-color0-f0.jpg.txt\n",
            "peacesign 201 386 511 748\n",
            "[['peacesign', '201', '386', '511', '748']]\n",
            "peacesign 1186 417 1486 823\n",
            "[['peacesign', '201', '386', '511', '748'], ['peacesign', '1186', '417', '1486', '823']]\n",
            "Processing complete for file: peace_42-color0-f0.jpg.txt\n",
            "ok_60-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0-rotate_180.jpg.txt\n",
            "oksign 421 197 704 635\n",
            "[['oksign', '421', '197', '704', '635']]\n",
            "Processing complete for file: ok_60-color0-rotate_180.jpg.txt\n",
            "ok_65-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_65-color0-f0.jpg.txt\n",
            "oksign 469 162 798 385\n",
            "[['oksign', '469', '162', '798', '385']]\n",
            "Processing complete for file: ok_65-color0-f0.jpg.txt\n",
            "ok_37-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_37-color0-rotate_270.jpg.txt\n",
            "oksign 115 197 437 421\n",
            "[['oksign', '115', '197', '437', '421']]\n",
            "Processing complete for file: ok_37-color0-rotate_270.jpg.txt\n",
            "peace_87-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_87-color0-f0.jpg.txt\n",
            "peacesign 305 146 696 577\n",
            "[['peacesign', '305', '146', '696', '577']]\n",
            "Processing complete for file: peace_87-color0-f0.jpg.txt\n",
            "palm_89-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0-f1.jpg.txt\n",
            "palmhand 140 229 486 494\n",
            "[['palmhand', '140', '229', '486', '494']]\n",
            "Processing complete for file: palm_89-color0-f1.jpg.txt\n",
            "ok_41-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_41-color0-f0.jpg.txt\n",
            "oksign 269 174 345 280\n",
            "[['oksign', '269', '174', '345', '280']]\n",
            "oksign 513 153 593 265\n",
            "[['oksign', '269', '174', '345', '280'], ['oksign', '513', '153', '593', '265']]\n",
            "Processing complete for file: ok_41-color0-f0.jpg.txt\n",
            "ok_33-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0-rotate_270.jpg.txt\n",
            "oksign 267 378 780 735\n",
            "[['oksign', '267', '378', '780', '735']]\n",
            "Processing complete for file: ok_33-color0-rotate_270.jpg.txt\n",
            "ok_60-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_60-color0-rotate_270.jpg.txt\n",
            "oksign 85 421 523 704\n",
            "[['oksign', '85', '421', '523', '704']]\n",
            "Processing complete for file: ok_60-color0-rotate_270.jpg.txt\n",
            "peace_39-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_39-color0.jpg.txt\n",
            "peacesign 60 51 268 387\n",
            "[['peacesign', '60', '51', '268', '387']]\n",
            "Processing complete for file: peace_39-color0.jpg.txt\n",
            "palm_54-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_54-color0-f1.jpg.txt\n",
            "palmhand 436 39 775 585\n",
            "[['palmhand', '436', '39', '775', '585']]\n",
            "Processing complete for file: palm_54-color0-f1.jpg.txt\n",
            "palm_92-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_92-color0-rotate_90.jpg.txt\n",
            "palmhand 312 419 601 613\n",
            "[['palmhand', '312', '419', '601', '613']]\n",
            "Processing complete for file: palm_92-color0-rotate_90.jpg.txt\n",
            "ok_33-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0.jpg.txt\n",
            "oksign 222 267 579 780\n",
            "[['oksign', '222', '267', '579', '780']]\n",
            "Processing complete for file: ok_33-color0.jpg.txt\n",
            "ok_69-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0-rotate_270.jpg.txt\n",
            "oksign 167 709 442 1004\n",
            "[['oksign', '167', '709', '442', '1004']]\n",
            "Processing complete for file: ok_69-color0-rotate_270.jpg.txt\n",
            "ok_86-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_86-color0-f1.jpg.txt\n",
            "oksign 361 273 554 487\n",
            "[['oksign', '361', '273', '554', '487']]\n",
            "Processing complete for file: ok_86-color0-f1.jpg.txt\n",
            "ok_7-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_7-color0-f1.jpg.txt\n",
            "oksign 858 85 1134 532\n",
            "[['oksign', '858', '85', '1134', '532']]\n",
            "Processing complete for file: ok_7-color0-f1.jpg.txt\n",
            "palm_81-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0-rotate_270.jpg.txt\n",
            "palmhand 106 515 487 923\n",
            "[['palmhand', '106', '515', '487', '923']]\n",
            "Processing complete for file: palm_81-color0-rotate_270.jpg.txt\n",
            "ok_92-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0-rotate_270.jpg.txt\n",
            "oksign 142 336 433 559\n",
            "[['oksign', '142', '336', '433', '559']]\n",
            "Processing complete for file: ok_92-color0-rotate_270.jpg.txt\n",
            "palm_61-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_61-color0-rotate_270.jpg.txt\n",
            "palmhand 146 211 517 573\n",
            "[['palmhand', '146', '211', '517', '573']]\n",
            "Processing complete for file: palm_61-color0-rotate_270.jpg.txt\n",
            "palm_58-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_58-color0.jpg.txt\n",
            "palmhand 321 119 571 506\n",
            "[['palmhand', '321', '119', '571', '506']]\n",
            "Processing complete for file: palm_58-color0.jpg.txt\n",
            "ok_8-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_8-color0-rotate_270.jpg.txt\n",
            "oksign 263 1053 442 1205\n",
            "[['oksign', '263', '1053', '442', '1205']]\n",
            "Processing complete for file: ok_8-color0-rotate_270.jpg.txt\n",
            "ok_89-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_89-color0-f0.jpg.txt\n",
            "oksign 317 199 609 389\n",
            "[['oksign', '317', '199', '609', '389']]\n",
            "Processing complete for file: ok_89-color0-f0.jpg.txt\n",
            "palm_6-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_6-color0-f0.jpg.txt\n",
            "palmhand 51 54 393 647\n",
            "[['palmhand', '51', '54', '393', '647']]\n",
            "Processing complete for file: palm_6-color0-f0.jpg.txt\n",
            "ok_33-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_33-color0-f1.jpg.txt\n",
            "oksign 378 267 735 780\n",
            "[['oksign', '378', '267', '735', '780']]\n",
            "Processing complete for file: ok_33-color0-f1.jpg.txt\n",
            "ok_68-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0-rotate_270.jpg.txt\n",
            "oksign 21 582 373 813\n",
            "[['oksign', '21', '582', '373', '813']]\n",
            "Processing complete for file: ok_68-color0-rotate_270.jpg.txt\n",
            "palm_66-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_66-color0-rotate_180.jpg.txt\n",
            "palmhand 371 178 682 697\n",
            "[['palmhand', '371', '178', '682', '697']]\n",
            "Processing complete for file: palm_66-color0-rotate_180.jpg.txt\n",
            "ok_22-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_22-color0-rotate_90.jpg.txt\n",
            "oksign 45 295 429 547\n",
            "[['oksign', '45', '295', '429', '547']]\n",
            "Processing complete for file: ok_22-color0-rotate_90.jpg.txt\n",
            "palm_44-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0-f1.jpg.txt\n",
            "palmhand 8 65 560 439\n",
            "[['palmhand', '8', '65', '560', '439']]\n",
            "Processing complete for file: palm_44-color0-f1.jpg.txt\n",
            "ok_78-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_78-color0.jpg.txt\n",
            "oksign 273 121 586 508\n",
            "[['oksign', '273', '121', '586', '508']]\n",
            "Processing complete for file: ok_78-color0.jpg.txt\n",
            "palm_9-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_9-color0-rotate_270.jpg.txt\n",
            "palmhand 19 49 580 358\n",
            "[['palmhand', '19', '49', '580', '358']]\n",
            "Processing complete for file: palm_9-color0-rotate_270.jpg.txt\n",
            "palm_62-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_62-color0-rotate_90.jpg.txt\n",
            "palmhand 222 380 660 661\n",
            "[['palmhand', '222', '380', '660', '661']]\n",
            "Processing complete for file: palm_62-color0-rotate_90.jpg.txt\n",
            "palm_37-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_37-color0-f0.jpg.txt\n",
            "palmhand 34 37 308 466\n",
            "[['palmhand', '34', '37', '308', '466']]\n",
            "Processing complete for file: palm_37-color0-f0.jpg.txt\n",
            "palm_28-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_28-color0.jpg.txt\n",
            "palmhand 49 194 589 437\n",
            "[['palmhand', '49', '194', '589', '437']]\n",
            "Processing complete for file: palm_28-color0.jpg.txt\n",
            "peace_70-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_70-color0-f1.jpg.txt\n",
            "peacesign 526 76 793 516\n",
            "[['peacesign', '526', '76', '793', '516']]\n",
            "Processing complete for file: peace_70-color0-f1.jpg.txt\n",
            "palm_5-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_5-color0-rotate_90.jpg.txt\n",
            "palmhand 19 72 568 378\n",
            "[['palmhand', '19', '72', '568', '378']]\n",
            "Processing complete for file: palm_5-color0-rotate_90.jpg.txt\n",
            "peace_78-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_78-color0-rotate_90.jpg.txt\n",
            "peacesign 99 401 604 683\n",
            "[['peacesign', '99', '401', '604', '683']]\n",
            "Processing complete for file: peace_78-color0-rotate_90.jpg.txt\n",
            "peace_23-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_23-color0-f0.jpg.txt\n",
            "peacesign 299 56 767 815\n",
            "[['peacesign', '299', '56', '767', '815']]\n",
            "Processing complete for file: peace_23-color0-f0.jpg.txt\n",
            "palm_97-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0-f0.jpg.txt\n",
            "palmhand 567 328 846 606\n",
            "[['palmhand', '567', '328', '846', '606']]\n",
            "Processing complete for file: palm_97-color0-f0.jpg.txt\n",
            "ok_69-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_69-color0.jpg.txt\n",
            "oksign 76 167 371 442\n",
            "[['oksign', '76', '167', '371', '442']]\n",
            "Processing complete for file: ok_69-color0.jpg.txt\n",
            "palm_90-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_90-color0.jpg.txt\n",
            "palmhand 544 114 830 425\n",
            "[['palmhand', '544', '114', '830', '425']]\n",
            "Processing complete for file: palm_90-color0.jpg.txt\n",
            "palm_55-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_55-color0-rotate_180.jpg.txt\n",
            "palmhand 307 166 573 581\n",
            "[['palmhand', '307', '166', '573', '581']]\n",
            "Processing complete for file: palm_55-color0-rotate_180.jpg.txt\n",
            "peace_60-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0-rotate_180.jpg.txt\n",
            "peacesign 582 302 835 613\n",
            "[['peacesign', '582', '302', '835', '613']]\n",
            "Processing complete for file: peace_60-color0-rotate_180.jpg.txt\n",
            "peace_63-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_63-color0-f1.jpg.txt\n",
            "peacesign 493 156 724 503\n",
            "[['peacesign', '493', '156', '724', '503']]\n",
            "Processing complete for file: peace_63-color0-f1.jpg.txt\n",
            "ok_29-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_29-color0-rotate_270.jpg.txt\n",
            "oksign 82 699 276 871\n",
            "[['oksign', '82', '699', '276', '871']]\n",
            "Processing complete for file: ok_29-color0-rotate_270.jpg.txt\n",
            "palm_95-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0-rotate_180.jpg.txt\n",
            "palmhand 361 201 561 508\n",
            "[['palmhand', '361', '201', '561', '508']]\n",
            "Processing complete for file: palm_95-color0-rotate_180.jpg.txt\n",
            "palm_8-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_8-color0-rotate_180.jpg.txt\n",
            "palmhand 83 43 424 646\n",
            "[['palmhand', '83', '43', '424', '646']]\n",
            "Processing complete for file: palm_8-color0-rotate_180.jpg.txt\n",
            "ok_44-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_44-color0-f1.jpg.txt\n",
            "oksign 490 16 647 236\n",
            "[['oksign', '490', '16', '647', '236']]\n",
            "Processing complete for file: ok_44-color0-f1.jpg.txt\n",
            "ok_61-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_61-color0.jpg.txt\n",
            "oksign 423 23 678 398\n",
            "[['oksign', '423', '23', '678', '398']]\n",
            "Processing complete for file: ok_61-color0.jpg.txt\n",
            "peace_76-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_76-color0.jpg.txt\n",
            "peacesign 76 314 690 650\n",
            "[['peacesign', '76', '314', '690', '650']]\n",
            "Processing complete for file: peace_76-color0.jpg.txt\n",
            "ok_6-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0-f0.jpg.txt\n",
            "oksign 575 450 1035 1027\n",
            "[['oksign', '575', '450', '1035', '1027']]\n",
            "Processing complete for file: ok_6-color0-f0.jpg.txt\n",
            "palm_24-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_24-color0.jpg.txt\n",
            "palmhand 118 8 428 480\n",
            "[['palmhand', '118', '8', '428', '480']]\n",
            "Processing complete for file: palm_24-color0.jpg.txt\n",
            "peace_13-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_13-color0-rotate_180.jpg.txt\n",
            "peacesign 46 21 294 474\n",
            "[['peacesign', '46', '21', '294', '474']]\n",
            "Processing complete for file: peace_13-color0-rotate_180.jpg.txt\n",
            "ok_40-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_40-color0-f1.jpg.txt\n",
            "oksign 738 161 987 407\n",
            "[['oksign', '738', '161', '987', '407']]\n",
            "Processing complete for file: ok_40-color0-f1.jpg.txt\n",
            "ok_3-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_3-color0-f1.jpg.txt\n",
            "oksign 166 227 366 451\n",
            "[['oksign', '166', '227', '366', '451']]\n",
            "Processing complete for file: ok_3-color0-f1.jpg.txt\n",
            "ok_87-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_87-color0.jpg.txt\n",
            "oksign 426 279 640 519\n",
            "[['oksign', '426', '279', '640', '519']]\n",
            "Processing complete for file: ok_87-color0.jpg.txt\n",
            "peace_40-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0-f1.jpg.txt\n",
            "peacesign 278 125 400 305\n",
            "[['peacesign', '278', '125', '400', '305']]\n",
            "Processing complete for file: peace_40-color0-f1.jpg.txt\n",
            "peace_40-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_40-color0-rotate_270.jpg.txt\n",
            "peacesign 125 278 305 400\n",
            "[['peacesign', '125', '278', '305', '400']]\n",
            "Processing complete for file: peace_40-color0-rotate_270.jpg.txt\n",
            "peace_85-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_85-color0-rotate_180.jpg.txt\n",
            "peacesign 88 162 442 679\n",
            "[['peacesign', '88', '162', '442', '679']]\n",
            "Processing complete for file: peace_85-color0-rotate_180.jpg.txt\n",
            "palm_63-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_63-color0-f1.jpg.txt\n",
            "palmhand 423 364 942 664\n",
            "[['palmhand', '423', '364', '942', '664']]\n",
            "Processing complete for file: palm_63-color0-f1.jpg.txt\n",
            "ok_38-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_38-color0.jpg.txt\n",
            "oksign 80 18 315 380\n",
            "[['oksign', '80', '18', '315', '380']]\n",
            "Processing complete for file: ok_38-color0.jpg.txt\n",
            "peace_53-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_53-color0-f0.jpg.txt\n",
            "peacesign 325 17 756 624\n",
            "[['peacesign', '325', '17', '756', '624']]\n",
            "Processing complete for file: peace_53-color0-f0.jpg.txt\n",
            "ok_6-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_6-color0-rotate_180.jpg.txt\n",
            "oksign 245 450 705 1027\n",
            "[['oksign', '245', '450', '705', '1027']]\n",
            "Processing complete for file: ok_6-color0-rotate_180.jpg.txt\n",
            "ok_26-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0.jpg.txt\n",
            "oksign 220 36 409 288\n",
            "[['oksign', '220', '36', '409', '288']]\n",
            "Processing complete for file: ok_26-color0.jpg.txt\n",
            "palm_82-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_82-color0-f1.jpg.txt\n",
            "palmhand 327 48 636 544\n",
            "[['palmhand', '327', '48', '636', '544']]\n",
            "Processing complete for file: palm_82-color0-f1.jpg.txt\n",
            "palm_52-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_52-color0-f0.jpg.txt\n",
            "palmhand 426 110 821 653\n",
            "[['palmhand', '426', '110', '821', '653']]\n",
            "Processing complete for file: palm_52-color0-f0.jpg.txt\n",
            "ok_47-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_47-color0-rotate_90.jpg.txt\n",
            "oksign 207 80 361 204\n",
            "[['oksign', '207', '80', '361', '204']]\n",
            "oksign 166 349 333 501\n",
            "[['oksign', '207', '80', '361', '204'], ['oksign', '166', '349', '333', '501']]\n",
            "Processing complete for file: ok_47-color0-rotate_90.jpg.txt\n",
            "ok_1-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_1-color0-rotate_180.jpg.txt\n",
            "oksign 803 499 984 731\n",
            "[['oksign', '803', '499', '984', '731']]\n",
            "Processing complete for file: ok_1-color0-rotate_180.jpg.txt\n",
            "peace_1-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_1-color0-f1.jpg.txt\n",
            "peacesign 70 25 394 589\n",
            "[['peacesign', '70', '25', '394', '589']]\n",
            "Processing complete for file: peace_1-color0-f1.jpg.txt\n",
            "peace_71-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_71-color0.jpg.txt\n",
            "peacesign 364 80 698 483\n",
            "[['peacesign', '364', '80', '698', '483']]\n",
            "Processing complete for file: peace_71-color0.jpg.txt\n",
            "ok_53-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_53-color0-f0.jpg.txt\n",
            "oksign 398 270 659 670\n",
            "[['oksign', '398', '270', '659', '670']]\n",
            "Processing complete for file: ok_53-color0-f0.jpg.txt\n",
            "palm_81-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_81-color0-rotate_90.jpg.txt\n",
            "palmhand 233 157 614 565\n",
            "[['palmhand', '233', '157', '614', '565']]\n",
            "Processing complete for file: palm_81-color0-rotate_90.jpg.txt\n",
            "ok_92-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_92-color0-rotate_90.jpg.txt\n",
            "oksign 287 521 578 744\n",
            "[['oksign', '287', '521', '578', '744']]\n",
            "Processing complete for file: ok_92-color0-rotate_90.jpg.txt\n",
            "palm_19-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_19-color0-f0.jpg.txt\n",
            "palmhand 82 79 494 479\n",
            "[['palmhand', '82', '79', '494', '479']]\n",
            "Processing complete for file: palm_19-color0-f0.jpg.txt\n",
            "ok_2-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_2-color0-rotate_270.jpg.txt\n",
            "oksign 338 125 979 556\n",
            "[['oksign', '338', '125', '979', '556']]\n",
            "Processing complete for file: ok_2-color0-rotate_270.jpg.txt\n",
            "ok_26-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_26-color0-f0.jpg.txt\n",
            "oksign 220 119 409 371\n",
            "[['oksign', '220', '119', '409', '371']]\n",
            "Processing complete for file: ok_26-color0-f0.jpg.txt\n",
            "palm_27-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_27-color0-rotate_180.jpg.txt\n",
            "palmhand 400 16 666 450\n",
            "[['palmhand', '400', '16', '666', '450']]\n",
            "Processing complete for file: palm_27-color0-rotate_180.jpg.txt\n",
            "ok_95-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_95-color0-rotate_180.jpg.txt\n",
            "oksign 175 320 463 545\n",
            "[['oksign', '175', '320', '463', '545']]\n",
            "Processing complete for file: ok_95-color0-rotate_180.jpg.txt\n",
            "peace_60-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_60-color0-rotate_90.jpg.txt\n",
            "peacesign 302 245 613 498\n",
            "[['peacesign', '302', '245', '613', '498']]\n",
            "Processing complete for file: peace_60-color0-rotate_90.jpg.txt\n",
            "peace_97-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0-rotate_180.jpg.txt\n",
            "peacesign 402 139 642 622\n",
            "[['peacesign', '402', '139', '642', '622']]\n",
            "Processing complete for file: peace_97-color0-rotate_180.jpg.txt\n",
            "peace_25-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_25-color0-rotate_270.jpg.txt\n",
            "peacesign 138 506 532 747\n",
            "[['peacesign', '138', '506', '532', '747']]\n",
            "Processing complete for file: peace_25-color0-rotate_270.jpg.txt\n",
            "ok_81-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_81-color0-rotate_180.jpg.txt\n",
            "oksign 329 106 596 501\n",
            "[['oksign', '329', '106', '596', '501']]\n",
            "Processing complete for file: ok_81-color0-rotate_180.jpg.txt\n",
            "palm_60-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_60-color0-rotate_90.jpg.txt\n",
            "palmhand 114 540 383 963\n",
            "[['palmhand', '114', '540', '383', '963']]\n",
            "Processing complete for file: palm_60-color0-rotate_90.jpg.txt\n",
            "palm_97-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_97-color0-rotate_270.jpg.txt\n",
            "palmhand 114 234 392 513\n",
            "[['palmhand', '114', '234', '392', '513']]\n",
            "Processing complete for file: palm_97-color0-rotate_270.jpg.txt\n",
            "peace_5-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_5-color0.jpg.txt\n",
            "peacesign 38 10 353 573\n",
            "[['peacesign', '38', '10', '353', '573']]\n",
            "Processing complete for file: peace_5-color0.jpg.txt\n",
            "palm_65-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_65-color0-f1.jpg.txt\n",
            "palmhand 432 52 836 533\n",
            "[['palmhand', '432', '52', '836', '533']]\n",
            "Processing complete for file: palm_65-color0-f1.jpg.txt\n",
            "palm_7-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_7-color0-f1.jpg.txt\n",
            "palmhand 61 22 453 699\n",
            "[['palmhand', '61', '22', '453', '699']]\n",
            "Processing complete for file: palm_7-color0-f1.jpg.txt\n",
            "peace_19-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_19-color0-rotate_270.jpg.txt\n",
            "peacesign 580 708 642 770\n",
            "[['peacesign', '580', '708', '642', '770']]\n",
            "peacesign 489 366 584 435\n",
            "[['peacesign', '580', '708', '642', '770'], ['peacesign', '489', '366', '584', '435']]\n",
            "Processing complete for file: peace_19-color0-rotate_270.jpg.txt\n",
            "peace_94-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_94-color0.jpg.txt\n",
            "peacesign 232 210 465 621\n",
            "[['peacesign', '232', '210', '465', '621']]\n",
            "Processing complete for file: peace_94-color0.jpg.txt\n",
            "palm_71-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_71-color0-rotate_270.jpg.txt\n",
            "palmhand 262 673 523 932\n",
            "[['palmhand', '262', '673', '523', '932']]\n",
            "Processing complete for file: palm_71-color0-rotate_270.jpg.txt\n",
            "peace_55-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0.jpg.txt\n",
            "peacesign 432 41 923 610\n",
            "[['peacesign', '432', '41', '923', '610']]\n",
            "Processing complete for file: peace_55-color0.jpg.txt\n",
            "ok_54-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_54-color0-f0.jpg.txt\n",
            "oksign 296 287 530 612\n",
            "[['oksign', '296', '287', '530', '612']]\n",
            "Processing complete for file: ok_54-color0-f0.jpg.txt\n",
            "palm_88-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_88-color0-rotate_180.jpg.txt\n",
            "palmhand 102 197 473 401\n",
            "[['palmhand', '102', '197', '473', '401']]\n",
            "Processing complete for file: palm_88-color0-rotate_180.jpg.txt\n",
            "palm_84-color0-f1.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_84-color0-f1.jpg.txt\n",
            "palmhand 477 275 875 500\n",
            "[['palmhand', '477', '275', '875', '500']]\n",
            "Processing complete for file: palm_84-color0-f1.jpg.txt\n",
            "peace_55-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_55-color0-f0.jpg.txt\n",
            "peacesign 432 110 923 679\n",
            "[['peacesign', '432', '110', '923', '679']]\n",
            "Processing complete for file: peace_55-color0-f0.jpg.txt\n",
            "peace_27-color0-rotate_180.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_27-color0-rotate_180.jpg.txt\n",
            "peacesign 169 258 339 590\n",
            "[['peacesign', '169', '258', '339', '590']]\n",
            "Processing complete for file: peace_27-color0-rotate_180.jpg.txt\n",
            "palm_95-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_95-color0-rotate_90.jpg.txt\n",
            "palmhand 201 519 508 719\n",
            "[['palmhand', '201', '519', '508', '719']]\n",
            "Processing complete for file: palm_95-color0-rotate_90.jpg.txt\n",
            "peace_72-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_72-color0-rotate_90.jpg.txt\n",
            "peacesign 181 228 616 559\n",
            "[['peacesign', '181', '228', '616', '559']]\n",
            "Processing complete for file: peace_72-color0-rotate_90.jpg.txt\n",
            "palm_44-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_44-color0.jpg.txt\n",
            "palmhand 29 65 581 439\n",
            "[['palmhand', '29', '65', '581', '439']]\n",
            "Processing complete for file: palm_44-color0.jpg.txt\n",
            "peace_17-color0-rotate_90.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_17-color0-rotate_90.jpg.txt\n",
            "peacesign 579 79 887 624\n",
            "[['peacesign', '579', '79', '887', '624']]\n",
            "peacesign 57 553 701 1040\n",
            "[['peacesign', '579', '79', '887', '624'], ['peacesign', '57', '553', '701', '1040']]\n",
            "Processing complete for file: peace_17-color0-rotate_90.jpg.txt\n",
            "ok_85-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_85-color0.jpg.txt\n",
            "oksign 665 231 857 483\n",
            "[['oksign', '665', '231', '857', '483']]\n",
            "Processing complete for file: ok_85-color0.jpg.txt\n",
            "peace_97-color0-rotate_270.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/peace_97-color0-rotate_270.jpg.txt\n",
            "peacesign 98 402 581 642\n",
            "[['peacesign', '98', '402', '581', '642']]\n",
            "Processing complete for file: peace_97-color0-rotate_270.jpg.txt\n",
            "palm_89-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0.jpg.txt\n",
            "palmhand 594 229 940 494\n",
            "[['palmhand', '594', '229', '940', '494']]\n",
            "Processing complete for file: palm_89-color0.jpg.txt\n",
            "palm_89-color0-f0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/palm_89-color0-f0.jpg.txt\n",
            "palmhand 594 226 940 491\n",
            "[['palmhand', '594', '226', '940', '491']]\n",
            "Processing complete for file: palm_89-color0-f0.jpg.txt\n",
            "ok_68-color0.jpg.txt\n",
            "the file path data /content/compproject/images/converted_annotation_in_txt/ok_68-color0.jpg.txt\n",
            "oksign 267 21 498 373\n",
            "[['oksign', '267', '21', '498', '373']]\n",
            "Processing complete for file: ok_68-color0.jpg.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quR32hewZY_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_quantized_300x300_coco_2019_01_03'\n",
        "    }\n",
        "}\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjyjMvmsZyDH",
        "colab_type": "code",
        "outputId": "19b691e1-b99c-4b15-a826-52cc7d643ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiHc8wNLaA0n",
        "colab_type": "code",
        "outputId": "3c4f19dc-1314-4139-8000-51dc5e15cc24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/compproject\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/compproject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbukZQXfaMLb",
        "colab_type": "code",
        "outputId": "15cdb253-bfeb-4dd0-ac40-b3816b93e0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!python xml_to_csv.py"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5rveK42aW6h",
        "colab_type": "code",
        "outputId": "5a028d84-8ddc-452f-d0ad-48d6c52d9f4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!python3 generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=data/train.record --image_dir=images/train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From generate_tfrecord.py:104: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1009 02:45:57.952476 139746153695104 module_wrapper.py:137] From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1009 02:45:58.087578 139746153695104 module_wrapper.py:137] From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/compproject/data/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHgprD2Gbhx7",
        "colab_type": "code",
        "outputId": "1396816d-2bde-43d6-c684-27a29d966189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!python3 generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=data/test.record --image_dir=images/test"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From generate_tfrecord.py:104: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1009 02:46:09.051358 139631189133184 module_wrapper.py:137] From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1009 02:46:09.081784 139631189133184 module_wrapper.py:137] From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/compproject/data/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkAnOAMOb-iO",
        "colab_type": "code",
        "outputId": "26c10a5d-75e4-4f56-d1e7-1389314ccd40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!python3 generate_tfrecord.py --csv_input=data/valid_labels.csv --output_path=data/valid.record --image_dir=images/valid"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From generate_tfrecord.py:104: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1010 04:18:13.757983 139959903520640 module_wrapper.py:139] From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1010 04:18:13.878118 139959903520640 module_wrapper.py:139] From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/compproject/data/valid.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAcdS2t7IpBT",
        "colab_type": "code",
        "outputId": "f34cb0ed-de4b-4b56-951f-2f23b62b4979",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-09 02:46:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.86.84.98, 52.205.50.157, 3.227.43.216, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.86.84.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   0%[                    ]  95.55K   394KB/s               \r        ngrok-stabl   6%[>                   ] 874.26K  1.76MB/s               \r       ngrok-stable  47%[========>           ]   6.23M  8.57MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  14.6MB/s    in 0.9s    \n",
            "\n",
            "2019-10-09 02:46:21 (14.6 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68I1Z7uzIvZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dir = '/content/compproject/training'\n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPrxzRHVJLw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsRPNDNrJPUd",
        "colab_type": "code",
        "outputId": "4bbf4627-306f-4f22-8374-8d08b610352e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://7d327966.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpmKUA0bl_O",
        "colab_type": "code",
        "outputId": "4f15b1ed-03fb-4f2b-98ac-3b9b20c156c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir=/content/compproject/training --pipeline_config_path=/content/compproject/training/ssd_mobilenet_v2.config"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/train.py:55: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/train.py:184: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W1009 02:46:57.924104 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W1009 02:46:57.924417 140425799219072 module_wrapper.py:137] From /content/models/research/object_detection/legacy/train.py:90: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W1009 02:46:57.931758 140425799219072 deprecation.py:323] From /content/models/research/object_detection/legacy/trainer.py:266: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1009 02:46:57.950755 140425799219072 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W1009 02:46:57.960016 140425799219072 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1009 02:46:57.960196 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1009 02:46:57.986190 140425799219072 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W1009 02:46:58.649457 140425799219072 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:196: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1009 02:46:58.730984 140425799219072 deprecation.py:323] From /content/models/research/object_detection/core/preprocessor.py:196: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1009 02:46:58.742555 140425799219072 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:206: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W1009 02:46:59.491619 140425799219072 deprecation.py:323] From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1009 02:46:59.495816 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1009 02:46:59.496969 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W1009 02:46:59.506664 140425799219072 module_wrapper.py:137] From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1009 02:47:00.340903 140425799219072 module_wrapper.py:137] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1009 02:47:00.775551 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:03.995342 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:04.034358 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:04.071559 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:04.108519 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:04.145858 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 02:47:04.182763 140425799219072 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W1009 02:47:08.716800 140425799219072 module_wrapper.py:137] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1009 02:47:20.164340 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1009 02:47:20.164919 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1009 02:47:20.165650 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1009 02:47:20.166110 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1009 02:47:20.166808 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1009 02:47:20.167269 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1009 02:47:20.167962 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1009 02:47:20.168423 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1009 02:47:20.169152 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1009 02:47:20.169589 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1009 02:47:20.170307 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1009 02:47:20.170738 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1009 02:47:20.171465 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1009 02:47:20.171895 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1009 02:47:20.172606 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1009 02:47:20.173054 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1009 02:47:20.173768 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1009 02:47:20.174222 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1009 02:47:20.174912 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1009 02:47:20.175379 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1009 02:47:20.176091 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1009 02:47:20.176541 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1009 02:47:20.177253 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1009 02:47:20.177682 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1009 02:47:20.178398 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1009 02:47:20.178828 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1009 02:47:20.179542 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1009 02:47:20.179971 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1009 02:47:20.180680 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1009 02:47:20.181122 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1009 02:47:20.181814 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1009 02:47:20.182277 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1009 02:47:20.182987 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1009 02:47:20.183442 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1009 02:47:20.184156 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1009 02:47:20.184572 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1009 02:47:20.184977 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1009 02:47:20.185417 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1009 02:47:20.185823 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1009 02:47:20.186284 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1009 02:47:20.186697 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1009 02:47:20.187123 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1009 02:47:20.187536 140425799219072 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1009 02:47:20.207496 140425799219072 module_wrapper.py:137] From /content/models/research/object_detection/builders/optimizer_builder.py:95: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1009 02:47:29.984569 140425799219072 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1009 02:47:32.056335 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W1009 02:47:40.768423 140425799219072 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2019-10-09 02:47:43.807791: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-09 02:47:43.808115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x274c1f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 02:47:43.808153: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-10-09 02:47:43.813879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-09 02:47:43.954312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:43.955183: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x274c1dc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 02:47:43.955234: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-09 02:47:43.956705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:43.957403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 02:47:43.974521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 02:47:44.166538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 02:47:44.255784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 02:47:44.284282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 02:47:44.527860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 02:47:44.671626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 02:47:45.085806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 02:47:45.086143: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:45.086981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:45.087793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 02:47:45.094485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 02:47:45.096177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 02:47:45.096214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 02:47:45.096231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 02:47:45.097874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:45.098754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 02:47:45.099480: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-09 02:47:45.099540: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/pretrained_model/model.ckpt\n",
            "I1009 02:47:51.828197 140425799219072 saver.py:1284] Restoring parameters from /content/models/research/pretrained_model/model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1009 02:47:54.223154 140425799219072 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1009 02:47:55.386621 140425799219072 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I1009 02:48:16.192237 140425799219072 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 02:48:17.243617 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I1009 02:48:17.247549 140425799219072 learning.py:768] Starting Queues.\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I1009 02:48:59.550557 140422673504000 supervisor.py:1099] global_step/sec: 0\n",
            "2019-10-09 02:49:04.247935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 02:49:08.830482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:Recording summary at step 0.\n",
            "I1009 02:49:20.422394 140422698682112 supervisor.py:1050] Recording summary at step 0.\n",
            "INFO:tensorflow:global step 1: loss = 23.2947 (65.002 sec/step)\n",
            "I1009 02:49:23.406786 140425799219072 learning.py:507] global step 1: loss = 23.2947 (65.002 sec/step)\n",
            "INFO:tensorflow:global step 2: loss = 19.1394 (4.706 sec/step)\n",
            "I1009 02:49:29.206175 140425799219072 learning.py:507] global step 2: loss = 19.1394 (4.706 sec/step)\n",
            "INFO:tensorflow:global step 3: loss = 17.9867 (4.707 sec/step)\n",
            "I1009 02:49:33.915093 140425799219072 learning.py:507] global step 3: loss = 17.9867 (4.707 sec/step)\n",
            "INFO:tensorflow:global step 4: loss = 16.8491 (4.767 sec/step)\n",
            "I1009 02:49:38.684276 140425799219072 learning.py:507] global step 4: loss = 16.8491 (4.767 sec/step)\n",
            "INFO:tensorflow:global step 5: loss = 15.9886 (4.843 sec/step)\n",
            "I1009 02:49:43.528905 140425799219072 learning.py:507] global step 5: loss = 15.9886 (4.843 sec/step)\n",
            "INFO:tensorflow:global step 6: loss = 14.9312 (4.744 sec/step)\n",
            "I1009 02:49:48.275230 140425799219072 learning.py:507] global step 6: loss = 14.9312 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 7: loss = 14.4923 (4.711 sec/step)\n",
            "I1009 02:49:52.988162 140425799219072 learning.py:507] global step 7: loss = 14.4923 (4.711 sec/step)\n",
            "2019-10-09 02:49:53.069632: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 2010562560 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb63202a000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:global step 8: loss = 13.8977 (5.729 sec/step)\n",
            "I1009 02:49:58.718817 140425799219072 learning.py:507] global step 8: loss = 13.8977 (5.729 sec/step)\n",
            "2019-10-09 02:49:58.863923: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 2010562560 exceeds 10% of system memory.\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb5ba2be000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:global step 9: loss = 13.2083 (5.956 sec/step)\n",
            "I1009 02:50:04.676595 140425799219072 learning.py:507] global step 9: loss = 13.2083 (5.956 sec/step)\n",
            "INFO:tensorflow:global step 10: loss = 12.1550 (5.161 sec/step)\n",
            "I1009 02:50:09.839130 140425799219072 learning.py:507] global step 10: loss = 12.1550 (5.161 sec/step)\n",
            "INFO:tensorflow:global step 11: loss = 11.6118 (4.859 sec/step)\n",
            "I1009 02:50:14.700579 140425799219072 learning.py:507] global step 11: loss = 11.6118 (4.859 sec/step)\n",
            "INFO:tensorflow:global step 12: loss = 11.3994 (7.590 sec/step)\n",
            "I1009 02:50:22.294287 140425799219072 learning.py:507] global step 12: loss = 11.3994 (7.590 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 12.\n",
            "I1009 02:50:26.153602 140422698682112 supervisor.py:1050] Recording summary at step 12.\n",
            "INFO:tensorflow:global_step/sec: 0.135289\n",
            "I1009 02:50:28.249263 140422673504000 supervisor.py:1099] global_step/sec: 0.135289\n",
            "INFO:tensorflow:global step 13: loss = 10.5614 (5.986 sec/step)\n",
            "I1009 02:50:28.292723 140425799219072 learning.py:507] global step 13: loss = 10.5614 (5.986 sec/step)\n",
            "INFO:tensorflow:global step 14: loss = 10.2494 (5.466 sec/step)\n",
            "I1009 02:50:33.760869 140425799219072 learning.py:507] global step 14: loss = 10.2494 (5.466 sec/step)\n",
            "INFO:tensorflow:global step 15: loss = 10.0450 (5.070 sec/step)\n",
            "I1009 02:50:38.832835 140425799219072 learning.py:507] global step 15: loss = 10.0450 (5.070 sec/step)\n",
            "INFO:tensorflow:global step 16: loss = 9.6090 (4.860 sec/step)\n",
            "I1009 02:50:43.695161 140425799219072 learning.py:507] global step 16: loss = 9.6090 (4.860 sec/step)\n",
            "INFO:tensorflow:global step 17: loss = 9.1617 (4.827 sec/step)\n",
            "I1009 02:50:48.524435 140425799219072 learning.py:507] global step 17: loss = 9.1617 (4.827 sec/step)\n",
            "INFO:tensorflow:global step 18: loss = 9.3952 (4.901 sec/step)\n",
            "I1009 02:50:53.427715 140425799219072 learning.py:507] global step 18: loss = 9.3952 (4.901 sec/step)\n",
            "INFO:tensorflow:global step 19: loss = 8.8592 (4.691 sec/step)\n",
            "I1009 02:50:58.122445 140425799219072 learning.py:507] global step 19: loss = 8.8592 (4.691 sec/step)\n",
            "INFO:tensorflow:global step 20: loss = 9.1622 (5.007 sec/step)\n",
            "I1009 02:51:03.130995 140425799219072 learning.py:507] global step 20: loss = 9.1622 (5.007 sec/step)\n",
            "INFO:tensorflow:global step 21: loss = 8.3765 (4.685 sec/step)\n",
            "I1009 02:51:07.817506 140425799219072 learning.py:507] global step 21: loss = 8.3765 (4.685 sec/step)\n",
            "2019-10-09 02:51:07.891713: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 756609984 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 22: loss = 8.3348 (4.764 sec/step)\n",
            "I1009 02:51:12.583585 140425799219072 learning.py:507] global step 22: loss = 8.3348 (4.764 sec/step)\n",
            "INFO:tensorflow:global step 23: loss = 8.5995 (4.654 sec/step)\n",
            "I1009 02:51:17.239640 140425799219072 learning.py:507] global step 23: loss = 8.5995 (4.654 sec/step)\n",
            "2019-10-09 02:51:17.334719: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 865677312 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 24: loss = 8.2824 (4.773 sec/step)\n",
            "I1009 02:51:22.014676 140425799219072 learning.py:507] global step 24: loss = 8.2824 (4.773 sec/step)\n",
            "INFO:tensorflow:global step 25: loss = 8.7331 (4.609 sec/step)\n",
            "I1009 02:51:26.625692 140425799219072 learning.py:507] global step 25: loss = 8.7331 (4.609 sec/step)\n",
            "INFO:tensorflow:global step 26: loss = 8.3095 (4.629 sec/step)\n",
            "I1009 02:51:31.257103 140425799219072 learning.py:507] global step 26: loss = 8.3095 (4.629 sec/step)\n",
            "INFO:tensorflow:global step 27: loss = 8.1583 (4.888 sec/step)\n",
            "I1009 02:51:36.147293 140425799219072 learning.py:507] global step 27: loss = 8.1583 (4.888 sec/step)\n",
            "2019-10-09 02:51:36.335086: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 959990400 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 28: loss = 8.0033 (5.172 sec/step)\n",
            "I1009 02:51:41.320817 140425799219072 learning.py:507] global step 28: loss = 8.0033 (5.172 sec/step)\n",
            "INFO:tensorflow:global step 29: loss = 8.0403 (4.837 sec/step)\n",
            "I1009 02:51:46.162111 140425799219072 learning.py:507] global step 29: loss = 8.0403 (4.837 sec/step)\n",
            "INFO:tensorflow:global step 30: loss = 7.8780 (4.866 sec/step)\n",
            "I1009 02:51:51.030768 140425799219072 learning.py:507] global step 30: loss = 7.8780 (4.866 sec/step)\n",
            "INFO:tensorflow:global step 31: loss = 7.5388 (4.880 sec/step)\n",
            "I1009 02:51:55.912850 140425799219072 learning.py:507] global step 31: loss = 7.5388 (4.880 sec/step)\n",
            "INFO:tensorflow:global step 32: loss = 8.1532 (4.666 sec/step)\n",
            "I1009 02:52:00.580648 140425799219072 learning.py:507] global step 32: loss = 8.1532 (4.666 sec/step)\n",
            "INFO:tensorflow:global step 33: loss = 7.6024 (4.891 sec/step)\n",
            "I1009 02:52:05.473639 140425799219072 learning.py:507] global step 33: loss = 7.6024 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 34: loss = 7.5666 (4.888 sec/step)\n",
            "I1009 02:52:10.363730 140425799219072 learning.py:507] global step 34: loss = 7.5666 (4.888 sec/step)\n",
            "INFO:tensorflow:global step 35: loss = 7.7839 (4.694 sec/step)\n",
            "I1009 02:52:15.059335 140425799219072 learning.py:507] global step 35: loss = 7.7839 (4.694 sec/step)\n",
            "INFO:tensorflow:global step 36: loss = 7.7478 (7.412 sec/step)\n",
            "I1009 02:52:22.479675 140425799219072 learning.py:507] global step 36: loss = 7.7478 (7.412 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 36.\n",
            "I1009 02:52:24.624568 140422698682112 supervisor.py:1050] Recording summary at step 36.\n",
            "INFO:tensorflow:global step 37: loss = 7.2447 (5.055 sec/step)\n",
            "I1009 02:52:27.537003 140425799219072 learning.py:507] global step 37: loss = 7.2447 (5.055 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.208053\n",
            "I1009 02:52:28.411151 140422673504000 supervisor.py:1099] global_step/sec: 0.208053\n",
            "INFO:tensorflow:global step 38: loss = 7.7810 (4.885 sec/step)\n",
            "I1009 02:52:32.423888 140425799219072 learning.py:507] global step 38: loss = 7.7810 (4.885 sec/step)\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb5ba2be000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:global step 39: loss = 7.3393 (4.951 sec/step)\n",
            "I1009 02:52:37.376176 140425799219072 learning.py:507] global step 39: loss = 7.3393 (4.951 sec/step)\n",
            "INFO:tensorflow:global step 40: loss = 7.2073 (4.738 sec/step)\n",
            "I1009 02:52:42.116069 140425799219072 learning.py:507] global step 40: loss = 7.2073 (4.738 sec/step)\n",
            "INFO:tensorflow:global step 41: loss = 7.4543 (4.670 sec/step)\n",
            "I1009 02:52:46.788233 140425799219072 learning.py:507] global step 41: loss = 7.4543 (4.670 sec/step)\n",
            "INFO:tensorflow:global step 42: loss = 7.2170 (4.718 sec/step)\n",
            "I1009 02:52:51.508266 140425799219072 learning.py:507] global step 42: loss = 7.2170 (4.718 sec/step)\n",
            "INFO:tensorflow:global step 43: loss = 7.1147 (4.803 sec/step)\n",
            "I1009 02:52:56.313300 140425799219072 learning.py:507] global step 43: loss = 7.1147 (4.803 sec/step)\n",
            "INFO:tensorflow:global step 44: loss = 6.7834 (4.706 sec/step)\n",
            "I1009 02:53:01.021190 140425799219072 learning.py:507] global step 44: loss = 6.7834 (4.706 sec/step)\n",
            "INFO:tensorflow:global step 45: loss = 6.6667 (5.082 sec/step)\n",
            "I1009 02:53:06.105250 140425799219072 learning.py:507] global step 45: loss = 6.6667 (5.082 sec/step)\n",
            "INFO:tensorflow:global step 46: loss = 7.2067 (4.834 sec/step)\n",
            "I1009 02:53:10.940942 140425799219072 learning.py:507] global step 46: loss = 7.2067 (4.834 sec/step)\n",
            "INFO:tensorflow:global step 47: loss = 6.4055 (4.735 sec/step)\n",
            "I1009 02:53:15.678415 140425799219072 learning.py:507] global step 47: loss = 6.4055 (4.735 sec/step)\n",
            "INFO:tensorflow:global step 48: loss = 7.1137 (4.785 sec/step)\n",
            "I1009 02:53:20.464881 140425799219072 learning.py:507] global step 48: loss = 7.1137 (4.785 sec/step)\n",
            "INFO:tensorflow:global step 49: loss = 6.8918 (4.676 sec/step)\n",
            "I1009 02:53:25.142872 140425799219072 learning.py:507] global step 49: loss = 6.8918 (4.676 sec/step)\n",
            "INFO:tensorflow:global step 50: loss = 6.7511 (4.641 sec/step)\n",
            "I1009 02:53:29.785973 140425799219072 learning.py:507] global step 50: loss = 6.7511 (4.641 sec/step)\n",
            "INFO:tensorflow:global step 51: loss = 6.8281 (4.680 sec/step)\n",
            "I1009 02:53:34.467958 140425799219072 learning.py:507] global step 51: loss = 6.8281 (4.680 sec/step)\n",
            "INFO:tensorflow:global step 52: loss = 6.7333 (4.845 sec/step)\n",
            "I1009 02:53:39.314759 140425799219072 learning.py:507] global step 52: loss = 6.7333 (4.845 sec/step)\n",
            "INFO:tensorflow:global step 53: loss = 6.7481 (4.815 sec/step)\n",
            "I1009 02:53:44.131975 140425799219072 learning.py:507] global step 53: loss = 6.7481 (4.815 sec/step)\n",
            "INFO:tensorflow:global step 54: loss = 6.5383 (5.013 sec/step)\n",
            "I1009 02:53:49.147225 140425799219072 learning.py:507] global step 54: loss = 6.5383 (5.013 sec/step)\n",
            "INFO:tensorflow:global step 55: loss = 6.1718 (4.847 sec/step)\n",
            "I1009 02:53:53.995990 140425799219072 learning.py:507] global step 55: loss = 6.1718 (4.847 sec/step)\n",
            "INFO:tensorflow:global step 56: loss = 6.3683 (4.746 sec/step)\n",
            "I1009 02:53:58.744194 140425799219072 learning.py:507] global step 56: loss = 6.3683 (4.746 sec/step)\n",
            "INFO:tensorflow:global step 57: loss = 6.2732 (4.859 sec/step)\n",
            "I1009 02:54:03.604472 140425799219072 learning.py:507] global step 57: loss = 6.2732 (4.859 sec/step)\n",
            "INFO:tensorflow:global step 58: loss = 6.1540 (4.886 sec/step)\n",
            "I1009 02:54:08.492220 140425799219072 learning.py:507] global step 58: loss = 6.1540 (4.886 sec/step)\n",
            "INFO:tensorflow:global step 59: loss = 6.0796 (4.857 sec/step)\n",
            "I1009 02:54:13.351256 140425799219072 learning.py:507] global step 59: loss = 6.0796 (4.857 sec/step)\n",
            "INFO:tensorflow:global step 60: loss = 6.3446 (4.792 sec/step)\n",
            "I1009 02:54:18.145369 140425799219072 learning.py:507] global step 60: loss = 6.3446 (4.792 sec/step)\n",
            "INFO:tensorflow:global step 61: loss = 6.4790 (7.964 sec/step)\n",
            "I1009 02:54:26.115337 140425799219072 learning.py:507] global step 61: loss = 6.4790 (7.964 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 61.\n",
            "I1009 02:54:26.267592 140422698682112 supervisor.py:1050] Recording summary at step 61.\n",
            "INFO:tensorflow:global_step/sec: 0.20027\n",
            "I1009 02:54:28.249253 140422673504000 supervisor.py:1099] global_step/sec: 0.20027\n",
            "INFO:tensorflow:global step 62: loss = 6.1411 (4.880 sec/step)\n",
            "I1009 02:54:31.002061 140425799219072 learning.py:507] global step 62: loss = 6.1411 (4.880 sec/step)\n",
            "INFO:tensorflow:global step 63: loss = 6.3481 (4.816 sec/step)\n",
            "I1009 02:54:35.820146 140425799219072 learning.py:507] global step 63: loss = 6.3481 (4.816 sec/step)\n",
            "INFO:tensorflow:global step 64: loss = 5.8278 (4.612 sec/step)\n",
            "I1009 02:54:40.434698 140425799219072 learning.py:507] global step 64: loss = 5.8278 (4.612 sec/step)\n",
            "INFO:tensorflow:global step 65: loss = 6.2285 (4.659 sec/step)\n",
            "I1009 02:54:45.095468 140425799219072 learning.py:507] global step 65: loss = 6.2285 (4.659 sec/step)\n",
            "INFO:tensorflow:global step 66: loss = 5.9765 (4.750 sec/step)\n",
            "I1009 02:54:49.847064 140425799219072 learning.py:507] global step 66: loss = 5.9765 (4.750 sec/step)\n",
            "INFO:tensorflow:global step 67: loss = 5.6191 (4.772 sec/step)\n",
            "I1009 02:54:54.621329 140425799219072 learning.py:507] global step 67: loss = 5.6191 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 68: loss = 5.5253 (4.762 sec/step)\n",
            "I1009 02:54:59.385790 140425799219072 learning.py:507] global step 68: loss = 5.5253 (4.762 sec/step)\n",
            "INFO:tensorflow:global step 69: loss = 5.5260 (4.808 sec/step)\n",
            "I1009 02:55:04.195431 140425799219072 learning.py:507] global step 69: loss = 5.5260 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 70: loss = 5.5881 (4.920 sec/step)\n",
            "I1009 02:55:09.117897 140425799219072 learning.py:507] global step 70: loss = 5.5881 (4.920 sec/step)\n",
            "INFO:tensorflow:global step 71: loss = 6.0058 (4.590 sec/step)\n",
            "I1009 02:55:13.709974 140425799219072 learning.py:507] global step 71: loss = 6.0058 (4.590 sec/step)\n",
            "INFO:tensorflow:global step 72: loss = 5.5599 (4.811 sec/step)\n",
            "I1009 02:55:18.522664 140425799219072 learning.py:507] global step 72: loss = 5.5599 (4.811 sec/step)\n",
            "INFO:tensorflow:global step 73: loss = 5.5093 (4.939 sec/step)\n",
            "I1009 02:55:23.463339 140425799219072 learning.py:507] global step 73: loss = 5.5093 (4.939 sec/step)\n",
            "INFO:tensorflow:global step 74: loss = 5.4937 (5.027 sec/step)\n",
            "I1009 02:55:28.492155 140425799219072 learning.py:507] global step 74: loss = 5.4937 (5.027 sec/step)\n",
            "INFO:tensorflow:global step 75: loss = 6.0874 (4.834 sec/step)\n",
            "I1009 02:55:33.328277 140425799219072 learning.py:507] global step 75: loss = 6.0874 (4.834 sec/step)\n",
            "INFO:tensorflow:global step 76: loss = 5.2157 (4.679 sec/step)\n",
            "I1009 02:55:38.009404 140425799219072 learning.py:507] global step 76: loss = 5.2157 (4.679 sec/step)\n",
            "INFO:tensorflow:global step 77: loss = 5.3764 (4.677 sec/step)\n",
            "I1009 02:55:42.688259 140425799219072 learning.py:507] global step 77: loss = 5.3764 (4.677 sec/step)\n",
            "INFO:tensorflow:global step 78: loss = 5.5807 (4.651 sec/step)\n",
            "I1009 02:55:47.341156 140425799219072 learning.py:507] global step 78: loss = 5.5807 (4.651 sec/step)\n",
            "INFO:tensorflow:global step 79: loss = 5.5189 (4.663 sec/step)\n",
            "I1009 02:55:52.006199 140425799219072 learning.py:507] global step 79: loss = 5.5189 (4.663 sec/step)\n",
            "INFO:tensorflow:global step 80: loss = 5.9979 (4.851 sec/step)\n",
            "I1009 02:55:56.859462 140425799219072 learning.py:507] global step 80: loss = 5.9979 (4.851 sec/step)\n",
            "INFO:tensorflow:global step 81: loss = 5.5851 (4.725 sec/step)\n",
            "I1009 02:56:01.586354 140425799219072 learning.py:507] global step 81: loss = 5.5851 (4.725 sec/step)\n",
            "INFO:tensorflow:global step 82: loss = 4.9670 (4.797 sec/step)\n",
            "I1009 02:56:06.385429 140425799219072 learning.py:507] global step 82: loss = 4.9670 (4.797 sec/step)\n",
            "INFO:tensorflow:global step 83: loss = 5.6112 (4.635 sec/step)\n",
            "I1009 02:56:11.021922 140425799219072 learning.py:507] global step 83: loss = 5.6112 (4.635 sec/step)\n",
            "INFO:tensorflow:global step 84: loss = 5.7036 (4.673 sec/step)\n",
            "I1009 02:56:15.696732 140425799219072 learning.py:507] global step 84: loss = 5.7036 (4.673 sec/step)\n",
            "INFO:tensorflow:global step 85: loss = 5.8978 (7.732 sec/step)\n",
            "I1009 02:56:23.431097 140425799219072 learning.py:507] global step 85: loss = 5.8978 (7.732 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 85.\n",
            "I1009 02:56:25.379018 140422698682112 supervisor.py:1050] Recording summary at step 85.\n",
            "INFO:tensorflow:global_step/sec: 0.2\n",
            "I1009 02:56:28.249130 140422673504000 supervisor.py:1099] global_step/sec: 0.2\n",
            "INFO:tensorflow:global step 86: loss = 5.7796 (4.958 sec/step)\n",
            "I1009 02:56:28.392135 140425799219072 learning.py:507] global step 86: loss = 5.7796 (4.958 sec/step)\n",
            "INFO:tensorflow:global step 87: loss = 4.7989 (4.737 sec/step)\n",
            "I1009 02:56:33.130760 140425799219072 learning.py:507] global step 87: loss = 4.7989 (4.737 sec/step)\n",
            "INFO:tensorflow:global step 88: loss = 4.8580 (4.858 sec/step)\n",
            "I1009 02:56:37.989969 140425799219072 learning.py:507] global step 88: loss = 4.8580 (4.858 sec/step)\n",
            "INFO:tensorflow:global step 89: loss = 4.8583 (4.769 sec/step)\n",
            "I1009 02:56:42.760433 140425799219072 learning.py:507] global step 89: loss = 4.8583 (4.769 sec/step)\n",
            "INFO:tensorflow:global step 90: loss = 5.1586 (4.830 sec/step)\n",
            "I1009 02:56:47.591876 140425799219072 learning.py:507] global step 90: loss = 5.1586 (4.830 sec/step)\n",
            "INFO:tensorflow:global step 91: loss = 5.3064 (4.829 sec/step)\n",
            "I1009 02:56:52.422812 140425799219072 learning.py:507] global step 91: loss = 5.3064 (4.829 sec/step)\n",
            "INFO:tensorflow:global step 92: loss = 4.3665 (4.822 sec/step)\n",
            "I1009 02:56:57.246483 140425799219072 learning.py:507] global step 92: loss = 4.3665 (4.822 sec/step)\n",
            "INFO:tensorflow:global step 93: loss = 4.4527 (4.850 sec/step)\n",
            "I1009 02:57:02.098807 140425799219072 learning.py:507] global step 93: loss = 4.4527 (4.850 sec/step)\n",
            "INFO:tensorflow:global step 94: loss = 4.9050 (4.802 sec/step)\n",
            "I1009 02:57:06.902792 140425799219072 learning.py:507] global step 94: loss = 4.9050 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 95: loss = 4.6205 (4.785 sec/step)\n",
            "I1009 02:57:11.690253 140425799219072 learning.py:507] global step 95: loss = 4.6205 (4.785 sec/step)\n",
            "INFO:tensorflow:global step 96: loss = 5.5394 (4.690 sec/step)\n",
            "I1009 02:57:16.382065 140425799219072 learning.py:507] global step 96: loss = 5.5394 (4.690 sec/step)\n",
            "INFO:tensorflow:global step 97: loss = 5.2724 (4.657 sec/step)\n",
            "I1009 02:57:21.041117 140425799219072 learning.py:507] global step 97: loss = 5.2724 (4.657 sec/step)\n",
            "INFO:tensorflow:global step 98: loss = 4.6987 (4.654 sec/step)\n",
            "I1009 02:57:25.697245 140425799219072 learning.py:507] global step 98: loss = 4.6987 (4.654 sec/step)\n",
            "INFO:tensorflow:global step 99: loss = 4.9533 (4.745 sec/step)\n",
            "I1009 02:57:30.444688 140425799219072 learning.py:507] global step 99: loss = 4.9533 (4.745 sec/step)\n",
            "INFO:tensorflow:global step 100: loss = 4.6339 (4.596 sec/step)\n",
            "I1009 02:57:35.043011 140425799219072 learning.py:507] global step 100: loss = 4.6339 (4.596 sec/step)\n",
            "INFO:tensorflow:global step 101: loss = 5.4933 (4.769 sec/step)\n",
            "I1009 02:57:39.814480 140425799219072 learning.py:507] global step 101: loss = 5.4933 (4.769 sec/step)\n",
            "INFO:tensorflow:global step 102: loss = 5.1776 (4.749 sec/step)\n",
            "I1009 02:57:44.565498 140425799219072 learning.py:507] global step 102: loss = 5.1776 (4.749 sec/step)\n",
            "INFO:tensorflow:global step 103: loss = 4.5554 (4.942 sec/step)\n",
            "I1009 02:57:49.508726 140425799219072 learning.py:507] global step 103: loss = 4.5554 (4.942 sec/step)\n",
            "INFO:tensorflow:global step 104: loss = 4.0698 (4.808 sec/step)\n",
            "I1009 02:57:54.318749 140425799219072 learning.py:507] global step 104: loss = 4.0698 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 105: loss = 4.9729 (4.917 sec/step)\n",
            "I1009 02:57:59.238143 140425799219072 learning.py:507] global step 105: loss = 4.9729 (4.917 sec/step)\n",
            "INFO:tensorflow:global step 106: loss = 4.1934 (4.738 sec/step)\n",
            "I1009 02:58:03.978299 140425799219072 learning.py:507] global step 106: loss = 4.1934 (4.738 sec/step)\n",
            "INFO:tensorflow:global step 107: loss = 4.4098 (4.716 sec/step)\n",
            "I1009 02:58:08.695716 140425799219072 learning.py:507] global step 107: loss = 4.4098 (4.716 sec/step)\n",
            "INFO:tensorflow:global step 108: loss = 4.1755 (4.726 sec/step)\n",
            "I1009 02:58:13.423351 140425799219072 learning.py:507] global step 108: loss = 4.1755 (4.726 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 02:58:17.243836 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 109: loss = 4.7753 (5.675 sec/step)\n",
            "I1009 02:58:19.264299 140425799219072 learning.py:507] global step 109: loss = 4.7753 (5.675 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 109.\n",
            "I1009 02:58:28.049274 140422698682112 supervisor.py:1050] Recording summary at step 109.\n",
            "INFO:tensorflow:global_step/sec: 0.199222\n",
            "I1009 02:58:28.717658 140422673504000 supervisor.py:1099] global_step/sec: 0.199222\n",
            "INFO:tensorflow:global step 110: loss = 4.4767 (9.113 sec/step)\n",
            "I1009 02:58:28.765067 140425799219072 learning.py:507] global step 110: loss = 4.4767 (9.113 sec/step)\n",
            "INFO:tensorflow:global step 111: loss = 4.1217 (4.675 sec/step)\n",
            "I1009 02:58:33.441539 140425799219072 learning.py:507] global step 111: loss = 4.1217 (4.675 sec/step)\n",
            "INFO:tensorflow:global step 112: loss = 4.6855 (4.728 sec/step)\n",
            "I1009 02:58:38.171692 140425799219072 learning.py:507] global step 112: loss = 4.6855 (4.728 sec/step)\n",
            "INFO:tensorflow:global step 113: loss = 4.3455 (4.840 sec/step)\n",
            "I1009 02:58:43.014135 140425799219072 learning.py:507] global step 113: loss = 4.3455 (4.840 sec/step)\n",
            "INFO:tensorflow:global step 114: loss = 4.3077 (4.781 sec/step)\n",
            "I1009 02:58:47.796594 140425799219072 learning.py:507] global step 114: loss = 4.3077 (4.781 sec/step)\n",
            "INFO:tensorflow:global step 115: loss = 4.3425 (4.807 sec/step)\n",
            "I1009 02:58:52.605334 140425799219072 learning.py:507] global step 115: loss = 4.3425 (4.807 sec/step)\n",
            "INFO:tensorflow:global step 116: loss = 4.5237 (4.860 sec/step)\n",
            "I1009 02:58:57.467414 140425799219072 learning.py:507] global step 116: loss = 4.5237 (4.860 sec/step)\n",
            "INFO:tensorflow:global step 117: loss = 4.3513 (5.018 sec/step)\n",
            "I1009 02:59:02.487257 140425799219072 learning.py:507] global step 117: loss = 4.3513 (5.018 sec/step)\n",
            "INFO:tensorflow:global step 118: loss = 4.4978 (4.701 sec/step)\n",
            "I1009 02:59:07.189932 140425799219072 learning.py:507] global step 118: loss = 4.4978 (4.701 sec/step)\n",
            "INFO:tensorflow:global step 119: loss = 4.7097 (4.796 sec/step)\n",
            "I1009 02:59:11.988235 140425799219072 learning.py:507] global step 119: loss = 4.7097 (4.796 sec/step)\n",
            "INFO:tensorflow:global step 120: loss = 4.3746 (4.804 sec/step)\n",
            "I1009 02:59:16.793888 140425799219072 learning.py:507] global step 120: loss = 4.3746 (4.804 sec/step)\n",
            "INFO:tensorflow:global step 121: loss = 4.6001 (4.686 sec/step)\n",
            "I1009 02:59:21.481911 140425799219072 learning.py:507] global step 121: loss = 4.6001 (4.686 sec/step)\n",
            "INFO:tensorflow:global step 122: loss = 4.4534 (4.855 sec/step)\n",
            "I1009 02:59:26.338338 140425799219072 learning.py:507] global step 122: loss = 4.4534 (4.855 sec/step)\n",
            "INFO:tensorflow:global step 123: loss = 4.5743 (4.930 sec/step)\n",
            "I1009 02:59:31.270504 140425799219072 learning.py:507] global step 123: loss = 4.5743 (4.930 sec/step)\n",
            "INFO:tensorflow:global step 124: loss = 3.7638 (4.713 sec/step)\n",
            "I1009 02:59:35.985301 140425799219072 learning.py:507] global step 124: loss = 3.7638 (4.713 sec/step)\n",
            "INFO:tensorflow:global step 125: loss = 3.8659 (4.813 sec/step)\n",
            "I1009 02:59:40.799575 140425799219072 learning.py:507] global step 125: loss = 3.8659 (4.813 sec/step)\n",
            "INFO:tensorflow:global step 126: loss = 3.8749 (4.702 sec/step)\n",
            "I1009 02:59:45.503045 140425799219072 learning.py:507] global step 126: loss = 3.8749 (4.702 sec/step)\n",
            "INFO:tensorflow:global step 127: loss = 4.0972 (4.807 sec/step)\n",
            "I1009 02:59:50.311623 140425799219072 learning.py:507] global step 127: loss = 4.0972 (4.807 sec/step)\n",
            "INFO:tensorflow:global step 128: loss = 4.3935 (4.939 sec/step)\n",
            "I1009 02:59:55.252920 140425799219072 learning.py:507] global step 128: loss = 4.3935 (4.939 sec/step)\n",
            "INFO:tensorflow:global step 129: loss = 4.3016 (4.766 sec/step)\n",
            "I1009 03:00:00.020876 140425799219072 learning.py:507] global step 129: loss = 4.3016 (4.766 sec/step)\n",
            "INFO:tensorflow:global step 130: loss = 4.6084 (4.969 sec/step)\n",
            "I1009 03:00:04.991802 140425799219072 learning.py:507] global step 130: loss = 4.6084 (4.969 sec/step)\n",
            "INFO:tensorflow:global step 131: loss = 4.1556 (4.738 sec/step)\n",
            "I1009 03:00:09.731941 140425799219072 learning.py:507] global step 131: loss = 4.1556 (4.738 sec/step)\n",
            "INFO:tensorflow:global step 132: loss = 4.0270 (4.713 sec/step)\n",
            "I1009 03:00:14.446681 140425799219072 learning.py:507] global step 132: loss = 4.0270 (4.713 sec/step)\n",
            "INFO:tensorflow:global step 133: loss = 3.7346 (7.295 sec/step)\n",
            "I1009 03:00:21.744475 140425799219072 learning.py:507] global step 133: loss = 3.7346 (7.295 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 133.\n",
            "I1009 03:00:25.352104 140422698682112 supervisor.py:1050] Recording summary at step 133.\n",
            "INFO:tensorflow:global step 134: loss = 4.4291 (5.486 sec/step)\n",
            "I1009 03:00:27.232753 140425799219072 learning.py:507] global step 134: loss = 4.4291 (5.486 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.20915\n",
            "I1009 03:00:28.249072 140422673504000 supervisor.py:1099] global_step/sec: 0.20915\n",
            "INFO:tensorflow:global step 135: loss = 3.7239 (4.958 sec/step)\n",
            "I1009 03:00:32.193057 140425799219072 learning.py:507] global step 135: loss = 3.7239 (4.958 sec/step)\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb60b752000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:global step 136: loss = 4.6582 (5.858 sec/step)\n",
            "I1009 03:00:38.053159 140425799219072 learning.py:507] global step 136: loss = 4.6582 (5.858 sec/step)\n",
            "INFO:tensorflow:global step 137: loss = 4.2691 (4.969 sec/step)\n",
            "I1009 03:00:43.024152 140425799219072 learning.py:507] global step 137: loss = 4.2691 (4.969 sec/step)\n",
            "INFO:tensorflow:global step 138: loss = 4.3050 (4.900 sec/step)\n",
            "I1009 03:00:47.926181 140425799219072 learning.py:507] global step 138: loss = 4.3050 (4.900 sec/step)\n",
            "INFO:tensorflow:global step 139: loss = 4.3589 (5.044 sec/step)\n",
            "I1009 03:00:52.972131 140425799219072 learning.py:507] global step 139: loss = 4.3589 (5.044 sec/step)\n",
            "INFO:tensorflow:global step 140: loss = 4.1867 (4.831 sec/step)\n",
            "I1009 03:00:57.805418 140425799219072 learning.py:507] global step 140: loss = 4.1867 (4.831 sec/step)\n",
            "INFO:tensorflow:global step 141: loss = 4.2342 (4.755 sec/step)\n",
            "I1009 03:01:02.562447 140425799219072 learning.py:507] global step 141: loss = 4.2342 (4.755 sec/step)\n",
            "INFO:tensorflow:global step 142: loss = 3.7521 (5.253 sec/step)\n",
            "I1009 03:01:07.817638 140425799219072 learning.py:507] global step 142: loss = 3.7521 (5.253 sec/step)\n",
            "INFO:tensorflow:global step 143: loss = 3.5239 (4.750 sec/step)\n",
            "I1009 03:01:12.569605 140425799219072 learning.py:507] global step 143: loss = 3.5239 (4.750 sec/step)\n",
            "INFO:tensorflow:global step 144: loss = 3.4888 (5.105 sec/step)\n",
            "I1009 03:01:17.676471 140425799219072 learning.py:507] global step 144: loss = 3.4888 (5.105 sec/step)\n",
            "INFO:tensorflow:global step 145: loss = 4.6003 (4.789 sec/step)\n",
            "I1009 03:01:22.468156 140425799219072 learning.py:507] global step 145: loss = 4.6003 (4.789 sec/step)\n",
            "INFO:tensorflow:global step 146: loss = 4.1381 (4.831 sec/step)\n",
            "I1009 03:01:27.301137 140425799219072 learning.py:507] global step 146: loss = 4.1381 (4.831 sec/step)\n",
            "INFO:tensorflow:global step 147: loss = 3.7230 (4.789 sec/step)\n",
            "I1009 03:01:32.092605 140425799219072 learning.py:507] global step 147: loss = 3.7230 (4.789 sec/step)\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb541d52000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:global step 148: loss = 3.5781 (5.843 sec/step)\n",
            "I1009 03:01:37.936982 140425799219072 learning.py:507] global step 148: loss = 3.5781 (5.843 sec/step)\n",
            "INFO:tensorflow:global step 149: loss = 4.3192 (4.879 sec/step)\n",
            "I1009 03:01:42.818363 140425799219072 learning.py:507] global step 149: loss = 4.3192 (4.879 sec/step)\n",
            "INFO:tensorflow:global step 150: loss = 3.5135 (5.106 sec/step)\n",
            "I1009 03:01:47.926150 140425799219072 learning.py:507] global step 150: loss = 3.5135 (5.106 sec/step)\n",
            "INFO:tensorflow:global step 151: loss = 3.8501 (5.013 sec/step)\n",
            "I1009 03:01:52.941322 140425799219072 learning.py:507] global step 151: loss = 3.8501 (5.013 sec/step)\n",
            "INFO:tensorflow:global step 152: loss = 3.2813 (4.830 sec/step)\n",
            "I1009 03:01:57.773911 140425799219072 learning.py:507] global step 152: loss = 3.2813 (4.830 sec/step)\n",
            "INFO:tensorflow:global step 153: loss = 3.4921 (4.912 sec/step)\n",
            "I1009 03:02:02.688288 140425799219072 learning.py:507] global step 153: loss = 3.4921 (4.912 sec/step)\n",
            "INFO:tensorflow:global step 154: loss = 3.4796 (5.199 sec/step)\n",
            "I1009 03:02:07.889530 140425799219072 learning.py:507] global step 154: loss = 3.4796 (5.199 sec/step)\n",
            "INFO:tensorflow:global step 155: loss = 3.3516 (5.162 sec/step)\n",
            "I1009 03:02:13.053594 140425799219072 learning.py:507] global step 155: loss = 3.3516 (5.162 sec/step)\n",
            "INFO:tensorflow:global step 156: loss = 4.4592 (5.300 sec/step)\n",
            "I1009 03:02:18.356279 140425799219072 learning.py:507] global step 156: loss = 4.4592 (5.300 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 156.\n",
            "I1009 03:02:25.469838 140422698682112 supervisor.py:1050] Recording summary at step 156.\n",
            "INFO:tensorflow:global step 157: loss = 4.3189 (8.159 sec/step)\n",
            "I1009 03:02:26.518253 140425799219072 learning.py:507] global step 157: loss = 4.3189 (8.159 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.191666\n",
            "I1009 03:02:28.249542 140422673504000 supervisor.py:1099] global_step/sec: 0.191666\n",
            "INFO:tensorflow:global step 158: loss = 4.3549 (4.844 sec/step)\n",
            "I1009 03:02:31.363697 140425799219072 learning.py:507] global step 158: loss = 4.3549 (4.844 sec/step)\n",
            "INFO:tensorflow:global step 159: loss = 4.2224 (4.802 sec/step)\n",
            "I1009 03:02:36.167571 140425799219072 learning.py:507] global step 159: loss = 4.2224 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 160: loss = 3.8814 (5.261 sec/step)\n",
            "I1009 03:02:41.430162 140425799219072 learning.py:507] global step 160: loss = 3.8814 (5.261 sec/step)\n",
            "INFO:tensorflow:global step 161: loss = 3.4374 (4.970 sec/step)\n",
            "I1009 03:02:46.402345 140425799219072 learning.py:507] global step 161: loss = 3.4374 (4.970 sec/step)\n",
            "INFO:tensorflow:global step 162: loss = 2.8510 (5.298 sec/step)\n",
            "I1009 03:02:51.702181 140425799219072 learning.py:507] global step 162: loss = 2.8510 (5.298 sec/step)\n",
            "INFO:tensorflow:global step 163: loss = 3.2980 (5.687 sec/step)\n",
            "I1009 03:02:57.391269 140425799219072 learning.py:507] global step 163: loss = 3.2980 (5.687 sec/step)\n",
            "INFO:tensorflow:global step 164: loss = 3.4238 (5.103 sec/step)\n",
            "I1009 03:03:02.496180 140425799219072 learning.py:507] global step 164: loss = 3.4238 (5.103 sec/step)\n",
            "INFO:tensorflow:global step 165: loss = 3.3265 (5.325 sec/step)\n",
            "I1009 03:03:07.823443 140425799219072 learning.py:507] global step 165: loss = 3.3265 (5.325 sec/step)\n",
            "INFO:tensorflow:global step 166: loss = 3.1542 (4.907 sec/step)\n",
            "I1009 03:03:12.738965 140425799219072 learning.py:507] global step 166: loss = 3.1542 (4.907 sec/step)\n",
            "INFO:tensorflow:global step 167: loss = 3.6380 (4.851 sec/step)\n",
            "I1009 03:03:17.591463 140425799219072 learning.py:507] global step 167: loss = 3.6380 (4.851 sec/step)\n",
            "INFO:tensorflow:global step 168: loss = 3.2073 (4.896 sec/step)\n",
            "I1009 03:03:22.489656 140425799219072 learning.py:507] global step 168: loss = 3.2073 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 169: loss = 3.7675 (5.250 sec/step)\n",
            "I1009 03:03:27.741845 140425799219072 learning.py:507] global step 169: loss = 3.7675 (5.250 sec/step)\n",
            "INFO:tensorflow:global step 170: loss = 3.2592 (5.002 sec/step)\n",
            "I1009 03:03:32.746322 140425799219072 learning.py:507] global step 170: loss = 3.2592 (5.002 sec/step)\n",
            "INFO:tensorflow:global step 171: loss = 3.2439 (4.927 sec/step)\n",
            "I1009 03:03:37.675289 140425799219072 learning.py:507] global step 171: loss = 3.2439 (4.927 sec/step)\n",
            "INFO:tensorflow:global step 172: loss = 3.3901 (4.946 sec/step)\n",
            "I1009 03:03:42.623815 140425799219072 learning.py:507] global step 172: loss = 3.3901 (4.946 sec/step)\n",
            "INFO:tensorflow:global step 173: loss = 3.4010 (4.870 sec/step)\n",
            "I1009 03:03:47.495807 140425799219072 learning.py:507] global step 173: loss = 3.4010 (4.870 sec/step)\n",
            "INFO:tensorflow:global step 174: loss = 3.2029 (4.904 sec/step)\n",
            "I1009 03:03:52.402087 140425799219072 learning.py:507] global step 174: loss = 3.2029 (4.904 sec/step)\n",
            "INFO:tensorflow:global step 175: loss = 3.6163 (4.815 sec/step)\n",
            "I1009 03:03:57.219201 140425799219072 learning.py:507] global step 175: loss = 3.6163 (4.815 sec/step)\n",
            "INFO:tensorflow:global step 176: loss = 3.3633 (4.818 sec/step)\n",
            "I1009 03:04:02.039352 140425799219072 learning.py:507] global step 176: loss = 3.3633 (4.818 sec/step)\n",
            "INFO:tensorflow:global step 177: loss = 3.8671 (4.935 sec/step)\n",
            "I1009 03:04:06.976551 140425799219072 learning.py:507] global step 177: loss = 3.8671 (4.935 sec/step)\n",
            "INFO:tensorflow:global step 178: loss = 3.1660 (4.787 sec/step)\n",
            "I1009 03:04:11.765072 140425799219072 learning.py:507] global step 178: loss = 3.1660 (4.787 sec/step)\n",
            "INFO:tensorflow:global step 179: loss = 3.3497 (4.851 sec/step)\n",
            "I1009 03:04:16.617966 140425799219072 learning.py:507] global step 179: loss = 3.3497 (4.851 sec/step)\n",
            "INFO:tensorflow:global step 180: loss = 3.8292 (7.960 sec/step)\n",
            "I1009 03:04:24.580116 140425799219072 learning.py:507] global step 180: loss = 3.8292 (7.960 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 180.\n",
            "I1009 03:04:24.831788 140422698682112 supervisor.py:1050] Recording summary at step 180.\n",
            "INFO:tensorflow:global_step/sec: 0.191667\n",
            "I1009 03:04:28.249382 140422673504000 supervisor.py:1099] global_step/sec: 0.191667\n",
            "INFO:tensorflow:global step 181: loss = 3.4392 (4.897 sec/step)\n",
            "I1009 03:04:29.482357 140425799219072 learning.py:507] global step 181: loss = 3.4392 (4.897 sec/step)\n",
            "INFO:tensorflow:global step 182: loss = 3.1806 (4.822 sec/step)\n",
            "I1009 03:04:34.305801 140425799219072 learning.py:507] global step 182: loss = 3.1806 (4.822 sec/step)\n",
            "INFO:tensorflow:global step 183: loss = 3.1951 (4.791 sec/step)\n",
            "I1009 03:04:39.098465 140425799219072 learning.py:507] global step 183: loss = 3.1951 (4.791 sec/step)\n",
            "INFO:tensorflow:global step 184: loss = 3.2196 (4.824 sec/step)\n",
            "I1009 03:04:43.924282 140425799219072 learning.py:507] global step 184: loss = 3.2196 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 185: loss = 3.2943 (4.921 sec/step)\n",
            "I1009 03:04:48.847230 140425799219072 learning.py:507] global step 185: loss = 3.2943 (4.921 sec/step)\n",
            "INFO:tensorflow:global step 186: loss = 3.5157 (4.775 sec/step)\n",
            "I1009 03:04:53.623719 140425799219072 learning.py:507] global step 186: loss = 3.5157 (4.775 sec/step)\n",
            "INFO:tensorflow:global step 187: loss = 3.5606 (4.917 sec/step)\n",
            "I1009 03:04:58.542678 140425799219072 learning.py:507] global step 187: loss = 3.5606 (4.917 sec/step)\n",
            "INFO:tensorflow:global step 188: loss = 3.2305 (4.782 sec/step)\n",
            "I1009 03:05:03.326407 140425799219072 learning.py:507] global step 188: loss = 3.2305 (4.782 sec/step)\n",
            "INFO:tensorflow:global step 189: loss = 3.5054 (4.837 sec/step)\n",
            "I1009 03:05:08.166252 140425799219072 learning.py:507] global step 189: loss = 3.5054 (4.837 sec/step)\n",
            "INFO:tensorflow:global step 190: loss = 3.9835 (4.843 sec/step)\n",
            "I1009 03:05:13.011493 140425799219072 learning.py:507] global step 190: loss = 3.9835 (4.843 sec/step)\n",
            "INFO:tensorflow:global step 191: loss = 3.4004 (4.787 sec/step)\n",
            "I1009 03:05:17.801609 140425799219072 learning.py:507] global step 191: loss = 3.4004 (4.787 sec/step)\n",
            "INFO:tensorflow:global step 192: loss = 2.7195 (4.839 sec/step)\n",
            "I1009 03:05:22.642341 140425799219072 learning.py:507] global step 192: loss = 2.7195 (4.839 sec/step)\n",
            "INFO:tensorflow:global step 193: loss = 3.8043 (4.861 sec/step)\n",
            "I1009 03:05:27.505541 140425799219072 learning.py:507] global step 193: loss = 3.8043 (4.861 sec/step)\n",
            "INFO:tensorflow:global step 194: loss = 3.2790 (4.990 sec/step)\n",
            "I1009 03:05:32.496999 140425799219072 learning.py:507] global step 194: loss = 3.2790 (4.990 sec/step)\n",
            "INFO:tensorflow:global step 195: loss = 2.9747 (4.773 sec/step)\n",
            "I1009 03:05:37.271958 140425799219072 learning.py:507] global step 195: loss = 2.9747 (4.773 sec/step)\n",
            "INFO:tensorflow:global step 196: loss = 3.2193 (4.775 sec/step)\n",
            "I1009 03:05:42.049159 140425799219072 learning.py:507] global step 196: loss = 3.2193 (4.775 sec/step)\n",
            "INFO:tensorflow:global step 197: loss = 3.4103 (5.067 sec/step)\n",
            "I1009 03:05:47.117857 140425799219072 learning.py:507] global step 197: loss = 3.4103 (5.067 sec/step)\n",
            "INFO:tensorflow:global step 198: loss = 2.8568 (4.787 sec/step)\n",
            "I1009 03:05:51.907485 140425799219072 learning.py:507] global step 198: loss = 2.8568 (4.787 sec/step)\n",
            "INFO:tensorflow:global step 199: loss = 3.2020 (4.878 sec/step)\n",
            "I1009 03:05:56.788093 140425799219072 learning.py:507] global step 199: loss = 3.2020 (4.878 sec/step)\n",
            "INFO:tensorflow:global step 200: loss = 3.3050 (4.790 sec/step)\n",
            "I1009 03:06:01.579287 140425799219072 learning.py:507] global step 200: loss = 3.3050 (4.790 sec/step)\n",
            "INFO:tensorflow:global step 201: loss = 2.6287 (4.736 sec/step)\n",
            "I1009 03:06:06.316889 140425799219072 learning.py:507] global step 201: loss = 2.6287 (4.736 sec/step)\n",
            "INFO:tensorflow:global step 202: loss = 3.3931 (4.947 sec/step)\n",
            "I1009 03:06:11.265743 140425799219072 learning.py:507] global step 202: loss = 3.3931 (4.947 sec/step)\n",
            "INFO:tensorflow:global step 203: loss = 3.0503 (4.740 sec/step)\n",
            "I1009 03:06:16.007817 140425799219072 learning.py:507] global step 203: loss = 3.0503 (4.740 sec/step)\n",
            "INFO:tensorflow:global step 204: loss = 3.7916 (8.126 sec/step)\n",
            "I1009 03:06:24.135984 140425799219072 learning.py:507] global step 204: loss = 3.7916 (8.126 sec/step)\n",
            "tcmalloc: large alloc 2010562560 bytes == 0x7fb5ba2be000 @  0x7fb76d9c1b6b 0x7fb76d9e1379 0x7fb734659037 0x7fb73444674f 0x7fb73430baeb 0x7fb7342d14d6 0x7fb7342d41e1 0x7fb73d1daf68 0x7fb73d292ddc 0x7fb73d2933a8 0x7fb73d16d49f 0x7fb73d1f2886 0x7fb73d1f1ace 0x7fb73a89ae20 0x7fb734589329 0x7fb73457ce45 0x7fb73463af79 0x7fb734638648 0x7fb76c2c166f 0x7fb76d3a36db 0x7fb76d6dc88f\n",
            "INFO:tensorflow:Recording summary at step 204.\n",
            "I1009 03:06:24.381688 140422698682112 supervisor.py:1050] Recording summary at step 204.\n",
            "INFO:tensorflow:global_step/sec: 0.2\n",
            "I1009 03:06:28.249199 140422673504000 supervisor.py:1099] global_step/sec: 0.2\n",
            "INFO:tensorflow:global step 205: loss = 3.2643 (5.088 sec/step)\n",
            "I1009 03:06:29.226002 140425799219072 learning.py:507] global step 205: loss = 3.2643 (5.088 sec/step)\n",
            "INFO:tensorflow:global step 206: loss = 3.8418 (4.828 sec/step)\n",
            "I1009 03:06:34.055726 140425799219072 learning.py:507] global step 206: loss = 3.8418 (4.828 sec/step)\n",
            "INFO:tensorflow:global step 207: loss = 3.1735 (5.058 sec/step)\n",
            "I1009 03:06:39.115664 140425799219072 learning.py:507] global step 207: loss = 3.1735 (5.058 sec/step)\n",
            "INFO:tensorflow:global step 208: loss = 3.2660 (4.968 sec/step)\n",
            "I1009 03:06:44.086050 140425799219072 learning.py:507] global step 208: loss = 3.2660 (4.968 sec/step)\n",
            "INFO:tensorflow:global step 209: loss = 3.4648 (4.789 sec/step)\n",
            "I1009 03:06:48.876916 140425799219072 learning.py:507] global step 209: loss = 3.4648 (4.789 sec/step)\n",
            "INFO:tensorflow:global step 210: loss = 3.7523 (4.768 sec/step)\n",
            "I1009 03:06:53.646492 140425799219072 learning.py:507] global step 210: loss = 3.7523 (4.768 sec/step)\n",
            "INFO:tensorflow:global step 211: loss = 4.1169 (5.369 sec/step)\n",
            "I1009 03:06:59.018168 140425799219072 learning.py:507] global step 211: loss = 4.1169 (5.369 sec/step)\n",
            "INFO:tensorflow:global step 212: loss = 3.6238 (4.895 sec/step)\n",
            "I1009 03:07:03.914967 140425799219072 learning.py:507] global step 212: loss = 3.6238 (4.895 sec/step)\n",
            "INFO:tensorflow:global step 213: loss = 3.2736 (5.075 sec/step)\n",
            "I1009 03:07:08.991862 140425799219072 learning.py:507] global step 213: loss = 3.2736 (5.075 sec/step)\n",
            "INFO:tensorflow:global step 214: loss = 3.3125 (4.856 sec/step)\n",
            "I1009 03:07:13.850251 140425799219072 learning.py:507] global step 214: loss = 3.3125 (4.856 sec/step)\n",
            "INFO:tensorflow:global step 215: loss = 2.9866 (4.879 sec/step)\n",
            "I1009 03:07:18.731802 140425799219072 learning.py:507] global step 215: loss = 2.9866 (4.879 sec/step)\n",
            "INFO:tensorflow:global step 216: loss = 3.0167 (4.842 sec/step)\n",
            "I1009 03:07:23.576285 140425799219072 learning.py:507] global step 216: loss = 3.0167 (4.842 sec/step)\n",
            "INFO:tensorflow:global step 217: loss = 3.0723 (4.819 sec/step)\n",
            "I1009 03:07:28.397117 140425799219072 learning.py:507] global step 217: loss = 3.0723 (4.819 sec/step)\n",
            "INFO:tensorflow:global step 218: loss = 3.2122 (4.860 sec/step)\n",
            "I1009 03:07:33.258816 140425799219072 learning.py:507] global step 218: loss = 3.2122 (4.860 sec/step)\n",
            "INFO:tensorflow:global step 219: loss = 2.9767 (4.774 sec/step)\n",
            "I1009 03:07:38.034358 140425799219072 learning.py:507] global step 219: loss = 2.9767 (4.774 sec/step)\n",
            "INFO:tensorflow:global step 220: loss = 2.6614 (4.664 sec/step)\n",
            "I1009 03:07:42.700004 140425799219072 learning.py:507] global step 220: loss = 2.6614 (4.664 sec/step)\n",
            "INFO:tensorflow:global step 221: loss = 2.7983 (4.711 sec/step)\n",
            "I1009 03:07:47.412618 140425799219072 learning.py:507] global step 221: loss = 2.7983 (4.711 sec/step)\n",
            "INFO:tensorflow:global step 222: loss = 2.7128 (4.623 sec/step)\n",
            "I1009 03:07:52.037472 140425799219072 learning.py:507] global step 222: loss = 2.7128 (4.623 sec/step)\n",
            "INFO:tensorflow:global step 223: loss = 2.8558 (4.669 sec/step)\n",
            "I1009 03:07:56.708307 140425799219072 learning.py:507] global step 223: loss = 2.8558 (4.669 sec/step)\n",
            "INFO:tensorflow:global step 224: loss = 2.7545 (4.644 sec/step)\n",
            "I1009 03:08:01.353858 140425799219072 learning.py:507] global step 224: loss = 2.7545 (4.644 sec/step)\n",
            "INFO:tensorflow:global step 225: loss = 3.2196 (4.771 sec/step)\n",
            "I1009 03:08:06.126564 140425799219072 learning.py:507] global step 225: loss = 3.2196 (4.771 sec/step)\n",
            "INFO:tensorflow:global step 226: loss = 3.2389 (4.717 sec/step)\n",
            "I1009 03:08:10.844914 140425799219072 learning.py:507] global step 226: loss = 3.2389 (4.717 sec/step)\n",
            "INFO:tensorflow:global step 227: loss = 3.2763 (4.906 sec/step)\n",
            "I1009 03:08:15.752949 140425799219072 learning.py:507] global step 227: loss = 3.2763 (4.906 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:08:17.244266 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 228.\n",
            "I1009 03:08:26.116547 140422698682112 supervisor.py:1050] Recording summary at step 228.\n",
            "INFO:tensorflow:global step 228: loss = 2.8392 (10.363 sec/step)\n",
            "I1009 03:08:26.124063 140425799219072 learning.py:507] global step 228: loss = 2.8392 (10.363 sec/step)\n",
            "INFO:tensorflow:global step 229: loss = 3.3594 (5.402 sec/step)\n",
            "I1009 03:08:31.537337 140425799219072 learning.py:507] global step 229: loss = 3.3594 (5.402 sec/step)\n",
            "INFO:tensorflow:global step 230: loss = 2.8705 (4.962 sec/step)\n",
            "I1009 03:08:36.501003 140425799219072 learning.py:507] global step 230: loss = 2.8705 (4.962 sec/step)\n",
            "INFO:tensorflow:global step 231: loss = 2.5583 (4.750 sec/step)\n",
            "I1009 03:08:41.253286 140425799219072 learning.py:507] global step 231: loss = 2.5583 (4.750 sec/step)\n",
            "INFO:tensorflow:global step 232: loss = 3.5021 (4.947 sec/step)\n",
            "I1009 03:08:46.201808 140425799219072 learning.py:507] global step 232: loss = 3.5021 (4.947 sec/step)\n",
            "INFO:tensorflow:global step 233: loss = 3.1601 (5.231 sec/step)\n",
            "I1009 03:08:51.434738 140425799219072 learning.py:507] global step 233: loss = 3.1601 (5.231 sec/step)\n",
            "INFO:tensorflow:global step 234: loss = 3.1984 (4.716 sec/step)\n",
            "I1009 03:08:56.153188 140425799219072 learning.py:507] global step 234: loss = 3.1984 (4.716 sec/step)\n",
            "INFO:tensorflow:global step 235: loss = 2.9156 (4.735 sec/step)\n",
            "I1009 03:09:00.890375 140425799219072 learning.py:507] global step 235: loss = 2.9156 (4.735 sec/step)\n",
            "INFO:tensorflow:global step 236: loss = 2.7972 (4.907 sec/step)\n",
            "I1009 03:09:05.798919 140425799219072 learning.py:507] global step 236: loss = 2.7972 (4.907 sec/step)\n",
            "INFO:tensorflow:global step 237: loss = 2.6409 (4.703 sec/step)\n",
            "I1009 03:09:10.503474 140425799219072 learning.py:507] global step 237: loss = 2.6409 (4.703 sec/step)\n",
            "INFO:tensorflow:global step 238: loss = 2.5975 (4.734 sec/step)\n",
            "I1009 03:09:15.239239 140425799219072 learning.py:507] global step 238: loss = 2.5975 (4.734 sec/step)\n",
            "INFO:tensorflow:global step 239: loss = 2.5852 (4.740 sec/step)\n",
            "I1009 03:09:19.981401 140425799219072 learning.py:507] global step 239: loss = 2.5852 (4.740 sec/step)\n",
            "INFO:tensorflow:global step 240: loss = 2.4891 (4.593 sec/step)\n",
            "I1009 03:09:24.576950 140425799219072 learning.py:507] global step 240: loss = 2.4891 (4.593 sec/step)\n",
            "INFO:tensorflow:global step 241: loss = 3.1396 (4.693 sec/step)\n",
            "I1009 03:09:29.272146 140425799219072 learning.py:507] global step 241: loss = 3.1396 (4.693 sec/step)\n",
            "INFO:tensorflow:global step 242: loss = 2.8907 (4.936 sec/step)\n",
            "I1009 03:09:34.210328 140425799219072 learning.py:507] global step 242: loss = 2.8907 (4.936 sec/step)\n",
            "INFO:tensorflow:global step 243: loss = 2.9415 (4.826 sec/step)\n",
            "I1009 03:09:39.038707 140425799219072 learning.py:507] global step 243: loss = 2.9415 (4.826 sec/step)\n",
            "INFO:tensorflow:global step 244: loss = 3.0020 (4.878 sec/step)\n",
            "I1009 03:09:43.918662 140425799219072 learning.py:507] global step 244: loss = 3.0020 (4.878 sec/step)\n",
            "INFO:tensorflow:global step 245: loss = 3.2642 (5.104 sec/step)\n",
            "I1009 03:09:49.024009 140425799219072 learning.py:507] global step 245: loss = 3.2642 (5.104 sec/step)\n",
            "INFO:tensorflow:global step 246: loss = 2.8521 (4.853 sec/step)\n",
            "I1009 03:09:53.878585 140425799219072 learning.py:507] global step 246: loss = 2.8521 (4.853 sec/step)\n",
            "INFO:tensorflow:global step 247: loss = 2.6044 (4.987 sec/step)\n",
            "I1009 03:09:58.867580 140425799219072 learning.py:507] global step 247: loss = 2.6044 (4.987 sec/step)\n",
            "INFO:tensorflow:global step 248: loss = 3.1440 (4.901 sec/step)\n",
            "I1009 03:10:03.770591 140425799219072 learning.py:507] global step 248: loss = 3.1440 (4.901 sec/step)\n",
            "INFO:tensorflow:global step 249: loss = 3.4870 (4.820 sec/step)\n",
            "I1009 03:10:08.592415 140425799219072 learning.py:507] global step 249: loss = 3.4870 (4.820 sec/step)\n",
            "INFO:tensorflow:global step 250: loss = 3.0057 (4.933 sec/step)\n",
            "I1009 03:10:13.527250 140425799219072 learning.py:507] global step 250: loss = 3.0057 (4.933 sec/step)\n",
            "INFO:tensorflow:global step 251: loss = 2.9021 (6.948 sec/step)\n",
            "I1009 03:10:20.481694 140425799219072 learning.py:507] global step 251: loss = 2.9021 (6.948 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 251.\n",
            "I1009 03:10:25.356545 140422698682112 supervisor.py:1050] Recording summary at step 251.\n",
            "INFO:tensorflow:global step 252: loss = 2.9151 (6.235 sec/step)\n",
            "I1009 03:10:26.723940 140425799219072 learning.py:507] global step 252: loss = 2.9151 (6.235 sec/step)\n",
            "INFO:tensorflow:global step 253: loss = 2.7378 (5.072 sec/step)\n",
            "I1009 03:10:31.798169 140425799219072 learning.py:507] global step 253: loss = 2.7378 (5.072 sec/step)\n",
            "INFO:tensorflow:global step 254: loss = 3.4800 (4.780 sec/step)\n",
            "I1009 03:10:36.580316 140425799219072 learning.py:507] global step 254: loss = 3.4800 (4.780 sec/step)\n",
            "INFO:tensorflow:global step 255: loss = 3.0999 (4.976 sec/step)\n",
            "I1009 03:10:41.557965 140425799219072 learning.py:507] global step 255: loss = 3.0999 (4.976 sec/step)\n",
            "INFO:tensorflow:global step 256: loss = 2.7793 (4.842 sec/step)\n",
            "I1009 03:10:46.402284 140425799219072 learning.py:507] global step 256: loss = 2.7793 (4.842 sec/step)\n",
            "INFO:tensorflow:global step 257: loss = 3.6366 (4.699 sec/step)\n",
            "I1009 03:10:51.102963 140425799219072 learning.py:507] global step 257: loss = 3.6366 (4.699 sec/step)\n",
            "INFO:tensorflow:global step 258: loss = 3.2267 (4.910 sec/step)\n",
            "I1009 03:10:56.014989 140425799219072 learning.py:507] global step 258: loss = 3.2267 (4.910 sec/step)\n",
            "INFO:tensorflow:global step 259: loss = 3.1072 (4.968 sec/step)\n",
            "I1009 03:11:00.985858 140425799219072 learning.py:507] global step 259: loss = 3.1072 (4.968 sec/step)\n",
            "INFO:tensorflow:global step 260: loss = 3.1528 (4.807 sec/step)\n",
            "I1009 03:11:05.794630 140425799219072 learning.py:507] global step 260: loss = 3.1528 (4.807 sec/step)\n",
            "INFO:tensorflow:global step 261: loss = 3.6327 (4.802 sec/step)\n",
            "I1009 03:11:10.598840 140425799219072 learning.py:507] global step 261: loss = 3.6327 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 262: loss = 3.1206 (5.096 sec/step)\n",
            "I1009 03:11:15.696502 140425799219072 learning.py:507] global step 262: loss = 3.1206 (5.096 sec/step)\n",
            "INFO:tensorflow:global step 263: loss = 3.3434 (4.906 sec/step)\n",
            "I1009 03:11:20.603903 140425799219072 learning.py:507] global step 263: loss = 3.3434 (4.906 sec/step)\n",
            "INFO:tensorflow:global step 264: loss = 2.6310 (4.918 sec/step)\n",
            "I1009 03:11:25.524072 140425799219072 learning.py:507] global step 264: loss = 2.6310 (4.918 sec/step)\n",
            "INFO:tensorflow:global step 265: loss = 2.8634 (4.858 sec/step)\n",
            "I1009 03:11:30.383519 140425799219072 learning.py:507] global step 265: loss = 2.8634 (4.858 sec/step)\n",
            "INFO:tensorflow:global step 266: loss = 2.4097 (4.742 sec/step)\n",
            "I1009 03:11:35.127473 140425799219072 learning.py:507] global step 266: loss = 2.4097 (4.742 sec/step)\n",
            "INFO:tensorflow:global step 267: loss = 2.3309 (4.833 sec/step)\n",
            "I1009 03:11:39.962487 140425799219072 learning.py:507] global step 267: loss = 2.3309 (4.833 sec/step)\n",
            "INFO:tensorflow:global step 268: loss = 2.7156 (5.397 sec/step)\n",
            "I1009 03:11:45.361379 140425799219072 learning.py:507] global step 268: loss = 2.7156 (5.397 sec/step)\n",
            "INFO:tensorflow:global step 269: loss = 3.2093 (4.863 sec/step)\n",
            "I1009 03:11:50.226594 140425799219072 learning.py:507] global step 269: loss = 3.2093 (4.863 sec/step)\n",
            "INFO:tensorflow:global step 270: loss = 2.6103 (4.941 sec/step)\n",
            "I1009 03:11:55.170106 140425799219072 learning.py:507] global step 270: loss = 2.6103 (4.941 sec/step)\n",
            "INFO:tensorflow:global step 271: loss = 2.5817 (5.025 sec/step)\n",
            "I1009 03:12:00.197330 140425799219072 learning.py:507] global step 271: loss = 2.5817 (5.025 sec/step)\n",
            "INFO:tensorflow:global step 272: loss = 2.9967 (4.763 sec/step)\n",
            "I1009 03:12:04.962118 140425799219072 learning.py:507] global step 272: loss = 2.9967 (4.763 sec/step)\n",
            "INFO:tensorflow:global step 273: loss = 3.0068 (4.851 sec/step)\n",
            "I1009 03:12:09.814972 140425799219072 learning.py:507] global step 273: loss = 3.0068 (4.851 sec/step)\n",
            "INFO:tensorflow:global step 274: loss = 2.5301 (4.858 sec/step)\n",
            "I1009 03:12:14.674661 140425799219072 learning.py:507] global step 274: loss = 2.5301 (4.858 sec/step)\n",
            "INFO:tensorflow:global step 275: loss = 2.1915 (7.442 sec/step)\n",
            "I1009 03:12:22.124234 140425799219072 learning.py:507] global step 275: loss = 2.1915 (7.442 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 275.\n",
            "I1009 03:12:25.064725 140422698682112 supervisor.py:1050] Recording summary at step 275.\n",
            "INFO:tensorflow:global step 276: loss = 2.4703 (5.409 sec/step)\n",
            "I1009 03:12:27.545305 140425799219072 learning.py:507] global step 276: loss = 2.4703 (5.409 sec/step)\n",
            "INFO:tensorflow:global step 277: loss = 2.3444 (5.002 sec/step)\n",
            "I1009 03:12:32.549857 140425799219072 learning.py:507] global step 277: loss = 2.3444 (5.002 sec/step)\n",
            "INFO:tensorflow:global step 278: loss = 2.4039 (4.768 sec/step)\n",
            "I1009 03:12:37.319482 140425799219072 learning.py:507] global step 278: loss = 2.4039 (4.768 sec/step)\n",
            "INFO:tensorflow:global step 279: loss = 2.0331 (4.746 sec/step)\n",
            "I1009 03:12:42.067100 140425799219072 learning.py:507] global step 279: loss = 2.0331 (4.746 sec/step)\n",
            "INFO:tensorflow:global step 280: loss = 3.0120 (4.832 sec/step)\n",
            "I1009 03:12:46.900557 140425799219072 learning.py:507] global step 280: loss = 3.0120 (4.832 sec/step)\n",
            "INFO:tensorflow:global step 281: loss = 2.6827 (4.703 sec/step)\n",
            "I1009 03:12:51.605831 140425799219072 learning.py:507] global step 281: loss = 2.6827 (4.703 sec/step)\n",
            "INFO:tensorflow:global step 282: loss = 2.3856 (4.757 sec/step)\n",
            "I1009 03:12:56.365158 140425799219072 learning.py:507] global step 282: loss = 2.3856 (4.757 sec/step)\n",
            "INFO:tensorflow:global step 283: loss = 3.3255 (4.806 sec/step)\n",
            "I1009 03:13:01.173290 140425799219072 learning.py:507] global step 283: loss = 3.3255 (4.806 sec/step)\n",
            "INFO:tensorflow:global step 284: loss = 2.2140 (4.827 sec/step)\n",
            "I1009 03:13:06.002062 140425799219072 learning.py:507] global step 284: loss = 2.2140 (4.827 sec/step)\n",
            "INFO:tensorflow:global step 285: loss = 2.8096 (4.786 sec/step)\n",
            "I1009 03:13:10.789906 140425799219072 learning.py:507] global step 285: loss = 2.8096 (4.786 sec/step)\n",
            "INFO:tensorflow:global step 286: loss = 2.4891 (4.871 sec/step)\n",
            "I1009 03:13:15.663262 140425799219072 learning.py:507] global step 286: loss = 2.4891 (4.871 sec/step)\n",
            "INFO:tensorflow:global step 287: loss = 2.2552 (5.006 sec/step)\n",
            "I1009 03:13:20.671264 140425799219072 learning.py:507] global step 287: loss = 2.2552 (5.006 sec/step)\n",
            "INFO:tensorflow:global step 288: loss = 2.3357 (4.790 sec/step)\n",
            "I1009 03:13:25.463596 140425799219072 learning.py:507] global step 288: loss = 2.3357 (4.790 sec/step)\n",
            "INFO:tensorflow:global step 289: loss = 2.7820 (4.798 sec/step)\n",
            "I1009 03:13:30.263443 140425799219072 learning.py:507] global step 289: loss = 2.7820 (4.798 sec/step)\n",
            "INFO:tensorflow:global step 290: loss = 3.3798 (4.756 sec/step)\n",
            "I1009 03:13:35.021257 140425799219072 learning.py:507] global step 290: loss = 3.3798 (4.756 sec/step)\n",
            "INFO:tensorflow:global step 291: loss = 2.3365 (4.752 sec/step)\n",
            "I1009 03:13:39.775284 140425799219072 learning.py:507] global step 291: loss = 2.3365 (4.752 sec/step)\n",
            "INFO:tensorflow:global step 292: loss = 3.0337 (4.796 sec/step)\n",
            "I1009 03:13:44.572849 140425799219072 learning.py:507] global step 292: loss = 3.0337 (4.796 sec/step)\n",
            "INFO:tensorflow:global step 293: loss = 2.5277 (4.910 sec/step)\n",
            "I1009 03:13:49.484554 140425799219072 learning.py:507] global step 293: loss = 2.5277 (4.910 sec/step)\n",
            "INFO:tensorflow:global step 294: loss = 2.7575 (4.759 sec/step)\n",
            "I1009 03:13:54.245582 140425799219072 learning.py:507] global step 294: loss = 2.7575 (4.759 sec/step)\n",
            "INFO:tensorflow:global step 295: loss = 2.4592 (4.713 sec/step)\n",
            "I1009 03:13:58.960433 140425799219072 learning.py:507] global step 295: loss = 2.4592 (4.713 sec/step)\n",
            "INFO:tensorflow:global step 296: loss = 3.0995 (5.030 sec/step)\n",
            "I1009 03:14:03.992826 140425799219072 learning.py:507] global step 296: loss = 3.0995 (5.030 sec/step)\n",
            "INFO:tensorflow:global step 297: loss = 2.7813 (4.754 sec/step)\n",
            "I1009 03:14:08.749342 140425799219072 learning.py:507] global step 297: loss = 2.7813 (4.754 sec/step)\n",
            "INFO:tensorflow:global step 298: loss = 2.3496 (4.868 sec/step)\n",
            "I1009 03:14:13.619126 140425799219072 learning.py:507] global step 298: loss = 2.3496 (4.868 sec/step)\n",
            "INFO:tensorflow:global step 299: loss = 2.5020 (5.989 sec/step)\n",
            "I1009 03:14:19.644189 140425799219072 learning.py:507] global step 299: loss = 2.5020 (5.989 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 299.\n",
            "I1009 03:14:25.216572 140422698682112 supervisor.py:1050] Recording summary at step 299.\n",
            "INFO:tensorflow:global step 300: loss = 2.7921 (6.699 sec/step)\n",
            "I1009 03:14:26.385303 140425799219072 learning.py:507] global step 300: loss = 2.7921 (6.699 sec/step)\n",
            "INFO:tensorflow:global step 301: loss = 2.4990 (5.165 sec/step)\n",
            "I1009 03:14:31.552182 140425799219072 learning.py:507] global step 301: loss = 2.4990 (5.165 sec/step)\n",
            "INFO:tensorflow:global step 302: loss = 2.5336 (4.766 sec/step)\n",
            "I1009 03:14:36.320256 140425799219072 learning.py:507] global step 302: loss = 2.5336 (4.766 sec/step)\n",
            "INFO:tensorflow:global step 303: loss = 3.2303 (4.758 sec/step)\n",
            "I1009 03:14:41.080620 140425799219072 learning.py:507] global step 303: loss = 3.2303 (4.758 sec/step)\n",
            "INFO:tensorflow:global step 304: loss = 2.1868 (4.779 sec/step)\n",
            "I1009 03:14:45.861950 140425799219072 learning.py:507] global step 304: loss = 2.1868 (4.779 sec/step)\n",
            "INFO:tensorflow:global step 305: loss = 2.5298 (4.846 sec/step)\n",
            "I1009 03:14:50.710082 140425799219072 learning.py:507] global step 305: loss = 2.5298 (4.846 sec/step)\n",
            "INFO:tensorflow:global step 306: loss = 2.7265 (4.779 sec/step)\n",
            "I1009 03:14:55.490621 140425799219072 learning.py:507] global step 306: loss = 2.7265 (4.779 sec/step)\n",
            "INFO:tensorflow:global step 307: loss = 2.3985 (4.742 sec/step)\n",
            "I1009 03:15:00.234090 140425799219072 learning.py:507] global step 307: loss = 2.3985 (4.742 sec/step)\n",
            "INFO:tensorflow:global step 308: loss = 3.1212 (4.649 sec/step)\n",
            "I1009 03:15:04.885128 140425799219072 learning.py:507] global step 308: loss = 3.1212 (4.649 sec/step)\n",
            "INFO:tensorflow:global step 309: loss = 3.6148 (4.690 sec/step)\n",
            "I1009 03:15:09.576481 140425799219072 learning.py:507] global step 309: loss = 3.6148 (4.690 sec/step)\n",
            "INFO:tensorflow:global step 310: loss = 3.2972 (4.660 sec/step)\n",
            "I1009 03:15:14.238421 140425799219072 learning.py:507] global step 310: loss = 3.2972 (4.660 sec/step)\n",
            "INFO:tensorflow:global step 311: loss = 2.6316 (4.595 sec/step)\n",
            "I1009 03:15:18.836476 140425799219072 learning.py:507] global step 311: loss = 2.6316 (4.595 sec/step)\n",
            "INFO:tensorflow:global step 312: loss = 3.0734 (4.700 sec/step)\n",
            "I1009 03:15:23.540007 140425799219072 learning.py:507] global step 312: loss = 3.0734 (4.700 sec/step)\n",
            "INFO:tensorflow:global step 313: loss = 2.6490 (4.801 sec/step)\n",
            "I1009 03:15:28.343288 140425799219072 learning.py:507] global step 313: loss = 2.6490 (4.801 sec/step)\n",
            "INFO:tensorflow:global step 314: loss = 2.5693 (4.744 sec/step)\n",
            "I1009 03:15:33.089297 140425799219072 learning.py:507] global step 314: loss = 2.5693 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 315: loss = 2.4857 (4.831 sec/step)\n",
            "I1009 03:15:37.922710 140425799219072 learning.py:507] global step 315: loss = 2.4857 (4.831 sec/step)\n",
            "INFO:tensorflow:global step 316: loss = 3.2588 (4.767 sec/step)\n",
            "I1009 03:15:42.691723 140425799219072 learning.py:507] global step 316: loss = 3.2588 (4.767 sec/step)\n",
            "INFO:tensorflow:global step 317: loss = 2.6786 (4.788 sec/step)\n",
            "I1009 03:15:47.481980 140425799219072 learning.py:507] global step 317: loss = 2.6786 (4.788 sec/step)\n",
            "INFO:tensorflow:global step 318: loss = 2.6674 (4.779 sec/step)\n",
            "I1009 03:15:52.262944 140425799219072 learning.py:507] global step 318: loss = 2.6674 (4.779 sec/step)\n",
            "INFO:tensorflow:global step 319: loss = 1.9756 (4.872 sec/step)\n",
            "I1009 03:15:57.136688 140425799219072 learning.py:507] global step 319: loss = 1.9756 (4.872 sec/step)\n",
            "INFO:tensorflow:global step 320: loss = 2.5294 (4.840 sec/step)\n",
            "I1009 03:16:01.978418 140425799219072 learning.py:507] global step 320: loss = 2.5294 (4.840 sec/step)\n",
            "INFO:tensorflow:global step 321: loss = 3.0172 (4.935 sec/step)\n",
            "I1009 03:16:06.915013 140425799219072 learning.py:507] global step 321: loss = 3.0172 (4.935 sec/step)\n",
            "INFO:tensorflow:global step 322: loss = 2.8073 (4.835 sec/step)\n",
            "I1009 03:16:11.751389 140425799219072 learning.py:507] global step 322: loss = 2.8073 (4.835 sec/step)\n",
            "INFO:tensorflow:global step 323: loss = 3.0055 (4.873 sec/step)\n",
            "I1009 03:16:16.626236 140425799219072 learning.py:507] global step 323: loss = 3.0055 (4.873 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 323.\n",
            "I1009 03:16:23.775888 140422698682112 supervisor.py:1050] Recording summary at step 323.\n",
            "INFO:tensorflow:global step 324: loss = 2.2035 (8.150 sec/step)\n",
            "I1009 03:16:24.778165 140425799219072 learning.py:507] global step 324: loss = 2.2035 (8.150 sec/step)\n",
            "INFO:tensorflow:global step 325: loss = 2.5714 (4.744 sec/step)\n",
            "I1009 03:16:29.524482 140425799219072 learning.py:507] global step 325: loss = 2.5714 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 326: loss = 2.2372 (4.849 sec/step)\n",
            "I1009 03:16:34.375457 140425799219072 learning.py:507] global step 326: loss = 2.2372 (4.849 sec/step)\n",
            "INFO:tensorflow:global step 327: loss = 3.3795 (4.859 sec/step)\n",
            "I1009 03:16:39.236114 140425799219072 learning.py:507] global step 327: loss = 3.3795 (4.859 sec/step)\n",
            "INFO:tensorflow:global step 328: loss = 2.8348 (4.886 sec/step)\n",
            "I1009 03:16:44.124366 140425799219072 learning.py:507] global step 328: loss = 2.8348 (4.886 sec/step)\n",
            "INFO:tensorflow:global step 329: loss = 2.6552 (4.913 sec/step)\n",
            "I1009 03:16:49.039519 140425799219072 learning.py:507] global step 329: loss = 2.6552 (4.913 sec/step)\n",
            "INFO:tensorflow:global step 330: loss = 2.3094 (4.924 sec/step)\n",
            "I1009 03:16:53.965382 140425799219072 learning.py:507] global step 330: loss = 2.3094 (4.924 sec/step)\n",
            "INFO:tensorflow:global step 331: loss = 2.0583 (5.001 sec/step)\n",
            "I1009 03:16:58.968685 140425799219072 learning.py:507] global step 331: loss = 2.0583 (5.001 sec/step)\n",
            "INFO:tensorflow:global step 332: loss = 2.0328 (4.874 sec/step)\n",
            "I1009 03:17:03.844958 140425799219072 learning.py:507] global step 332: loss = 2.0328 (4.874 sec/step)\n",
            "INFO:tensorflow:global step 333: loss = 2.1710 (4.834 sec/step)\n",
            "I1009 03:17:08.681684 140425799219072 learning.py:507] global step 333: loss = 2.1710 (4.834 sec/step)\n",
            "INFO:tensorflow:global step 334: loss = 2.4160 (4.784 sec/step)\n",
            "I1009 03:17:13.467628 140425799219072 learning.py:507] global step 334: loss = 2.4160 (4.784 sec/step)\n",
            "INFO:tensorflow:global step 335: loss = 3.0211 (4.996 sec/step)\n",
            "I1009 03:17:18.465170 140425799219072 learning.py:507] global step 335: loss = 3.0211 (4.996 sec/step)\n",
            "INFO:tensorflow:global step 336: loss = 2.4159 (4.833 sec/step)\n",
            "I1009 03:17:23.300214 140425799219072 learning.py:507] global step 336: loss = 2.4159 (4.833 sec/step)\n",
            "INFO:tensorflow:global step 337: loss = 3.1420 (5.049 sec/step)\n",
            "I1009 03:17:28.351210 140425799219072 learning.py:507] global step 337: loss = 3.1420 (5.049 sec/step)\n",
            "INFO:tensorflow:global step 338: loss = 2.9830 (4.802 sec/step)\n",
            "I1009 03:17:33.155539 140425799219072 learning.py:507] global step 338: loss = 2.9830 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 339: loss = 2.2830 (4.867 sec/step)\n",
            "I1009 03:17:38.024324 140425799219072 learning.py:507] global step 339: loss = 2.2830 (4.867 sec/step)\n",
            "INFO:tensorflow:global step 340: loss = 2.3802 (4.801 sec/step)\n",
            "I1009 03:17:42.827220 140425799219072 learning.py:507] global step 340: loss = 2.3802 (4.801 sec/step)\n",
            "INFO:tensorflow:global step 341: loss = 2.7260 (4.864 sec/step)\n",
            "I1009 03:17:47.693278 140425799219072 learning.py:507] global step 341: loss = 2.7260 (4.864 sec/step)\n",
            "INFO:tensorflow:global step 342: loss = 2.5660 (4.912 sec/step)\n",
            "I1009 03:17:52.607329 140425799219072 learning.py:507] global step 342: loss = 2.5660 (4.912 sec/step)\n",
            "INFO:tensorflow:global step 343: loss = 2.8039 (4.789 sec/step)\n",
            "I1009 03:17:57.397917 140425799219072 learning.py:507] global step 343: loss = 2.8039 (4.789 sec/step)\n",
            "INFO:tensorflow:global step 344: loss = 2.5337 (4.852 sec/step)\n",
            "I1009 03:18:02.251835 140425799219072 learning.py:507] global step 344: loss = 2.5337 (4.852 sec/step)\n",
            "INFO:tensorflow:global step 345: loss = 2.6931 (4.822 sec/step)\n",
            "I1009 03:18:07.075968 140425799219072 learning.py:507] global step 345: loss = 2.6931 (4.822 sec/step)\n",
            "INFO:tensorflow:global step 346: loss = 2.3504 (4.703 sec/step)\n",
            "I1009 03:18:11.780853 140425799219072 learning.py:507] global step 346: loss = 2.3504 (4.703 sec/step)\n",
            "INFO:tensorflow:global step 347: loss = 2.6495 (4.666 sec/step)\n",
            "I1009 03:18:16.448586 140425799219072 learning.py:507] global step 347: loss = 2.6495 (4.666 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:18:17.244154 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:Recording summary at step 348.\n",
            "I1009 03:18:27.199992 140422698682112 supervisor.py:1050] Recording summary at step 348.\n",
            "INFO:tensorflow:global step 348: loss = 2.0534 (10.750 sec/step)\n",
            "I1009 03:18:27.206176 140425799219072 learning.py:507] global step 348: loss = 2.0534 (10.750 sec/step)\n",
            "INFO:tensorflow:global step 349: loss = 2.1816 (5.385 sec/step)\n",
            "I1009 03:18:32.603600 140425799219072 learning.py:507] global step 349: loss = 2.1816 (5.385 sec/step)\n",
            "INFO:tensorflow:global step 350: loss = 2.3041 (4.795 sec/step)\n",
            "I1009 03:18:37.400638 140425799219072 learning.py:507] global step 350: loss = 2.3041 (4.795 sec/step)\n",
            "INFO:tensorflow:global step 351: loss = 2.6801 (4.781 sec/step)\n",
            "I1009 03:18:42.183925 140425799219072 learning.py:507] global step 351: loss = 2.6801 (4.781 sec/step)\n",
            "INFO:tensorflow:global step 352: loss = 2.2277 (4.613 sec/step)\n",
            "I1009 03:18:46.799328 140425799219072 learning.py:507] global step 352: loss = 2.2277 (4.613 sec/step)\n",
            "INFO:tensorflow:global step 353: loss = 3.3109 (4.640 sec/step)\n",
            "I1009 03:18:51.441396 140425799219072 learning.py:507] global step 353: loss = 3.3109 (4.640 sec/step)\n",
            "INFO:tensorflow:global step 354: loss = 2.2866 (4.582 sec/step)\n",
            "I1009 03:18:56.025863 140425799219072 learning.py:507] global step 354: loss = 2.2866 (4.582 sec/step)\n",
            "INFO:tensorflow:global step 355: loss = 2.4527 (4.625 sec/step)\n",
            "I1009 03:19:00.652651 140425799219072 learning.py:507] global step 355: loss = 2.4527 (4.625 sec/step)\n",
            "INFO:tensorflow:global step 356: loss = 2.4848 (4.910 sec/step)\n",
            "I1009 03:19:05.564309 140425799219072 learning.py:507] global step 356: loss = 2.4848 (4.910 sec/step)\n",
            "INFO:tensorflow:global step 357: loss = 1.8998 (4.576 sec/step)\n",
            "I1009 03:19:10.142436 140425799219072 learning.py:507] global step 357: loss = 1.8998 (4.576 sec/step)\n",
            "INFO:tensorflow:global step 358: loss = 2.8901 (4.713 sec/step)\n",
            "I1009 03:19:14.857773 140425799219072 learning.py:507] global step 358: loss = 2.8901 (4.713 sec/step)\n",
            "INFO:tensorflow:global step 359: loss = 2.3863 (4.686 sec/step)\n",
            "I1009 03:19:19.545932 140425799219072 learning.py:507] global step 359: loss = 2.3863 (4.686 sec/step)\n",
            "INFO:tensorflow:global step 360: loss = 2.6443 (4.622 sec/step)\n",
            "I1009 03:19:24.170123 140425799219072 learning.py:507] global step 360: loss = 2.6443 (4.622 sec/step)\n",
            "INFO:tensorflow:global step 361: loss = 2.5452 (4.655 sec/step)\n",
            "I1009 03:19:28.827602 140425799219072 learning.py:507] global step 361: loss = 2.5452 (4.655 sec/step)\n",
            "INFO:tensorflow:global step 362: loss = 2.4607 (4.563 sec/step)\n",
            "I1009 03:19:33.392659 140425799219072 learning.py:507] global step 362: loss = 2.4607 (4.563 sec/step)\n",
            "INFO:tensorflow:global step 363: loss = 2.0794 (4.704 sec/step)\n",
            "I1009 03:19:38.098021 140425799219072 learning.py:507] global step 363: loss = 2.0794 (4.704 sec/step)\n",
            "INFO:tensorflow:global step 364: loss = 2.2813 (4.837 sec/step)\n",
            "I1009 03:19:42.937658 140425799219072 learning.py:507] global step 364: loss = 2.2813 (4.837 sec/step)\n",
            "INFO:tensorflow:global step 365: loss = 2.3596 (4.932 sec/step)\n",
            "I1009 03:19:47.872234 140425799219072 learning.py:507] global step 365: loss = 2.3596 (4.932 sec/step)\n",
            "INFO:tensorflow:global step 366: loss = 2.8460 (4.799 sec/step)\n",
            "I1009 03:19:52.673336 140425799219072 learning.py:507] global step 366: loss = 2.8460 (4.799 sec/step)\n",
            "INFO:tensorflow:global step 367: loss = 2.6094 (4.905 sec/step)\n",
            "I1009 03:19:57.580159 140425799219072 learning.py:507] global step 367: loss = 2.6094 (4.905 sec/step)\n",
            "INFO:tensorflow:global step 368: loss = 2.9321 (4.882 sec/step)\n",
            "I1009 03:20:02.463931 140425799219072 learning.py:507] global step 368: loss = 2.9321 (4.882 sec/step)\n",
            "INFO:tensorflow:global step 369: loss = 2.3741 (4.870 sec/step)\n",
            "I1009 03:20:07.335385 140425799219072 learning.py:507] global step 369: loss = 2.3741 (4.870 sec/step)\n",
            "INFO:tensorflow:global step 370: loss = 2.6883 (4.940 sec/step)\n",
            "I1009 03:20:12.277114 140425799219072 learning.py:507] global step 370: loss = 2.6883 (4.940 sec/step)\n",
            "INFO:tensorflow:global step 371: loss = 2.7401 (4.764 sec/step)\n",
            "I1009 03:20:17.042988 140425799219072 learning.py:507] global step 371: loss = 2.7401 (4.764 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 371.\n",
            "I1009 03:20:24.180677 140422698682112 supervisor.py:1050] Recording summary at step 371.\n",
            "INFO:tensorflow:global step 372: loss = 2.2077 (8.102 sec/step)\n",
            "I1009 03:20:25.146863 140425799219072 learning.py:507] global step 372: loss = 2.2077 (8.102 sec/step)\n",
            "INFO:tensorflow:global step 373: loss = 2.7279 (4.886 sec/step)\n",
            "I1009 03:20:30.035220 140425799219072 learning.py:507] global step 373: loss = 2.7279 (4.886 sec/step)\n",
            "INFO:tensorflow:global step 374: loss = 2.2666 (5.028 sec/step)\n",
            "I1009 03:20:35.065514 140425799219072 learning.py:507] global step 374: loss = 2.2666 (5.028 sec/step)\n",
            "INFO:tensorflow:global step 375: loss = 2.3421 (4.896 sec/step)\n",
            "I1009 03:20:39.963529 140425799219072 learning.py:507] global step 375: loss = 2.3421 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 376: loss = 2.3568 (4.749 sec/step)\n",
            "I1009 03:20:44.714668 140425799219072 learning.py:507] global step 376: loss = 2.3568 (4.749 sec/step)\n",
            "INFO:tensorflow:global step 377: loss = 1.9588 (4.813 sec/step)\n",
            "I1009 03:20:49.530179 140425799219072 learning.py:507] global step 377: loss = 1.9588 (4.813 sec/step)\n",
            "INFO:tensorflow:global step 378: loss = 3.1398 (5.309 sec/step)\n",
            "I1009 03:20:54.841559 140425799219072 learning.py:507] global step 378: loss = 3.1398 (5.309 sec/step)\n",
            "INFO:tensorflow:global step 379: loss = 2.6847 (4.869 sec/step)\n",
            "I1009 03:20:59.712333 140425799219072 learning.py:507] global step 379: loss = 2.6847 (4.869 sec/step)\n",
            "INFO:tensorflow:global step 380: loss = 3.0288 (4.910 sec/step)\n",
            "I1009 03:21:04.624828 140425799219072 learning.py:507] global step 380: loss = 3.0288 (4.910 sec/step)\n",
            "INFO:tensorflow:global step 381: loss = 2.2183 (4.894 sec/step)\n",
            "I1009 03:21:09.520299 140425799219072 learning.py:507] global step 381: loss = 2.2183 (4.894 sec/step)\n",
            "INFO:tensorflow:global step 382: loss = 2.3846 (4.706 sec/step)\n",
            "I1009 03:21:14.228358 140425799219072 learning.py:507] global step 382: loss = 2.3846 (4.706 sec/step)\n",
            "INFO:tensorflow:global step 383: loss = 2.0705 (5.337 sec/step)\n",
            "I1009 03:21:19.567502 140425799219072 learning.py:507] global step 383: loss = 2.0705 (5.337 sec/step)\n",
            "INFO:tensorflow:global step 384: loss = 2.1800 (5.288 sec/step)\n",
            "I1009 03:21:24.857096 140425799219072 learning.py:507] global step 384: loss = 2.1800 (5.288 sec/step)\n",
            "INFO:tensorflow:global step 385: loss = 3.2109 (4.993 sec/step)\n",
            "I1009 03:21:29.851877 140425799219072 learning.py:507] global step 385: loss = 3.2109 (4.993 sec/step)\n",
            "INFO:tensorflow:global step 386: loss = 2.5992 (4.870 sec/step)\n",
            "I1009 03:21:34.724193 140425799219072 learning.py:507] global step 386: loss = 2.5992 (4.870 sec/step)\n",
            "INFO:tensorflow:global step 387: loss = 3.0466 (4.805 sec/step)\n",
            "I1009 03:21:39.531211 140425799219072 learning.py:507] global step 387: loss = 3.0466 (4.805 sec/step)\n",
            "INFO:tensorflow:global step 388: loss = 2.5036 (4.890 sec/step)\n",
            "I1009 03:21:44.423240 140425799219072 learning.py:507] global step 388: loss = 2.5036 (4.890 sec/step)\n",
            "INFO:tensorflow:global step 389: loss = 2.5232 (5.215 sec/step)\n",
            "I1009 03:21:49.640478 140425799219072 learning.py:507] global step 389: loss = 2.5232 (5.215 sec/step)\n",
            "INFO:tensorflow:global step 390: loss = 2.3039 (4.890 sec/step)\n",
            "I1009 03:21:54.532397 140425799219072 learning.py:507] global step 390: loss = 2.3039 (4.890 sec/step)\n",
            "INFO:tensorflow:global step 391: loss = 2.1616 (4.835 sec/step)\n",
            "I1009 03:21:59.369049 140425799219072 learning.py:507] global step 391: loss = 2.1616 (4.835 sec/step)\n",
            "INFO:tensorflow:global step 392: loss = 2.6597 (4.837 sec/step)\n",
            "I1009 03:22:04.207375 140425799219072 learning.py:507] global step 392: loss = 2.6597 (4.837 sec/step)\n",
            "INFO:tensorflow:global step 393: loss = 2.5608 (4.757 sec/step)\n",
            "I1009 03:22:08.966664 140425799219072 learning.py:507] global step 393: loss = 2.5608 (4.757 sec/step)\n",
            "INFO:tensorflow:global step 394: loss = 2.4103 (4.793 sec/step)\n",
            "I1009 03:22:13.762119 140425799219072 learning.py:507] global step 394: loss = 2.4103 (4.793 sec/step)\n",
            "INFO:tensorflow:global step 395: loss = 2.0740 (6.325 sec/step)\n",
            "I1009 03:22:20.108464 140425799219072 learning.py:507] global step 395: loss = 2.0740 (6.325 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 395.\n",
            "I1009 03:22:25.211495 140422698682112 supervisor.py:1050] Recording summary at step 395.\n",
            "INFO:tensorflow:global step 396: loss = 2.0109 (6.499 sec/step)\n",
            "I1009 03:22:26.629426 140425799219072 learning.py:507] global step 396: loss = 2.0109 (6.499 sec/step)\n",
            "INFO:tensorflow:global step 397: loss = 2.0613 (4.830 sec/step)\n",
            "I1009 03:22:31.461166 140425799219072 learning.py:507] global step 397: loss = 2.0613 (4.830 sec/step)\n",
            "INFO:tensorflow:global step 398: loss = 2.5507 (4.811 sec/step)\n",
            "I1009 03:22:36.273429 140425799219072 learning.py:507] global step 398: loss = 2.5507 (4.811 sec/step)\n",
            "INFO:tensorflow:global step 399: loss = 2.2391 (4.811 sec/step)\n",
            "I1009 03:22:41.086826 140425799219072 learning.py:507] global step 399: loss = 2.2391 (4.811 sec/step)\n",
            "INFO:tensorflow:global step 400: loss = 1.9601 (4.756 sec/step)\n",
            "I1009 03:22:45.844665 140425799219072 learning.py:507] global step 400: loss = 1.9601 (4.756 sec/step)\n",
            "INFO:tensorflow:global step 401: loss = 1.9878 (4.815 sec/step)\n",
            "I1009 03:22:50.661748 140425799219072 learning.py:507] global step 401: loss = 1.9878 (4.815 sec/step)\n",
            "INFO:tensorflow:global step 402: loss = 2.4935 (5.024 sec/step)\n",
            "I1009 03:22:55.688261 140425799219072 learning.py:507] global step 402: loss = 2.4935 (5.024 sec/step)\n",
            "INFO:tensorflow:global step 403: loss = 2.4160 (4.830 sec/step)\n",
            "I1009 03:23:00.520138 140425799219072 learning.py:507] global step 403: loss = 2.4160 (4.830 sec/step)\n",
            "INFO:tensorflow:global step 404: loss = 2.7400 (4.804 sec/step)\n",
            "I1009 03:23:05.326380 140425799219072 learning.py:507] global step 404: loss = 2.7400 (4.804 sec/step)\n",
            "INFO:tensorflow:global step 405: loss = 2.2695 (4.816 sec/step)\n",
            "I1009 03:23:10.144146 140425799219072 learning.py:507] global step 405: loss = 2.2695 (4.816 sec/step)\n",
            "INFO:tensorflow:global step 406: loss = 2.5685 (4.823 sec/step)\n",
            "I1009 03:23:14.968828 140425799219072 learning.py:507] global step 406: loss = 2.5685 (4.823 sec/step)\n",
            "INFO:tensorflow:global step 407: loss = 1.7107 (4.929 sec/step)\n",
            "I1009 03:23:19.900076 140425799219072 learning.py:507] global step 407: loss = 1.7107 (4.929 sec/step)\n",
            "INFO:tensorflow:global step 408: loss = 2.3701 (4.755 sec/step)\n",
            "I1009 03:23:24.657063 140425799219072 learning.py:507] global step 408: loss = 2.3701 (4.755 sec/step)\n",
            "INFO:tensorflow:global step 409: loss = 2.1181 (5.000 sec/step)\n",
            "I1009 03:23:29.658565 140425799219072 learning.py:507] global step 409: loss = 2.1181 (5.000 sec/step)\n",
            "INFO:tensorflow:global step 410: loss = 2.9936 (4.859 sec/step)\n",
            "I1009 03:23:34.519339 140425799219072 learning.py:507] global step 410: loss = 2.9936 (4.859 sec/step)\n",
            "INFO:tensorflow:global step 411: loss = 2.5696 (4.934 sec/step)\n",
            "I1009 03:23:39.455545 140425799219072 learning.py:507] global step 411: loss = 2.5696 (4.934 sec/step)\n",
            "INFO:tensorflow:global step 412: loss = 2.2076 (5.163 sec/step)\n",
            "I1009 03:23:44.620536 140425799219072 learning.py:507] global step 412: loss = 2.2076 (5.163 sec/step)\n",
            "INFO:tensorflow:global step 413: loss = 2.3881 (4.862 sec/step)\n",
            "I1009 03:23:49.483983 140425799219072 learning.py:507] global step 413: loss = 2.3881 (4.862 sec/step)\n",
            "INFO:tensorflow:global step 414: loss = 1.9129 (4.810 sec/step)\n",
            "I1009 03:23:54.295942 140425799219072 learning.py:507] global step 414: loss = 1.9129 (4.810 sec/step)\n",
            "INFO:tensorflow:global step 415: loss = 2.3435 (4.862 sec/step)\n",
            "I1009 03:23:59.159476 140425799219072 learning.py:507] global step 415: loss = 2.3435 (4.862 sec/step)\n",
            "INFO:tensorflow:global step 416: loss = 2.3554 (5.349 sec/step)\n",
            "I1009 03:24:04.510183 140425799219072 learning.py:507] global step 416: loss = 2.3554 (5.349 sec/step)\n",
            "INFO:tensorflow:global step 417: loss = 2.4620 (4.817 sec/step)\n",
            "I1009 03:24:09.329430 140425799219072 learning.py:507] global step 417: loss = 2.4620 (4.817 sec/step)\n",
            "INFO:tensorflow:global step 418: loss = 2.1016 (4.883 sec/step)\n",
            "I1009 03:24:14.214477 140425799219072 learning.py:507] global step 418: loss = 2.1016 (4.883 sec/step)\n",
            "INFO:tensorflow:global step 419: loss = 2.1560 (7.085 sec/step)\n",
            "I1009 03:24:21.313548 140425799219072 learning.py:507] global step 419: loss = 2.1560 (7.085 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 419.\n",
            "I1009 03:24:25.424355 140422698682112 supervisor.py:1050] Recording summary at step 419.\n",
            "INFO:tensorflow:global step 420: loss = 2.2039 (5.897 sec/step)\n",
            "I1009 03:24:27.212699 140425799219072 learning.py:507] global step 420: loss = 2.2039 (5.897 sec/step)\n",
            "INFO:tensorflow:global step 421: loss = 1.9440 (4.877 sec/step)\n",
            "I1009 03:24:32.092219 140425799219072 learning.py:507] global step 421: loss = 1.9440 (4.877 sec/step)\n",
            "INFO:tensorflow:global step 422: loss = 3.3027 (4.684 sec/step)\n",
            "I1009 03:24:36.778334 140425799219072 learning.py:507] global step 422: loss = 3.3027 (4.684 sec/step)\n",
            "INFO:tensorflow:global step 423: loss = 2.8760 (4.718 sec/step)\n",
            "I1009 03:24:41.497694 140425799219072 learning.py:507] global step 423: loss = 2.8760 (4.718 sec/step)\n",
            "INFO:tensorflow:global step 424: loss = 2.0162 (4.673 sec/step)\n",
            "I1009 03:24:46.172836 140425799219072 learning.py:507] global step 424: loss = 2.0162 (4.673 sec/step)\n",
            "INFO:tensorflow:global step 425: loss = 2.2772 (4.799 sec/step)\n",
            "I1009 03:24:50.973539 140425799219072 learning.py:507] global step 425: loss = 2.2772 (4.799 sec/step)\n",
            "INFO:tensorflow:global step 426: loss = 2.4572 (4.809 sec/step)\n",
            "I1009 03:24:55.784366 140425799219072 learning.py:507] global step 426: loss = 2.4572 (4.809 sec/step)\n",
            "INFO:tensorflow:global step 427: loss = 2.3682 (4.870 sec/step)\n",
            "I1009 03:25:00.656495 140425799219072 learning.py:507] global step 427: loss = 2.3682 (4.870 sec/step)\n",
            "INFO:tensorflow:global step 428: loss = 1.9844 (4.884 sec/step)\n",
            "I1009 03:25:05.542645 140425799219072 learning.py:507] global step 428: loss = 1.9844 (4.884 sec/step)\n",
            "INFO:tensorflow:global step 429: loss = 2.5725 (4.677 sec/step)\n",
            "I1009 03:25:10.221831 140425799219072 learning.py:507] global step 429: loss = 2.5725 (4.677 sec/step)\n",
            "INFO:tensorflow:global step 430: loss = 2.5552 (4.840 sec/step)\n",
            "I1009 03:25:15.064107 140425799219072 learning.py:507] global step 430: loss = 2.5552 (4.840 sec/step)\n",
            "INFO:tensorflow:global step 431: loss = 2.4871 (4.623 sec/step)\n",
            "I1009 03:25:19.689284 140425799219072 learning.py:507] global step 431: loss = 2.4871 (4.623 sec/step)\n",
            "INFO:tensorflow:global step 432: loss = 2.5723 (4.610 sec/step)\n",
            "I1009 03:25:24.301722 140425799219072 learning.py:507] global step 432: loss = 2.5723 (4.610 sec/step)\n",
            "INFO:tensorflow:global step 433: loss = 2.1400 (4.985 sec/step)\n",
            "I1009 03:25:29.288415 140425799219072 learning.py:507] global step 433: loss = 2.1400 (4.985 sec/step)\n",
            "INFO:tensorflow:global step 434: loss = 2.0192 (4.729 sec/step)\n",
            "I1009 03:25:34.018979 140425799219072 learning.py:507] global step 434: loss = 2.0192 (4.729 sec/step)\n",
            "INFO:tensorflow:global step 435: loss = 1.9775 (4.537 sec/step)\n",
            "I1009 03:25:38.558440 140425799219072 learning.py:507] global step 435: loss = 1.9775 (4.537 sec/step)\n",
            "INFO:tensorflow:global step 436: loss = 2.3213 (4.654 sec/step)\n",
            "I1009 03:25:43.214634 140425799219072 learning.py:507] global step 436: loss = 2.3213 (4.654 sec/step)\n",
            "INFO:tensorflow:global step 437: loss = 2.2199 (4.708 sec/step)\n",
            "I1009 03:25:47.924295 140425799219072 learning.py:507] global step 437: loss = 2.2199 (4.708 sec/step)\n",
            "INFO:tensorflow:global step 438: loss = 2.0437 (4.785 sec/step)\n",
            "I1009 03:25:52.711213 140425799219072 learning.py:507] global step 438: loss = 2.0437 (4.785 sec/step)\n",
            "INFO:tensorflow:global step 439: loss = 1.9386 (4.924 sec/step)\n",
            "I1009 03:25:57.636941 140425799219072 learning.py:507] global step 439: loss = 1.9386 (4.924 sec/step)\n",
            "INFO:tensorflow:global step 440: loss = 1.4470 (4.714 sec/step)\n",
            "I1009 03:26:02.352830 140425799219072 learning.py:507] global step 440: loss = 1.4470 (4.714 sec/step)\n",
            "INFO:tensorflow:global step 441: loss = 2.6256 (4.613 sec/step)\n",
            "I1009 03:26:06.968322 140425799219072 learning.py:507] global step 441: loss = 2.6256 (4.613 sec/step)\n",
            "INFO:tensorflow:global step 442: loss = 2.3514 (5.080 sec/step)\n",
            "I1009 03:26:12.049830 140425799219072 learning.py:507] global step 442: loss = 2.3514 (5.080 sec/step)\n",
            "INFO:tensorflow:global step 443: loss = 2.2658 (4.815 sec/step)\n",
            "I1009 03:26:16.866580 140425799219072 learning.py:507] global step 443: loss = 2.2658 (4.815 sec/step)\n",
            "INFO:tensorflow:global step 444: loss = 2.3372 (8.659 sec/step)\n",
            "I1009 03:26:25.527806 140425799219072 learning.py:507] global step 444: loss = 2.3372 (8.659 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 444.\n",
            "I1009 03:26:26.423607 140422698682112 supervisor.py:1050] Recording summary at step 444.\n",
            "INFO:tensorflow:global step 445: loss = 2.4970 (5.196 sec/step)\n",
            "I1009 03:26:30.727307 140425799219072 learning.py:507] global step 445: loss = 2.4970 (5.196 sec/step)\n",
            "INFO:tensorflow:global step 446: loss = 2.4335 (4.744 sec/step)\n",
            "I1009 03:26:35.473083 140425799219072 learning.py:507] global step 446: loss = 2.4335 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 447: loss = 2.0498 (5.115 sec/step)\n",
            "I1009 03:26:40.590289 140425799219072 learning.py:507] global step 447: loss = 2.0498 (5.115 sec/step)\n",
            "INFO:tensorflow:global step 448: loss = 2.3938 (4.785 sec/step)\n",
            "I1009 03:26:45.377802 140425799219072 learning.py:507] global step 448: loss = 2.3938 (4.785 sec/step)\n",
            "INFO:tensorflow:global step 449: loss = 2.3845 (4.757 sec/step)\n",
            "I1009 03:26:50.136483 140425799219072 learning.py:507] global step 449: loss = 2.3845 (4.757 sec/step)\n",
            "INFO:tensorflow:global step 450: loss = 2.3903 (4.980 sec/step)\n",
            "I1009 03:26:55.118025 140425799219072 learning.py:507] global step 450: loss = 2.3903 (4.980 sec/step)\n",
            "INFO:tensorflow:global step 451: loss = 2.7615 (4.999 sec/step)\n",
            "I1009 03:27:00.119227 140425799219072 learning.py:507] global step 451: loss = 2.7615 (4.999 sec/step)\n",
            "INFO:tensorflow:global step 452: loss = 2.4035 (4.768 sec/step)\n",
            "I1009 03:27:04.888744 140425799219072 learning.py:507] global step 452: loss = 2.4035 (4.768 sec/step)\n",
            "INFO:tensorflow:global step 453: loss = 1.9723 (4.747 sec/step)\n",
            "I1009 03:27:09.638196 140425799219072 learning.py:507] global step 453: loss = 1.9723 (4.747 sec/step)\n",
            "INFO:tensorflow:global step 454: loss = 2.3165 (4.901 sec/step)\n",
            "I1009 03:27:14.540818 140425799219072 learning.py:507] global step 454: loss = 2.3165 (4.901 sec/step)\n",
            "INFO:tensorflow:global step 455: loss = 2.2780 (5.265 sec/step)\n",
            "I1009 03:27:19.808140 140425799219072 learning.py:507] global step 455: loss = 2.2780 (5.265 sec/step)\n",
            "INFO:tensorflow:global step 456: loss = 2.1811 (4.788 sec/step)\n",
            "I1009 03:27:24.598483 140425799219072 learning.py:507] global step 456: loss = 2.1811 (4.788 sec/step)\n",
            "INFO:tensorflow:global step 457: loss = 2.3834 (4.774 sec/step)\n",
            "I1009 03:27:29.374692 140425799219072 learning.py:507] global step 457: loss = 2.3834 (4.774 sec/step)\n",
            "INFO:tensorflow:global step 458: loss = 2.3077 (4.688 sec/step)\n",
            "I1009 03:27:34.064960 140425799219072 learning.py:507] global step 458: loss = 2.3077 (4.688 sec/step)\n",
            "INFO:tensorflow:global step 459: loss = 2.2450 (4.737 sec/step)\n",
            "I1009 03:27:38.803714 140425799219072 learning.py:507] global step 459: loss = 2.2450 (4.737 sec/step)\n",
            "INFO:tensorflow:global step 460: loss = 2.5052 (4.899 sec/step)\n",
            "I1009 03:27:43.704767 140425799219072 learning.py:507] global step 460: loss = 2.5052 (4.899 sec/step)\n",
            "INFO:tensorflow:global step 461: loss = 2.6008 (5.204 sec/step)\n",
            "I1009 03:27:48.910465 140425799219072 learning.py:507] global step 461: loss = 2.6008 (5.204 sec/step)\n",
            "INFO:tensorflow:global step 462: loss = 2.3240 (4.727 sec/step)\n",
            "I1009 03:27:53.639018 140425799219072 learning.py:507] global step 462: loss = 2.3240 (4.727 sec/step)\n",
            "INFO:tensorflow:global step 463: loss = 2.2695 (4.788 sec/step)\n",
            "I1009 03:27:58.428560 140425799219072 learning.py:507] global step 463: loss = 2.2695 (4.788 sec/step)\n",
            "INFO:tensorflow:global step 464: loss = 2.2275 (4.853 sec/step)\n",
            "I1009 03:28:03.283350 140425799219072 learning.py:507] global step 464: loss = 2.2275 (4.853 sec/step)\n",
            "INFO:tensorflow:global step 465: loss = 2.1866 (4.842 sec/step)\n",
            "I1009 03:28:08.127569 140425799219072 learning.py:507] global step 465: loss = 2.1866 (4.842 sec/step)\n",
            "INFO:tensorflow:global step 466: loss = 2.4666 (4.700 sec/step)\n",
            "I1009 03:28:12.829973 140425799219072 learning.py:507] global step 466: loss = 2.4666 (4.700 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:28:17.246524 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 467: loss = 1.9202 (4.914 sec/step)\n",
            "I1009 03:28:18.394179 140425799219072 learning.py:507] global step 467: loss = 1.9202 (4.914 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 468.\n",
            "I1009 03:28:27.346843 140422698682112 supervisor.py:1050] Recording summary at step 468.\n",
            "INFO:tensorflow:global step 468: loss = 2.8036 (8.708 sec/step)\n",
            "I1009 03:28:27.365282 140425799219072 learning.py:507] global step 468: loss = 2.8036 (8.708 sec/step)\n",
            "INFO:tensorflow:global step 469: loss = 2.1298 (5.247 sec/step)\n",
            "I1009 03:28:32.615294 140425799219072 learning.py:507] global step 469: loss = 2.1298 (5.247 sec/step)\n",
            "INFO:tensorflow:global step 470: loss = 1.9698 (4.642 sec/step)\n",
            "I1009 03:28:37.259445 140425799219072 learning.py:507] global step 470: loss = 1.9698 (4.642 sec/step)\n",
            "INFO:tensorflow:global step 471: loss = 2.0299 (4.595 sec/step)\n",
            "I1009 03:28:41.856991 140425799219072 learning.py:507] global step 471: loss = 2.0299 (4.595 sec/step)\n",
            "INFO:tensorflow:global step 472: loss = 1.9197 (4.823 sec/step)\n",
            "I1009 03:28:46.681527 140425799219072 learning.py:507] global step 472: loss = 1.9197 (4.823 sec/step)\n",
            "INFO:tensorflow:global step 473: loss = 2.0811 (4.985 sec/step)\n",
            "I1009 03:28:51.668669 140425799219072 learning.py:507] global step 473: loss = 2.0811 (4.985 sec/step)\n",
            "INFO:tensorflow:global step 474: loss = 1.7925 (4.774 sec/step)\n",
            "I1009 03:28:56.444785 140425799219072 learning.py:507] global step 474: loss = 1.7925 (4.774 sec/step)\n",
            "INFO:tensorflow:global step 475: loss = 2.0154 (4.940 sec/step)\n",
            "I1009 03:29:01.386229 140425799219072 learning.py:507] global step 475: loss = 2.0154 (4.940 sec/step)\n",
            "INFO:tensorflow:global step 476: loss = 2.6482 (4.947 sec/step)\n",
            "I1009 03:29:06.334742 140425799219072 learning.py:507] global step 476: loss = 2.6482 (4.947 sec/step)\n",
            "INFO:tensorflow:global step 477: loss = 2.0548 (4.831 sec/step)\n",
            "I1009 03:29:11.167532 140425799219072 learning.py:507] global step 477: loss = 2.0548 (4.831 sec/step)\n",
            "INFO:tensorflow:global step 478: loss = 2.5511 (4.710 sec/step)\n",
            "I1009 03:29:15.878963 140425799219072 learning.py:507] global step 478: loss = 2.5511 (4.710 sec/step)\n",
            "INFO:tensorflow:global step 479: loss = 2.6187 (4.994 sec/step)\n",
            "I1009 03:29:20.874465 140425799219072 learning.py:507] global step 479: loss = 2.6187 (4.994 sec/step)\n",
            "INFO:tensorflow:global step 480: loss = 2.3336 (4.633 sec/step)\n",
            "I1009 03:29:25.509404 140425799219072 learning.py:507] global step 480: loss = 2.3336 (4.633 sec/step)\n",
            "INFO:tensorflow:global step 481: loss = 1.8753 (4.654 sec/step)\n",
            "I1009 03:29:30.165559 140425799219072 learning.py:507] global step 481: loss = 1.8753 (4.654 sec/step)\n",
            "INFO:tensorflow:global step 482: loss = 2.1902 (4.691 sec/step)\n",
            "I1009 03:29:34.858219 140425799219072 learning.py:507] global step 482: loss = 2.1902 (4.691 sec/step)\n",
            "INFO:tensorflow:global step 483: loss = 2.4145 (4.676 sec/step)\n",
            "I1009 03:29:39.536531 140425799219072 learning.py:507] global step 483: loss = 2.4145 (4.676 sec/step)\n",
            "INFO:tensorflow:global step 484: loss = 2.2341 (4.676 sec/step)\n",
            "I1009 03:29:44.214427 140425799219072 learning.py:507] global step 484: loss = 2.2341 (4.676 sec/step)\n",
            "INFO:tensorflow:global step 485: loss = 1.9958 (4.943 sec/step)\n",
            "I1009 03:29:49.159492 140425799219072 learning.py:507] global step 485: loss = 1.9958 (4.943 sec/step)\n",
            "INFO:tensorflow:global step 486: loss = 1.9988 (4.808 sec/step)\n",
            "I1009 03:29:53.968837 140425799219072 learning.py:507] global step 486: loss = 1.9988 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 487: loss = 1.9196 (4.795 sec/step)\n",
            "I1009 03:29:58.766923 140425799219072 learning.py:507] global step 487: loss = 1.9196 (4.795 sec/step)\n",
            "INFO:tensorflow:global step 488: loss = 2.2709 (4.860 sec/step)\n",
            "I1009 03:30:03.630731 140425799219072 learning.py:507] global step 488: loss = 2.2709 (4.860 sec/step)\n",
            "INFO:tensorflow:global step 489: loss = 2.5419 (4.740 sec/step)\n",
            "I1009 03:30:08.373010 140425799219072 learning.py:507] global step 489: loss = 2.5419 (4.740 sec/step)\n",
            "INFO:tensorflow:global step 490: loss = 1.8659 (4.751 sec/step)\n",
            "I1009 03:30:13.126445 140425799219072 learning.py:507] global step 490: loss = 1.8659 (4.751 sec/step)\n",
            "INFO:tensorflow:global step 491: loss = 1.8412 (4.844 sec/step)\n",
            "I1009 03:30:18.045011 140425799219072 learning.py:507] global step 491: loss = 1.8412 (4.844 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 491.\n",
            "I1009 03:30:24.596236 140422698682112 supervisor.py:1050] Recording summary at step 491.\n",
            "INFO:tensorflow:global step 492: loss = 1.8702 (7.402 sec/step)\n",
            "I1009 03:30:25.464636 140425799219072 learning.py:507] global step 492: loss = 1.8702 (7.402 sec/step)\n",
            "INFO:tensorflow:global step 493: loss = 2.3264 (4.854 sec/step)\n",
            "I1009 03:30:30.320284 140425799219072 learning.py:507] global step 493: loss = 2.3264 (4.854 sec/step)\n",
            "INFO:tensorflow:global step 494: loss = 2.3246 (4.843 sec/step)\n",
            "I1009 03:30:35.165119 140425799219072 learning.py:507] global step 494: loss = 2.3246 (4.843 sec/step)\n",
            "INFO:tensorflow:global step 495: loss = 2.1353 (4.582 sec/step)\n",
            "I1009 03:30:39.749877 140425799219072 learning.py:507] global step 495: loss = 2.1353 (4.582 sec/step)\n",
            "INFO:tensorflow:global step 496: loss = 2.9810 (4.797 sec/step)\n",
            "I1009 03:30:44.548443 140425799219072 learning.py:507] global step 496: loss = 2.9810 (4.797 sec/step)\n",
            "INFO:tensorflow:global step 497: loss = 1.7067 (4.650 sec/step)\n",
            "I1009 03:30:49.200275 140425799219072 learning.py:507] global step 497: loss = 1.7067 (4.650 sec/step)\n",
            "INFO:tensorflow:global step 498: loss = 2.0149 (4.743 sec/step)\n",
            "I1009 03:30:53.945172 140425799219072 learning.py:507] global step 498: loss = 2.0149 (4.743 sec/step)\n",
            "INFO:tensorflow:global step 499: loss = 1.9715 (5.051 sec/step)\n",
            "I1009 03:30:58.998139 140425799219072 learning.py:507] global step 499: loss = 1.9715 (5.051 sec/step)\n",
            "INFO:tensorflow:global step 500: loss = 1.8482 (4.827 sec/step)\n",
            "I1009 03:31:03.826804 140425799219072 learning.py:507] global step 500: loss = 1.8482 (4.827 sec/step)\n",
            "INFO:tensorflow:global step 501: loss = 2.4827 (4.762 sec/step)\n",
            "I1009 03:31:08.590558 140425799219072 learning.py:507] global step 501: loss = 2.4827 (4.762 sec/step)\n",
            "INFO:tensorflow:global step 502: loss = 2.6782 (4.737 sec/step)\n",
            "I1009 03:31:13.329580 140425799219072 learning.py:507] global step 502: loss = 2.6782 (4.737 sec/step)\n",
            "INFO:tensorflow:global step 503: loss = 1.6887 (4.653 sec/step)\n",
            "I1009 03:31:17.984766 140425799219072 learning.py:507] global step 503: loss = 1.6887 (4.653 sec/step)\n",
            "INFO:tensorflow:global step 504: loss = 2.2796 (4.736 sec/step)\n",
            "I1009 03:31:22.722759 140425799219072 learning.py:507] global step 504: loss = 2.2796 (4.736 sec/step)\n",
            "INFO:tensorflow:global step 505: loss = 2.5062 (4.668 sec/step)\n",
            "I1009 03:31:27.392643 140425799219072 learning.py:507] global step 505: loss = 2.5062 (4.668 sec/step)\n",
            "INFO:tensorflow:global step 506: loss = 2.5151 (4.778 sec/step)\n",
            "I1009 03:31:32.172350 140425799219072 learning.py:507] global step 506: loss = 2.5151 (4.778 sec/step)\n",
            "INFO:tensorflow:global step 507: loss = 2.4446 (4.719 sec/step)\n",
            "I1009 03:31:36.893873 140425799219072 learning.py:507] global step 507: loss = 2.4446 (4.719 sec/step)\n",
            "INFO:tensorflow:global step 508: loss = 2.7485 (4.809 sec/step)\n",
            "I1009 03:31:41.705158 140425799219072 learning.py:507] global step 508: loss = 2.7485 (4.809 sec/step)\n",
            "INFO:tensorflow:global step 509: loss = 2.4237 (4.773 sec/step)\n",
            "I1009 03:31:46.480437 140425799219072 learning.py:507] global step 509: loss = 2.4237 (4.773 sec/step)\n",
            "INFO:tensorflow:global step 510: loss = 1.9686 (4.875 sec/step)\n",
            "I1009 03:31:51.357878 140425799219072 learning.py:507] global step 510: loss = 1.9686 (4.875 sec/step)\n",
            "INFO:tensorflow:global step 511: loss = 1.9434 (4.868 sec/step)\n",
            "I1009 03:31:56.227743 140425799219072 learning.py:507] global step 511: loss = 1.9434 (4.868 sec/step)\n",
            "INFO:tensorflow:global step 512: loss = 2.2986 (4.895 sec/step)\n",
            "I1009 03:32:01.124380 140425799219072 learning.py:507] global step 512: loss = 2.2986 (4.895 sec/step)\n",
            "INFO:tensorflow:global step 513: loss = 2.2300 (4.792 sec/step)\n",
            "I1009 03:32:05.918739 140425799219072 learning.py:507] global step 513: loss = 2.2300 (4.792 sec/step)\n",
            "INFO:tensorflow:global step 514: loss = 2.7754 (4.649 sec/step)\n",
            "I1009 03:32:10.570097 140425799219072 learning.py:507] global step 514: loss = 2.7754 (4.649 sec/step)\n",
            "INFO:tensorflow:global step 515: loss = 2.5676 (4.746 sec/step)\n",
            "I1009 03:32:15.317748 140425799219072 learning.py:507] global step 515: loss = 2.5676 (4.746 sec/step)\n",
            "INFO:tensorflow:global step 516: loss = 2.1667 (8.288 sec/step)\n",
            "I1009 03:32:23.607597 140425799219072 learning.py:507] global step 516: loss = 2.1667 (8.288 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 516.\n",
            "I1009 03:32:24.767387 140422698682112 supervisor.py:1050] Recording summary at step 516.\n",
            "INFO:tensorflow:global step 517: loss = 2.0254 (5.004 sec/step)\n",
            "I1009 03:32:28.613641 140425799219072 learning.py:507] global step 517: loss = 2.0254 (5.004 sec/step)\n",
            "INFO:tensorflow:global step 518: loss = 1.8197 (4.945 sec/step)\n",
            "I1009 03:32:33.560362 140425799219072 learning.py:507] global step 518: loss = 1.8197 (4.945 sec/step)\n",
            "INFO:tensorflow:global step 519: loss = 2.2996 (4.752 sec/step)\n",
            "I1009 03:32:38.314413 140425799219072 learning.py:507] global step 519: loss = 2.2996 (4.752 sec/step)\n",
            "INFO:tensorflow:global step 520: loss = 2.3627 (4.810 sec/step)\n",
            "I1009 03:32:43.125944 140425799219072 learning.py:507] global step 520: loss = 2.3627 (4.810 sec/step)\n",
            "INFO:tensorflow:global step 521: loss = 2.0379 (4.846 sec/step)\n",
            "I1009 03:32:47.973982 140425799219072 learning.py:507] global step 521: loss = 2.0379 (4.846 sec/step)\n",
            "INFO:tensorflow:global step 522: loss = 2.0235 (5.087 sec/step)\n",
            "I1009 03:32:53.063412 140425799219072 learning.py:507] global step 522: loss = 2.0235 (5.087 sec/step)\n",
            "INFO:tensorflow:global step 523: loss = 2.3308 (4.827 sec/step)\n",
            "I1009 03:32:57.894499 140425799219072 learning.py:507] global step 523: loss = 2.3308 (4.827 sec/step)\n",
            "INFO:tensorflow:global step 524: loss = 2.6264 (4.780 sec/step)\n",
            "I1009 03:33:02.678007 140425799219072 learning.py:507] global step 524: loss = 2.6264 (4.780 sec/step)\n",
            "INFO:tensorflow:global step 525: loss = 2.0653 (4.818 sec/step)\n",
            "I1009 03:33:07.497996 140425799219072 learning.py:507] global step 525: loss = 2.0653 (4.818 sec/step)\n",
            "INFO:tensorflow:global step 526: loss = 1.8057 (4.818 sec/step)\n",
            "I1009 03:33:12.317597 140425799219072 learning.py:507] global step 526: loss = 1.8057 (4.818 sec/step)\n",
            "INFO:tensorflow:global step 527: loss = 1.9642 (4.818 sec/step)\n",
            "I1009 03:33:17.137741 140425799219072 learning.py:507] global step 527: loss = 1.9642 (4.818 sec/step)\n",
            "INFO:tensorflow:global step 528: loss = 2.2995 (4.782 sec/step)\n",
            "I1009 03:33:21.921326 140425799219072 learning.py:507] global step 528: loss = 2.2995 (4.782 sec/step)\n",
            "INFO:tensorflow:global step 529: loss = 2.0291 (4.891 sec/step)\n",
            "I1009 03:33:26.813647 140425799219072 learning.py:507] global step 529: loss = 2.0291 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 530: loss = 2.7456 (4.920 sec/step)\n",
            "I1009 03:33:31.735782 140425799219072 learning.py:507] global step 530: loss = 2.7456 (4.920 sec/step)\n",
            "INFO:tensorflow:global step 531: loss = 2.1006 (4.831 sec/step)\n",
            "I1009 03:33:36.569202 140425799219072 learning.py:507] global step 531: loss = 2.1006 (4.831 sec/step)\n",
            "INFO:tensorflow:global step 532: loss = 2.1294 (4.774 sec/step)\n",
            "I1009 03:33:41.345371 140425799219072 learning.py:507] global step 532: loss = 2.1294 (4.774 sec/step)\n",
            "INFO:tensorflow:global step 533: loss = 1.7451 (4.857 sec/step)\n",
            "I1009 03:33:46.204164 140425799219072 learning.py:507] global step 533: loss = 1.7451 (4.857 sec/step)\n",
            "INFO:tensorflow:global step 534: loss = 2.8250 (4.797 sec/step)\n",
            "I1009 03:33:51.002783 140425799219072 learning.py:507] global step 534: loss = 2.8250 (4.797 sec/step)\n",
            "INFO:tensorflow:global step 535: loss = 1.9713 (4.726 sec/step)\n",
            "I1009 03:33:55.730674 140425799219072 learning.py:507] global step 535: loss = 1.9713 (4.726 sec/step)\n",
            "INFO:tensorflow:global step 536: loss = 1.7908 (4.897 sec/step)\n",
            "I1009 03:34:00.629555 140425799219072 learning.py:507] global step 536: loss = 1.7908 (4.897 sec/step)\n",
            "INFO:tensorflow:global step 537: loss = 1.8578 (4.855 sec/step)\n",
            "I1009 03:34:05.486694 140425799219072 learning.py:507] global step 537: loss = 1.8578 (4.855 sec/step)\n",
            "INFO:tensorflow:global step 538: loss = 2.7994 (4.826 sec/step)\n",
            "I1009 03:34:10.314497 140425799219072 learning.py:507] global step 538: loss = 2.7994 (4.826 sec/step)\n",
            "INFO:tensorflow:global step 539: loss = 1.5673 (4.884 sec/step)\n",
            "I1009 03:34:15.200146 140425799219072 learning.py:507] global step 539: loss = 1.5673 (4.884 sec/step)\n",
            "INFO:tensorflow:global step 540: loss = 2.8338 (7.719 sec/step)\n",
            "I1009 03:34:22.922401 140425799219072 learning.py:507] global step 540: loss = 2.8338 (7.719 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 540.\n",
            "I1009 03:34:24.602170 140422698682112 supervisor.py:1050] Recording summary at step 540.\n",
            "INFO:tensorflow:global step 541: loss = 3.0909 (5.050 sec/step)\n",
            "I1009 03:34:27.974469 140425799219072 learning.py:507] global step 541: loss = 3.0909 (5.050 sec/step)\n",
            "INFO:tensorflow:global step 542: loss = 2.1738 (4.841 sec/step)\n",
            "I1009 03:34:32.817005 140425799219072 learning.py:507] global step 542: loss = 2.1738 (4.841 sec/step)\n",
            "INFO:tensorflow:global step 543: loss = 2.4184 (4.804 sec/step)\n",
            "I1009 03:34:37.623429 140425799219072 learning.py:507] global step 543: loss = 2.4184 (4.804 sec/step)\n",
            "INFO:tensorflow:global step 544: loss = 2.5507 (4.905 sec/step)\n",
            "I1009 03:34:42.530668 140425799219072 learning.py:507] global step 544: loss = 2.5507 (4.905 sec/step)\n",
            "INFO:tensorflow:global step 545: loss = 2.6111 (4.883 sec/step)\n",
            "I1009 03:34:47.416132 140425799219072 learning.py:507] global step 545: loss = 2.6111 (4.883 sec/step)\n",
            "INFO:tensorflow:global step 546: loss = 2.8035 (4.889 sec/step)\n",
            "I1009 03:34:52.306876 140425799219072 learning.py:507] global step 546: loss = 2.8035 (4.889 sec/step)\n",
            "INFO:tensorflow:global step 547: loss = 1.5390 (4.906 sec/step)\n",
            "I1009 03:34:57.215404 140425799219072 learning.py:507] global step 547: loss = 1.5390 (4.906 sec/step)\n",
            "INFO:tensorflow:global step 548: loss = 2.0944 (4.782 sec/step)\n",
            "I1009 03:35:01.999518 140425799219072 learning.py:507] global step 548: loss = 2.0944 (4.782 sec/step)\n",
            "INFO:tensorflow:global step 549: loss = 2.0027 (4.754 sec/step)\n",
            "I1009 03:35:06.755285 140425799219072 learning.py:507] global step 549: loss = 2.0027 (4.754 sec/step)\n",
            "INFO:tensorflow:global step 550: loss = 1.8579 (4.765 sec/step)\n",
            "I1009 03:35:11.521691 140425799219072 learning.py:507] global step 550: loss = 1.8579 (4.765 sec/step)\n",
            "INFO:tensorflow:global step 551: loss = 2.0282 (4.909 sec/step)\n",
            "I1009 03:35:16.433129 140425799219072 learning.py:507] global step 551: loss = 2.0282 (4.909 sec/step)\n",
            "INFO:tensorflow:global step 552: loss = 2.3792 (4.786 sec/step)\n",
            "I1009 03:35:21.220962 140425799219072 learning.py:507] global step 552: loss = 2.3792 (4.786 sec/step)\n",
            "INFO:tensorflow:global step 553: loss = 1.5797 (4.807 sec/step)\n",
            "I1009 03:35:26.029378 140425799219072 learning.py:507] global step 553: loss = 1.5797 (4.807 sec/step)\n",
            "INFO:tensorflow:global step 554: loss = 2.3468 (4.794 sec/step)\n",
            "I1009 03:35:30.825794 140425799219072 learning.py:507] global step 554: loss = 2.3468 (4.794 sec/step)\n",
            "INFO:tensorflow:global step 555: loss = 2.0215 (4.771 sec/step)\n",
            "I1009 03:35:35.599137 140425799219072 learning.py:507] global step 555: loss = 2.0215 (4.771 sec/step)\n",
            "INFO:tensorflow:global step 556: loss = 2.6285 (4.931 sec/step)\n",
            "I1009 03:35:40.531869 140425799219072 learning.py:507] global step 556: loss = 2.6285 (4.931 sec/step)\n",
            "INFO:tensorflow:global step 557: loss = 2.3820 (4.811 sec/step)\n",
            "I1009 03:35:45.345136 140425799219072 learning.py:507] global step 557: loss = 2.3820 (4.811 sec/step)\n",
            "INFO:tensorflow:global step 558: loss = 2.3158 (4.815 sec/step)\n",
            "I1009 03:35:50.162250 140425799219072 learning.py:507] global step 558: loss = 2.3158 (4.815 sec/step)\n",
            "INFO:tensorflow:global step 559: loss = 2.1047 (4.930 sec/step)\n",
            "I1009 03:35:55.093824 140425799219072 learning.py:507] global step 559: loss = 2.1047 (4.930 sec/step)\n",
            "INFO:tensorflow:global step 560: loss = 2.0736 (4.826 sec/step)\n",
            "I1009 03:35:59.921820 140425799219072 learning.py:507] global step 560: loss = 2.0736 (4.826 sec/step)\n",
            "INFO:tensorflow:global step 561: loss = 1.8808 (4.759 sec/step)\n",
            "I1009 03:36:04.683276 140425799219072 learning.py:507] global step 561: loss = 1.8808 (4.759 sec/step)\n",
            "INFO:tensorflow:global step 562: loss = 1.8802 (4.824 sec/step)\n",
            "I1009 03:36:09.508994 140425799219072 learning.py:507] global step 562: loss = 1.8802 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 563: loss = 2.5054 (4.698 sec/step)\n",
            "I1009 03:36:14.209073 140425799219072 learning.py:507] global step 563: loss = 2.5054 (4.698 sec/step)\n",
            "INFO:tensorflow:global step 564: loss = 1.9546 (6.736 sec/step)\n",
            "I1009 03:36:20.957375 140425799219072 learning.py:507] global step 564: loss = 1.9546 (6.736 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 564.\n",
            "I1009 03:36:25.258861 140422698682112 supervisor.py:1050] Recording summary at step 564.\n",
            "INFO:tensorflow:global step 565: loss = 1.9249 (5.810 sec/step)\n",
            "I1009 03:36:26.771112 140425799219072 learning.py:507] global step 565: loss = 1.9249 (5.810 sec/step)\n",
            "INFO:tensorflow:global step 566: loss = 2.0048 (4.687 sec/step)\n",
            "I1009 03:36:31.460350 140425799219072 learning.py:507] global step 566: loss = 2.0048 (4.687 sec/step)\n",
            "INFO:tensorflow:global step 567: loss = 1.8398 (5.327 sec/step)\n",
            "I1009 03:36:36.789445 140425799219072 learning.py:507] global step 567: loss = 1.8398 (5.327 sec/step)\n",
            "INFO:tensorflow:global step 568: loss = 1.7283 (4.770 sec/step)\n",
            "I1009 03:36:41.561675 140425799219072 learning.py:507] global step 568: loss = 1.7283 (4.770 sec/step)\n",
            "INFO:tensorflow:global step 569: loss = 1.7903 (4.700 sec/step)\n",
            "I1009 03:36:46.263789 140425799219072 learning.py:507] global step 569: loss = 1.7903 (4.700 sec/step)\n",
            "INFO:tensorflow:global step 570: loss = 2.0837 (4.735 sec/step)\n",
            "I1009 03:36:51.000227 140425799219072 learning.py:507] global step 570: loss = 2.0837 (4.735 sec/step)\n",
            "INFO:tensorflow:global step 571: loss = 2.1073 (4.686 sec/step)\n",
            "I1009 03:36:55.687755 140425799219072 learning.py:507] global step 571: loss = 2.1073 (4.686 sec/step)\n",
            "INFO:tensorflow:global step 572: loss = 2.2624 (4.669 sec/step)\n",
            "I1009 03:37:00.358589 140425799219072 learning.py:507] global step 572: loss = 2.2624 (4.669 sec/step)\n",
            "INFO:tensorflow:global step 573: loss = 2.1300 (5.100 sec/step)\n",
            "I1009 03:37:05.460397 140425799219072 learning.py:507] global step 573: loss = 2.1300 (5.100 sec/step)\n",
            "INFO:tensorflow:global step 574: loss = 1.7723 (4.778 sec/step)\n",
            "I1009 03:37:10.240062 140425799219072 learning.py:507] global step 574: loss = 1.7723 (4.778 sec/step)\n",
            "INFO:tensorflow:global step 575: loss = 1.8745 (4.584 sec/step)\n",
            "I1009 03:37:14.826204 140425799219072 learning.py:507] global step 575: loss = 1.8745 (4.584 sec/step)\n",
            "INFO:tensorflow:global step 576: loss = 2.1957 (4.791 sec/step)\n",
            "I1009 03:37:19.619377 140425799219072 learning.py:507] global step 576: loss = 2.1957 (4.791 sec/step)\n",
            "INFO:tensorflow:global step 577: loss = 2.6894 (4.856 sec/step)\n",
            "I1009 03:37:24.477265 140425799219072 learning.py:507] global step 577: loss = 2.6894 (4.856 sec/step)\n",
            "INFO:tensorflow:global step 578: loss = 1.6355 (4.958 sec/step)\n",
            "I1009 03:37:29.436525 140425799219072 learning.py:507] global step 578: loss = 1.6355 (4.958 sec/step)\n",
            "INFO:tensorflow:global step 579: loss = 2.0906 (4.886 sec/step)\n",
            "I1009 03:37:34.324561 140425799219072 learning.py:507] global step 579: loss = 2.0906 (4.886 sec/step)\n",
            "INFO:tensorflow:global step 580: loss = 1.8010 (4.711 sec/step)\n",
            "I1009 03:37:39.037545 140425799219072 learning.py:507] global step 580: loss = 1.8010 (4.711 sec/step)\n",
            "INFO:tensorflow:global step 581: loss = 1.7039 (4.614 sec/step)\n",
            "I1009 03:37:43.654005 140425799219072 learning.py:507] global step 581: loss = 1.7039 (4.614 sec/step)\n",
            "INFO:tensorflow:global step 582: loss = 2.3001 (4.649 sec/step)\n",
            "I1009 03:37:48.305197 140425799219072 learning.py:507] global step 582: loss = 2.3001 (4.649 sec/step)\n",
            "INFO:tensorflow:global step 583: loss = 1.7557 (4.779 sec/step)\n",
            "I1009 03:37:53.086233 140425799219072 learning.py:507] global step 583: loss = 1.7557 (4.779 sec/step)\n",
            "INFO:tensorflow:global step 584: loss = 2.2327 (5.044 sec/step)\n",
            "I1009 03:37:58.131942 140425799219072 learning.py:507] global step 584: loss = 2.2327 (5.044 sec/step)\n",
            "INFO:tensorflow:global step 585: loss = 1.8776 (4.824 sec/step)\n",
            "I1009 03:38:02.958189 140425799219072 learning.py:507] global step 585: loss = 1.8776 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 586: loss = 2.1699 (4.965 sec/step)\n",
            "I1009 03:38:07.925288 140425799219072 learning.py:507] global step 586: loss = 2.1699 (4.965 sec/step)\n",
            "INFO:tensorflow:global step 587: loss = 2.2296 (4.828 sec/step)\n",
            "I1009 03:38:12.755240 140425799219072 learning.py:507] global step 587: loss = 2.2296 (4.828 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:38:17.244292 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 588: loss = 1.7729 (4.671 sec/step)\n",
            "I1009 03:38:17.428118 140425799219072 learning.py:507] global step 588: loss = 1.7729 (4.671 sec/step)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W1009 03:38:17.446385 140422665111296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:Recording summary at step 589.\n",
            "I1009 03:38:28.054864 140422698682112 supervisor.py:1050] Recording summary at step 589.\n",
            "INFO:tensorflow:global step 589: loss = 2.3704 (10.606 sec/step)\n",
            "I1009 03:38:28.055058 140425799219072 learning.py:507] global step 589: loss = 2.3704 (10.606 sec/step)\n",
            "INFO:tensorflow:global step 590: loss = 1.9690 (5.566 sec/step)\n",
            "I1009 03:38:33.636445 140425799219072 learning.py:507] global step 590: loss = 1.9690 (5.566 sec/step)\n",
            "INFO:tensorflow:global step 591: loss = 2.0216 (4.737 sec/step)\n",
            "I1009 03:38:38.375541 140425799219072 learning.py:507] global step 591: loss = 2.0216 (4.737 sec/step)\n",
            "INFO:tensorflow:global step 592: loss = 2.6222 (4.712 sec/step)\n",
            "I1009 03:38:43.089414 140425799219072 learning.py:507] global step 592: loss = 2.6222 (4.712 sec/step)\n",
            "INFO:tensorflow:global step 593: loss = 2.4249 (4.749 sec/step)\n",
            "I1009 03:38:47.840290 140425799219072 learning.py:507] global step 593: loss = 2.4249 (4.749 sec/step)\n",
            "INFO:tensorflow:global step 594: loss = 1.8932 (4.723 sec/step)\n",
            "I1009 03:38:52.564939 140425799219072 learning.py:507] global step 594: loss = 1.8932 (4.723 sec/step)\n",
            "INFO:tensorflow:global step 595: loss = 1.7540 (4.846 sec/step)\n",
            "I1009 03:38:57.412680 140425799219072 learning.py:507] global step 595: loss = 1.7540 (4.846 sec/step)\n",
            "INFO:tensorflow:global step 596: loss = 2.3173 (4.896 sec/step)\n",
            "I1009 03:39:02.311993 140425799219072 learning.py:507] global step 596: loss = 2.3173 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 597: loss = 2.4389 (4.836 sec/step)\n",
            "I1009 03:39:07.150592 140425799219072 learning.py:507] global step 597: loss = 2.4389 (4.836 sec/step)\n",
            "INFO:tensorflow:global step 598: loss = 2.2958 (4.719 sec/step)\n",
            "I1009 03:39:11.871907 140425799219072 learning.py:507] global step 598: loss = 2.2958 (4.719 sec/step)\n",
            "INFO:tensorflow:global step 599: loss = 1.9145 (4.750 sec/step)\n",
            "I1009 03:39:16.623916 140425799219072 learning.py:507] global step 599: loss = 1.9145 (4.750 sec/step)\n",
            "INFO:tensorflow:global step 600: loss = 2.2315 (4.652 sec/step)\n",
            "I1009 03:39:21.278916 140425799219072 learning.py:507] global step 600: loss = 2.2315 (4.652 sec/step)\n",
            "INFO:tensorflow:global step 601: loss = 1.7106 (4.640 sec/step)\n",
            "I1009 03:39:25.920900 140425799219072 learning.py:507] global step 601: loss = 1.7106 (4.640 sec/step)\n",
            "INFO:tensorflow:global step 602: loss = 1.8846 (4.725 sec/step)\n",
            "I1009 03:39:30.648009 140425799219072 learning.py:507] global step 602: loss = 1.8846 (4.725 sec/step)\n",
            "INFO:tensorflow:global step 603: loss = 3.0617 (4.637 sec/step)\n",
            "I1009 03:39:35.286745 140425799219072 learning.py:507] global step 603: loss = 3.0617 (4.637 sec/step)\n",
            "INFO:tensorflow:global step 604: loss = 1.5146 (4.718 sec/step)\n",
            "I1009 03:39:40.006305 140425799219072 learning.py:507] global step 604: loss = 1.5146 (4.718 sec/step)\n",
            "INFO:tensorflow:global step 605: loss = 2.6543 (4.702 sec/step)\n",
            "I1009 03:39:44.710955 140425799219072 learning.py:507] global step 605: loss = 2.6543 (4.702 sec/step)\n",
            "INFO:tensorflow:global step 606: loss = 2.3558 (4.857 sec/step)\n",
            "I1009 03:39:49.569896 140425799219072 learning.py:507] global step 606: loss = 2.3558 (4.857 sec/step)\n",
            "INFO:tensorflow:global step 607: loss = 1.9082 (4.718 sec/step)\n",
            "I1009 03:39:54.290024 140425799219072 learning.py:507] global step 607: loss = 1.9082 (4.718 sec/step)\n",
            "INFO:tensorflow:global step 608: loss = 2.1602 (4.742 sec/step)\n",
            "I1009 03:39:59.034290 140425799219072 learning.py:507] global step 608: loss = 2.1602 (4.742 sec/step)\n",
            "INFO:tensorflow:global step 609: loss = 2.0941 (4.863 sec/step)\n",
            "I1009 03:40:03.899369 140425799219072 learning.py:507] global step 609: loss = 2.0941 (4.863 sec/step)\n",
            "INFO:tensorflow:global step 610: loss = 2.3279 (4.821 sec/step)\n",
            "I1009 03:40:08.722386 140425799219072 learning.py:507] global step 610: loss = 2.3279 (4.821 sec/step)\n",
            "INFO:tensorflow:global step 611: loss = 1.7939 (4.881 sec/step)\n",
            "I1009 03:40:13.604905 140425799219072 learning.py:507] global step 611: loss = 1.7939 (4.881 sec/step)\n",
            "INFO:tensorflow:global step 612: loss = 1.7670 (6.167 sec/step)\n",
            "I1009 03:40:19.790477 140425799219072 learning.py:507] global step 612: loss = 1.7670 (6.167 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 612.\n",
            "I1009 03:40:25.175634 140422698682112 supervisor.py:1050] Recording summary at step 612.\n",
            "INFO:tensorflow:global step 613: loss = 1.6511 (6.654 sec/step)\n",
            "I1009 03:40:26.468746 140425799219072 learning.py:507] global step 613: loss = 1.6511 (6.654 sec/step)\n",
            "INFO:tensorflow:global step 614: loss = 1.9364 (4.905 sec/step)\n",
            "I1009 03:40:31.376114 140425799219072 learning.py:507] global step 614: loss = 1.9364 (4.905 sec/step)\n",
            "INFO:tensorflow:global step 615: loss = 2.4308 (4.856 sec/step)\n",
            "I1009 03:40:36.234212 140425799219072 learning.py:507] global step 615: loss = 2.4308 (4.856 sec/step)\n",
            "INFO:tensorflow:global step 616: loss = 1.7272 (4.586 sec/step)\n",
            "I1009 03:40:40.822726 140425799219072 learning.py:507] global step 616: loss = 1.7272 (4.586 sec/step)\n",
            "INFO:tensorflow:global step 617: loss = 1.9387 (4.682 sec/step)\n",
            "I1009 03:40:45.506323 140425799219072 learning.py:507] global step 617: loss = 1.9387 (4.682 sec/step)\n",
            "INFO:tensorflow:global step 618: loss = 2.2815 (4.666 sec/step)\n",
            "I1009 03:40:50.173962 140425799219072 learning.py:507] global step 618: loss = 2.2815 (4.666 sec/step)\n",
            "INFO:tensorflow:global step 619: loss = 2.1544 (4.948 sec/step)\n",
            "I1009 03:40:55.123398 140425799219072 learning.py:507] global step 619: loss = 2.1544 (4.948 sec/step)\n",
            "INFO:tensorflow:global step 620: loss = 1.9263 (4.820 sec/step)\n",
            "I1009 03:40:59.945475 140425799219072 learning.py:507] global step 620: loss = 1.9263 (4.820 sec/step)\n",
            "INFO:tensorflow:global step 621: loss = 2.5958 (4.762 sec/step)\n",
            "I1009 03:41:04.708941 140425799219072 learning.py:507] global step 621: loss = 2.5958 (4.762 sec/step)\n",
            "INFO:tensorflow:global step 622: loss = 2.0345 (4.745 sec/step)\n",
            "I1009 03:41:09.456454 140425799219072 learning.py:507] global step 622: loss = 2.0345 (4.745 sec/step)\n",
            "INFO:tensorflow:global step 623: loss = 1.9056 (4.647 sec/step)\n",
            "I1009 03:41:14.105017 140425799219072 learning.py:507] global step 623: loss = 1.9056 (4.647 sec/step)\n",
            "INFO:tensorflow:global step 624: loss = 1.5881 (4.601 sec/step)\n",
            "I1009 03:41:18.707562 140425799219072 learning.py:507] global step 624: loss = 1.5881 (4.601 sec/step)\n",
            "INFO:tensorflow:global step 625: loss = 2.6657 (4.735 sec/step)\n",
            "I1009 03:41:23.444566 140425799219072 learning.py:507] global step 625: loss = 2.6657 (4.735 sec/step)\n",
            "INFO:tensorflow:global step 626: loss = 2.5423 (4.826 sec/step)\n",
            "I1009 03:41:28.272236 140425799219072 learning.py:507] global step 626: loss = 2.5423 (4.826 sec/step)\n",
            "INFO:tensorflow:global step 627: loss = 2.3173 (4.606 sec/step)\n",
            "I1009 03:41:32.879959 140425799219072 learning.py:507] global step 627: loss = 2.3173 (4.606 sec/step)\n",
            "INFO:tensorflow:global step 628: loss = 1.8695 (5.172 sec/step)\n",
            "I1009 03:41:38.053997 140425799219072 learning.py:507] global step 628: loss = 1.8695 (5.172 sec/step)\n",
            "INFO:tensorflow:global step 629: loss = 1.8555 (4.927 sec/step)\n",
            "I1009 03:41:42.983175 140425799219072 learning.py:507] global step 629: loss = 1.8555 (4.927 sec/step)\n",
            "INFO:tensorflow:global step 630: loss = 2.0712 (4.854 sec/step)\n",
            "I1009 03:41:47.839986 140425799219072 learning.py:507] global step 630: loss = 2.0712 (4.854 sec/step)\n",
            "INFO:tensorflow:global step 631: loss = 1.9086 (4.960 sec/step)\n",
            "I1009 03:41:52.802013 140425799219072 learning.py:507] global step 631: loss = 1.9086 (4.960 sec/step)\n",
            "INFO:tensorflow:global step 632: loss = 2.5317 (5.205 sec/step)\n",
            "I1009 03:41:58.009209 140425799219072 learning.py:507] global step 632: loss = 2.5317 (5.205 sec/step)\n",
            "INFO:tensorflow:global step 633: loss = 2.0666 (4.842 sec/step)\n",
            "I1009 03:42:02.853465 140425799219072 learning.py:507] global step 633: loss = 2.0666 (4.842 sec/step)\n",
            "INFO:tensorflow:global step 634: loss = 1.9406 (4.963 sec/step)\n",
            "I1009 03:42:07.818709 140425799219072 learning.py:507] global step 634: loss = 1.9406 (4.963 sec/step)\n",
            "INFO:tensorflow:global step 635: loss = 1.8316 (4.757 sec/step)\n",
            "I1009 03:42:12.577089 140425799219072 learning.py:507] global step 635: loss = 1.8316 (4.757 sec/step)\n",
            "INFO:tensorflow:global step 636: loss = 2.2694 (4.614 sec/step)\n",
            "I1009 03:42:17.193276 140425799219072 learning.py:507] global step 636: loss = 2.2694 (4.614 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 636.\n",
            "I1009 03:42:24.094867 140422698682112 supervisor.py:1050] Recording summary at step 636.\n",
            "INFO:tensorflow:global step 637: loss = 2.0604 (7.867 sec/step)\n",
            "I1009 03:42:25.065690 140425799219072 learning.py:507] global step 637: loss = 2.0604 (7.867 sec/step)\n",
            "INFO:tensorflow:global step 638: loss = 2.2533 (4.650 sec/step)\n",
            "I1009 03:42:29.720456 140425799219072 learning.py:507] global step 638: loss = 2.2533 (4.650 sec/step)\n",
            "INFO:tensorflow:global step 639: loss = 2.1536 (4.720 sec/step)\n",
            "I1009 03:42:34.442316 140425799219072 learning.py:507] global step 639: loss = 2.1536 (4.720 sec/step)\n",
            "INFO:tensorflow:global step 640: loss = 1.4656 (4.611 sec/step)\n",
            "I1009 03:42:39.055252 140425799219072 learning.py:507] global step 640: loss = 1.4656 (4.611 sec/step)\n",
            "INFO:tensorflow:global step 641: loss = 2.2044 (4.667 sec/step)\n",
            "I1009 03:42:43.724253 140425799219072 learning.py:507] global step 641: loss = 2.2044 (4.667 sec/step)\n",
            "INFO:tensorflow:global step 642: loss = 2.1180 (4.650 sec/step)\n",
            "I1009 03:42:48.375608 140425799219072 learning.py:507] global step 642: loss = 2.1180 (4.650 sec/step)\n",
            "INFO:tensorflow:global step 643: loss = 2.4773 (4.887 sec/step)\n",
            "I1009 03:42:53.264497 140425799219072 learning.py:507] global step 643: loss = 2.4773 (4.887 sec/step)\n",
            "INFO:tensorflow:global step 644: loss = 2.0799 (4.766 sec/step)\n",
            "I1009 03:42:58.032697 140425799219072 learning.py:507] global step 644: loss = 2.0799 (4.766 sec/step)\n",
            "INFO:tensorflow:global step 645: loss = 2.0155 (4.772 sec/step)\n",
            "I1009 03:43:02.807286 140425799219072 learning.py:507] global step 645: loss = 2.0155 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 646: loss = 2.0223 (4.673 sec/step)\n",
            "I1009 03:43:07.481977 140425799219072 learning.py:507] global step 646: loss = 2.0223 (4.673 sec/step)\n",
            "INFO:tensorflow:global step 647: loss = 2.0802 (4.619 sec/step)\n",
            "I1009 03:43:12.103227 140425799219072 learning.py:507] global step 647: loss = 2.0802 (4.619 sec/step)\n",
            "INFO:tensorflow:global step 648: loss = 1.6323 (4.552 sec/step)\n",
            "I1009 03:43:16.657426 140425799219072 learning.py:507] global step 648: loss = 1.6323 (4.552 sec/step)\n",
            "INFO:tensorflow:global step 649: loss = 1.5884 (4.687 sec/step)\n",
            "I1009 03:43:21.346721 140425799219072 learning.py:507] global step 649: loss = 1.5884 (4.687 sec/step)\n",
            "INFO:tensorflow:global step 650: loss = 1.7891 (4.677 sec/step)\n",
            "I1009 03:43:26.025520 140425799219072 learning.py:507] global step 650: loss = 1.7891 (4.677 sec/step)\n",
            "INFO:tensorflow:global step 651: loss = 2.1532 (4.750 sec/step)\n",
            "I1009 03:43:30.777292 140425799219072 learning.py:507] global step 651: loss = 2.1532 (4.750 sec/step)\n",
            "INFO:tensorflow:global step 652: loss = 2.4697 (4.673 sec/step)\n",
            "I1009 03:43:35.452282 140425799219072 learning.py:507] global step 652: loss = 2.4697 (4.673 sec/step)\n",
            "INFO:tensorflow:global step 653: loss = 2.0717 (4.673 sec/step)\n",
            "I1009 03:43:40.127691 140425799219072 learning.py:507] global step 653: loss = 2.0717 (4.673 sec/step)\n",
            "INFO:tensorflow:global step 654: loss = 1.6736 (4.687 sec/step)\n",
            "I1009 03:43:44.817333 140425799219072 learning.py:507] global step 654: loss = 1.6736 (4.687 sec/step)\n",
            "INFO:tensorflow:global step 655: loss = 2.2100 (4.688 sec/step)\n",
            "I1009 03:43:49.507605 140425799219072 learning.py:507] global step 655: loss = 2.2100 (4.688 sec/step)\n",
            "INFO:tensorflow:global step 656: loss = 1.6237 (4.739 sec/step)\n",
            "I1009 03:43:54.248535 140425799219072 learning.py:507] global step 656: loss = 1.6237 (4.739 sec/step)\n",
            "INFO:tensorflow:global step 657: loss = 2.4124 (4.736 sec/step)\n",
            "I1009 03:43:58.987109 140425799219072 learning.py:507] global step 657: loss = 2.4124 (4.736 sec/step)\n",
            "INFO:tensorflow:global step 658: loss = 1.8967 (4.792 sec/step)\n",
            "I1009 03:44:03.780781 140425799219072 learning.py:507] global step 658: loss = 1.8967 (4.792 sec/step)\n",
            "INFO:tensorflow:global step 659: loss = 1.7612 (4.632 sec/step)\n",
            "I1009 03:44:08.415472 140425799219072 learning.py:507] global step 659: loss = 1.7612 (4.632 sec/step)\n",
            "INFO:tensorflow:global step 660: loss = 1.6724 (4.681 sec/step)\n",
            "I1009 03:44:13.098818 140425799219072 learning.py:507] global step 660: loss = 1.6724 (4.681 sec/step)\n",
            "INFO:tensorflow:global step 661: loss = 3.0165 (5.657 sec/step)\n",
            "I1009 03:44:18.787997 140425799219072 learning.py:507] global step 661: loss = 3.0165 (5.657 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 661.\n",
            "I1009 03:44:24.709758 140422698682112 supervisor.py:1050] Recording summary at step 661.\n",
            "INFO:tensorflow:global step 662: loss = 2.4178 (7.098 sec/step)\n",
            "I1009 03:44:25.888605 140425799219072 learning.py:507] global step 662: loss = 2.4178 (7.098 sec/step)\n",
            "INFO:tensorflow:global step 663: loss = 1.3497 (4.706 sec/step)\n",
            "I1009 03:44:30.596411 140425799219072 learning.py:507] global step 663: loss = 1.3497 (4.706 sec/step)\n",
            "INFO:tensorflow:global step 664: loss = 1.8984 (4.665 sec/step)\n",
            "I1009 03:44:35.263643 140425799219072 learning.py:507] global step 664: loss = 1.8984 (4.665 sec/step)\n",
            "INFO:tensorflow:global step 665: loss = 2.4236 (4.571 sec/step)\n",
            "I1009 03:44:39.837182 140425799219072 learning.py:507] global step 665: loss = 2.4236 (4.571 sec/step)\n",
            "INFO:tensorflow:global step 666: loss = 1.9256 (4.706 sec/step)\n",
            "I1009 03:44:44.544836 140425799219072 learning.py:507] global step 666: loss = 1.9256 (4.706 sec/step)\n",
            "INFO:tensorflow:global step 667: loss = 1.8446 (4.727 sec/step)\n",
            "I1009 03:44:49.274833 140425799219072 learning.py:507] global step 667: loss = 1.8446 (4.727 sec/step)\n",
            "INFO:tensorflow:global step 668: loss = 1.9843 (4.941 sec/step)\n",
            "I1009 03:44:54.217907 140425799219072 learning.py:507] global step 668: loss = 1.9843 (4.941 sec/step)\n",
            "INFO:tensorflow:global step 669: loss = 1.8178 (5.316 sec/step)\n",
            "I1009 03:44:59.535982 140425799219072 learning.py:507] global step 669: loss = 1.8178 (5.316 sec/step)\n",
            "INFO:tensorflow:global step 670: loss = 2.1054 (4.695 sec/step)\n",
            "I1009 03:45:04.232858 140425799219072 learning.py:507] global step 670: loss = 2.1054 (4.695 sec/step)\n",
            "INFO:tensorflow:global step 671: loss = 2.1895 (4.712 sec/step)\n",
            "I1009 03:45:08.947137 140425799219072 learning.py:507] global step 671: loss = 2.1895 (4.712 sec/step)\n",
            "INFO:tensorflow:global step 672: loss = 1.9398 (4.734 sec/step)\n",
            "I1009 03:45:13.682661 140425799219072 learning.py:507] global step 672: loss = 1.9398 (4.734 sec/step)\n",
            "INFO:tensorflow:global step 673: loss = 1.7513 (4.608 sec/step)\n",
            "I1009 03:45:18.292564 140425799219072 learning.py:507] global step 673: loss = 1.7513 (4.608 sec/step)\n",
            "INFO:tensorflow:global step 674: loss = 2.1372 (4.655 sec/step)\n",
            "I1009 03:45:22.949228 140425799219072 learning.py:507] global step 674: loss = 2.1372 (4.655 sec/step)\n",
            "INFO:tensorflow:global step 675: loss = 1.7049 (5.128 sec/step)\n",
            "I1009 03:45:28.079371 140425799219072 learning.py:507] global step 675: loss = 1.7049 (5.128 sec/step)\n",
            "INFO:tensorflow:global step 676: loss = 2.1257 (4.555 sec/step)\n",
            "I1009 03:45:32.636140 140425799219072 learning.py:507] global step 676: loss = 2.1257 (4.555 sec/step)\n",
            "INFO:tensorflow:global step 677: loss = 2.0243 (4.643 sec/step)\n",
            "I1009 03:45:37.281558 140425799219072 learning.py:507] global step 677: loss = 2.0243 (4.643 sec/step)\n",
            "INFO:tensorflow:global step 678: loss = 1.6846 (4.646 sec/step)\n",
            "I1009 03:45:41.929315 140425799219072 learning.py:507] global step 678: loss = 1.6846 (4.646 sec/step)\n",
            "INFO:tensorflow:global step 679: loss = 1.8595 (4.681 sec/step)\n",
            "I1009 03:45:46.612602 140425799219072 learning.py:507] global step 679: loss = 1.8595 (4.681 sec/step)\n",
            "INFO:tensorflow:global step 680: loss = 1.8753 (4.810 sec/step)\n",
            "I1009 03:45:51.424414 140425799219072 learning.py:507] global step 680: loss = 1.8753 (4.810 sec/step)\n",
            "INFO:tensorflow:global step 681: loss = 2.1690 (4.710 sec/step)\n",
            "I1009 03:45:56.135814 140425799219072 learning.py:507] global step 681: loss = 2.1690 (4.710 sec/step)\n",
            "INFO:tensorflow:global step 682: loss = 1.7082 (4.902 sec/step)\n",
            "I1009 03:46:01.039875 140425799219072 learning.py:507] global step 682: loss = 1.7082 (4.902 sec/step)\n",
            "INFO:tensorflow:global step 683: loss = 2.5036 (4.896 sec/step)\n",
            "I1009 03:46:05.937598 140425799219072 learning.py:507] global step 683: loss = 2.5036 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 684: loss = 2.1011 (4.727 sec/step)\n",
            "I1009 03:46:10.666787 140425799219072 learning.py:507] global step 684: loss = 2.1011 (4.727 sec/step)\n",
            "INFO:tensorflow:global step 685: loss = 2.3785 (4.891 sec/step)\n",
            "I1009 03:46:15.559668 140425799219072 learning.py:507] global step 685: loss = 2.3785 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 686: loss = 1.6053 (7.722 sec/step)\n",
            "I1009 03:46:23.284736 140425799219072 learning.py:507] global step 686: loss = 1.6053 (7.722 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 686.\n",
            "I1009 03:46:25.159685 140422698682112 supervisor.py:1050] Recording summary at step 686.\n",
            "INFO:tensorflow:global step 687: loss = 1.6935 (5.209 sec/step)\n",
            "I1009 03:46:28.496483 140425799219072 learning.py:507] global step 687: loss = 1.6935 (5.209 sec/step)\n",
            "INFO:tensorflow:global step 688: loss = 2.1429 (4.828 sec/step)\n",
            "I1009 03:46:33.326744 140425799219072 learning.py:507] global step 688: loss = 2.1429 (4.828 sec/step)\n",
            "INFO:tensorflow:global step 689: loss = 2.1236 (4.861 sec/step)\n",
            "I1009 03:46:38.189856 140425799219072 learning.py:507] global step 689: loss = 2.1236 (4.861 sec/step)\n",
            "INFO:tensorflow:global step 690: loss = 1.8801 (4.874 sec/step)\n",
            "I1009 03:46:43.066256 140425799219072 learning.py:507] global step 690: loss = 1.8801 (4.874 sec/step)\n",
            "INFO:tensorflow:global step 691: loss = 2.1085 (4.957 sec/step)\n",
            "I1009 03:46:48.024514 140425799219072 learning.py:507] global step 691: loss = 2.1085 (4.957 sec/step)\n",
            "INFO:tensorflow:global step 692: loss = 2.4105 (4.828 sec/step)\n",
            "I1009 03:46:52.854576 140425799219072 learning.py:507] global step 692: loss = 2.4105 (4.828 sec/step)\n",
            "INFO:tensorflow:global step 693: loss = 1.6343 (4.824 sec/step)\n",
            "I1009 03:46:57.680359 140425799219072 learning.py:507] global step 693: loss = 1.6343 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 694: loss = 2.0720 (4.772 sec/step)\n",
            "I1009 03:47:02.454145 140425799219072 learning.py:507] global step 694: loss = 2.0720 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 695: loss = 2.0968 (4.778 sec/step)\n",
            "I1009 03:47:07.233665 140425799219072 learning.py:507] global step 695: loss = 2.0968 (4.778 sec/step)\n",
            "INFO:tensorflow:global step 696: loss = 1.7528 (4.768 sec/step)\n",
            "I1009 03:47:12.003376 140425799219072 learning.py:507] global step 696: loss = 1.7528 (4.768 sec/step)\n",
            "INFO:tensorflow:global step 697: loss = 2.0830 (4.923 sec/step)\n",
            "I1009 03:47:16.928017 140425799219072 learning.py:507] global step 697: loss = 2.0830 (4.923 sec/step)\n",
            "INFO:tensorflow:global step 698: loss = 2.1092 (4.810 sec/step)\n",
            "I1009 03:47:21.739804 140425799219072 learning.py:507] global step 698: loss = 2.1092 (4.810 sec/step)\n",
            "INFO:tensorflow:global step 699: loss = 2.3380 (4.769 sec/step)\n",
            "I1009 03:47:26.510337 140425799219072 learning.py:507] global step 699: loss = 2.3380 (4.769 sec/step)\n",
            "INFO:tensorflow:global step 700: loss = 1.9335 (4.878 sec/step)\n",
            "I1009 03:47:31.390244 140425799219072 learning.py:507] global step 700: loss = 1.9335 (4.878 sec/step)\n",
            "INFO:tensorflow:global step 701: loss = 2.0286 (4.901 sec/step)\n",
            "I1009 03:47:36.293339 140425799219072 learning.py:507] global step 701: loss = 2.0286 (4.901 sec/step)\n",
            "INFO:tensorflow:global step 702: loss = 1.6452 (4.915 sec/step)\n",
            "I1009 03:47:41.210148 140425799219072 learning.py:507] global step 702: loss = 1.6452 (4.915 sec/step)\n",
            "INFO:tensorflow:global step 703: loss = 2.1870 (4.744 sec/step)\n",
            "I1009 03:47:45.956244 140425799219072 learning.py:507] global step 703: loss = 2.1870 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 704: loss = 2.1430 (4.762 sec/step)\n",
            "I1009 03:47:50.720584 140425799219072 learning.py:507] global step 704: loss = 2.1430 (4.762 sec/step)\n",
            "INFO:tensorflow:global step 705: loss = 2.9683 (4.943 sec/step)\n",
            "I1009 03:47:55.665297 140425799219072 learning.py:507] global step 705: loss = 2.9683 (4.943 sec/step)\n",
            "INFO:tensorflow:global step 706: loss = 1.8823 (4.886 sec/step)\n",
            "I1009 03:48:00.553561 140425799219072 learning.py:507] global step 706: loss = 1.8823 (4.886 sec/step)\n",
            "INFO:tensorflow:global step 707: loss = 1.9021 (4.870 sec/step)\n",
            "I1009 03:48:05.425052 140425799219072 learning.py:507] global step 707: loss = 1.9021 (4.870 sec/step)\n",
            "INFO:tensorflow:global step 708: loss = 1.8445 (4.773 sec/step)\n",
            "I1009 03:48:10.200232 140425799219072 learning.py:507] global step 708: loss = 1.8445 (4.773 sec/step)\n",
            "INFO:tensorflow:global step 709: loss = 1.7965 (4.659 sec/step)\n",
            "I1009 03:48:14.860651 140425799219072 learning.py:507] global step 709: loss = 1.7965 (4.659 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:48:17.244267 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 710: loss = 2.0582 (9.148 sec/step)\n",
            "I1009 03:48:24.031337 140425799219072 learning.py:507] global step 710: loss = 2.0582 (9.148 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 710.\n",
            "I1009 03:48:26.997867 140422698682112 supervisor.py:1050] Recording summary at step 710.\n",
            "INFO:tensorflow:global step 711: loss = 2.2317 (6.187 sec/step)\n",
            "I1009 03:48:30.226436 140425799219072 learning.py:507] global step 711: loss = 2.2317 (6.187 sec/step)\n",
            "INFO:tensorflow:global step 712: loss = 2.4143 (4.614 sec/step)\n",
            "I1009 03:48:34.841909 140425799219072 learning.py:507] global step 712: loss = 2.4143 (4.614 sec/step)\n",
            "INFO:tensorflow:global step 713: loss = 1.5080 (4.650 sec/step)\n",
            "I1009 03:48:39.493549 140425799219072 learning.py:507] global step 713: loss = 1.5080 (4.650 sec/step)\n",
            "INFO:tensorflow:global step 714: loss = 1.6934 (4.752 sec/step)\n",
            "I1009 03:48:44.247610 140425799219072 learning.py:507] global step 714: loss = 1.6934 (4.752 sec/step)\n",
            "INFO:tensorflow:global step 715: loss = 1.9283 (4.851 sec/step)\n",
            "I1009 03:48:49.100677 140425799219072 learning.py:507] global step 715: loss = 1.9283 (4.851 sec/step)\n",
            "INFO:tensorflow:global step 716: loss = 2.0286 (4.809 sec/step)\n",
            "I1009 03:48:53.912237 140425799219072 learning.py:507] global step 716: loss = 2.0286 (4.809 sec/step)\n",
            "INFO:tensorflow:global step 717: loss = 2.4434 (4.744 sec/step)\n",
            "I1009 03:48:58.658444 140425799219072 learning.py:507] global step 717: loss = 2.4434 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 718: loss = 2.0315 (4.812 sec/step)\n",
            "I1009 03:49:03.472088 140425799219072 learning.py:507] global step 718: loss = 2.0315 (4.812 sec/step)\n",
            "INFO:tensorflow:global step 719: loss = 2.0838 (4.722 sec/step)\n",
            "I1009 03:49:08.196282 140425799219072 learning.py:507] global step 719: loss = 2.0838 (4.722 sec/step)\n",
            "INFO:tensorflow:global step 720: loss = 1.9933 (4.757 sec/step)\n",
            "I1009 03:49:12.955178 140425799219072 learning.py:507] global step 720: loss = 1.9933 (4.757 sec/step)\n",
            "INFO:tensorflow:global step 721: loss = 1.5475 (4.947 sec/step)\n",
            "I1009 03:49:17.903726 140425799219072 learning.py:507] global step 721: loss = 1.5475 (4.947 sec/step)\n",
            "INFO:tensorflow:global step 722: loss = 1.8946 (4.613 sec/step)\n",
            "I1009 03:49:22.518320 140425799219072 learning.py:507] global step 722: loss = 1.8946 (4.613 sec/step)\n",
            "INFO:tensorflow:global step 723: loss = 1.9746 (4.598 sec/step)\n",
            "I1009 03:49:27.118758 140425799219072 learning.py:507] global step 723: loss = 1.9746 (4.598 sec/step)\n",
            "INFO:tensorflow:global step 724: loss = 1.8000 (4.626 sec/step)\n",
            "I1009 03:49:31.746989 140425799219072 learning.py:507] global step 724: loss = 1.8000 (4.626 sec/step)\n",
            "INFO:tensorflow:global step 725: loss = 1.9252 (4.772 sec/step)\n",
            "I1009 03:49:36.520813 140425799219072 learning.py:507] global step 725: loss = 1.9252 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 726: loss = 1.9827 (4.658 sec/step)\n",
            "I1009 03:49:41.180213 140425799219072 learning.py:507] global step 726: loss = 1.9827 (4.658 sec/step)\n",
            "INFO:tensorflow:global step 727: loss = 2.3112 (4.809 sec/step)\n",
            "I1009 03:49:45.991127 140425799219072 learning.py:507] global step 727: loss = 2.3112 (4.809 sec/step)\n",
            "INFO:tensorflow:global step 728: loss = 1.5768 (4.777 sec/step)\n",
            "I1009 03:49:50.770137 140425799219072 learning.py:507] global step 728: loss = 1.5768 (4.777 sec/step)\n",
            "INFO:tensorflow:global step 729: loss = 2.2023 (4.705 sec/step)\n",
            "I1009 03:49:55.477003 140425799219072 learning.py:507] global step 729: loss = 2.2023 (4.705 sec/step)\n",
            "INFO:tensorflow:global step 730: loss = 1.8334 (4.838 sec/step)\n",
            "I1009 03:50:00.316855 140425799219072 learning.py:507] global step 730: loss = 1.8334 (4.838 sec/step)\n",
            "INFO:tensorflow:global step 731: loss = 1.9681 (4.827 sec/step)\n",
            "I1009 03:50:05.145640 140425799219072 learning.py:507] global step 731: loss = 1.9681 (4.827 sec/step)\n",
            "INFO:tensorflow:global step 732: loss = 2.1000 (4.636 sec/step)\n",
            "I1009 03:50:09.784224 140425799219072 learning.py:507] global step 732: loss = 2.1000 (4.636 sec/step)\n",
            "INFO:tensorflow:global step 733: loss = 1.7355 (4.633 sec/step)\n",
            "I1009 03:50:14.419465 140425799219072 learning.py:507] global step 733: loss = 1.7355 (4.633 sec/step)\n",
            "INFO:tensorflow:global step 734: loss = 1.5568 (7.714 sec/step)\n",
            "I1009 03:50:22.134989 140425799219072 learning.py:507] global step 734: loss = 1.5568 (7.714 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 734.\n",
            "I1009 03:50:25.052795 140422698682112 supervisor.py:1050] Recording summary at step 734.\n",
            "INFO:tensorflow:global step 735: loss = 1.7361 (5.196 sec/step)\n",
            "I1009 03:50:27.333463 140425799219072 learning.py:507] global step 735: loss = 1.7361 (5.196 sec/step)\n",
            "INFO:tensorflow:global step 736: loss = 1.8387 (4.727 sec/step)\n",
            "I1009 03:50:32.062110 140425799219072 learning.py:507] global step 736: loss = 1.8387 (4.727 sec/step)\n",
            "INFO:tensorflow:global step 737: loss = 2.4624 (4.921 sec/step)\n",
            "I1009 03:50:36.985191 140425799219072 learning.py:507] global step 737: loss = 2.4624 (4.921 sec/step)\n",
            "INFO:tensorflow:global step 738: loss = 1.7290 (4.772 sec/step)\n",
            "I1009 03:50:41.759022 140425799219072 learning.py:507] global step 738: loss = 1.7290 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 739: loss = 2.0641 (5.253 sec/step)\n",
            "I1009 03:50:47.014228 140425799219072 learning.py:507] global step 739: loss = 2.0641 (5.253 sec/step)\n",
            "INFO:tensorflow:global step 740: loss = 1.3393 (4.847 sec/step)\n",
            "I1009 03:50:51.863292 140425799219072 learning.py:507] global step 740: loss = 1.3393 (4.847 sec/step)\n",
            "INFO:tensorflow:global step 741: loss = 1.9639 (4.862 sec/step)\n",
            "I1009 03:50:56.727489 140425799219072 learning.py:507] global step 741: loss = 1.9639 (4.862 sec/step)\n",
            "INFO:tensorflow:global step 742: loss = 1.7631 (4.860 sec/step)\n",
            "I1009 03:51:01.589107 140425799219072 learning.py:507] global step 742: loss = 1.7631 (4.860 sec/step)\n",
            "INFO:tensorflow:global step 743: loss = 2.0591 (4.785 sec/step)\n",
            "I1009 03:51:06.375731 140425799219072 learning.py:507] global step 743: loss = 2.0591 (4.785 sec/step)\n",
            "INFO:tensorflow:global step 744: loss = 1.9963 (4.953 sec/step)\n",
            "I1009 03:51:11.330459 140425799219072 learning.py:507] global step 744: loss = 1.9963 (4.953 sec/step)\n",
            "INFO:tensorflow:global step 745: loss = 1.9350 (4.704 sec/step)\n",
            "I1009 03:51:16.036455 140425799219072 learning.py:507] global step 745: loss = 1.9350 (4.704 sec/step)\n",
            "INFO:tensorflow:global step 746: loss = 2.1022 (4.737 sec/step)\n",
            "I1009 03:51:20.775276 140425799219072 learning.py:507] global step 746: loss = 2.1022 (4.737 sec/step)\n",
            "INFO:tensorflow:global step 747: loss = 1.8577 (5.076 sec/step)\n",
            "I1009 03:51:25.853143 140425799219072 learning.py:507] global step 747: loss = 1.8577 (5.076 sec/step)\n",
            "INFO:tensorflow:global step 748: loss = 1.7143 (4.664 sec/step)\n",
            "I1009 03:51:30.519242 140425799219072 learning.py:507] global step 748: loss = 1.7143 (4.664 sec/step)\n",
            "INFO:tensorflow:global step 749: loss = 2.0624 (4.796 sec/step)\n",
            "I1009 03:51:35.317150 140425799219072 learning.py:507] global step 749: loss = 2.0624 (4.796 sec/step)\n",
            "INFO:tensorflow:global step 750: loss = 2.0133 (4.877 sec/step)\n",
            "I1009 03:51:40.195633 140425799219072 learning.py:507] global step 750: loss = 2.0133 (4.877 sec/step)\n",
            "INFO:tensorflow:global step 751: loss = 1.4457 (5.002 sec/step)\n",
            "I1009 03:51:45.199220 140425799219072 learning.py:507] global step 751: loss = 1.4457 (5.002 sec/step)\n",
            "INFO:tensorflow:global step 752: loss = 1.8238 (4.854 sec/step)\n",
            "I1009 03:51:50.055187 140425799219072 learning.py:507] global step 752: loss = 1.8238 (4.854 sec/step)\n",
            "INFO:tensorflow:global step 753: loss = 1.8791 (5.314 sec/step)\n",
            "I1009 03:51:55.371050 140425799219072 learning.py:507] global step 753: loss = 1.8791 (5.314 sec/step)\n",
            "INFO:tensorflow:global step 754: loss = 1.9487 (4.728 sec/step)\n",
            "I1009 03:52:00.100335 140425799219072 learning.py:507] global step 754: loss = 1.9487 (4.728 sec/step)\n",
            "INFO:tensorflow:global step 755: loss = 2.0877 (4.790 sec/step)\n",
            "I1009 03:52:04.892163 140425799219072 learning.py:507] global step 755: loss = 2.0877 (4.790 sec/step)\n",
            "INFO:tensorflow:global step 756: loss = 1.8132 (4.630 sec/step)\n",
            "I1009 03:52:09.523878 140425799219072 learning.py:507] global step 756: loss = 1.8132 (4.630 sec/step)\n",
            "INFO:tensorflow:global step 757: loss = 2.2539 (5.026 sec/step)\n",
            "I1009 03:52:14.551683 140425799219072 learning.py:507] global step 757: loss = 2.2539 (5.026 sec/step)\n",
            "INFO:tensorflow:global step 758: loss = 2.3719 (7.624 sec/step)\n",
            "I1009 03:52:22.178023 140425799219072 learning.py:507] global step 758: loss = 2.3719 (7.624 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 758.\n",
            "I1009 03:52:25.505441 140422698682112 supervisor.py:1050] Recording summary at step 758.\n",
            "INFO:tensorflow:global step 759: loss = 2.0185 (5.480 sec/step)\n",
            "I1009 03:52:27.659846 140425799219072 learning.py:507] global step 759: loss = 2.0185 (5.480 sec/step)\n",
            "INFO:tensorflow:global step 760: loss = 2.2460 (4.715 sec/step)\n",
            "I1009 03:52:32.376950 140425799219072 learning.py:507] global step 760: loss = 2.2460 (4.715 sec/step)\n",
            "INFO:tensorflow:global step 761: loss = 1.5207 (4.715 sec/step)\n",
            "I1009 03:52:37.094156 140425799219072 learning.py:507] global step 761: loss = 1.5207 (4.715 sec/step)\n",
            "INFO:tensorflow:global step 762: loss = 1.8288 (4.918 sec/step)\n",
            "I1009 03:52:42.014566 140425799219072 learning.py:507] global step 762: loss = 1.8288 (4.918 sec/step)\n",
            "INFO:tensorflow:global step 763: loss = 1.8718 (4.877 sec/step)\n",
            "I1009 03:52:46.893070 140425799219072 learning.py:507] global step 763: loss = 1.8718 (4.877 sec/step)\n",
            "INFO:tensorflow:global step 764: loss = 2.1520 (4.894 sec/step)\n",
            "I1009 03:52:51.789168 140425799219072 learning.py:507] global step 764: loss = 2.1520 (4.894 sec/step)\n",
            "INFO:tensorflow:global step 765: loss = 2.0694 (5.115 sec/step)\n",
            "I1009 03:52:56.905684 140425799219072 learning.py:507] global step 765: loss = 2.0694 (5.115 sec/step)\n",
            "INFO:tensorflow:global step 766: loss = 1.5724 (4.919 sec/step)\n",
            "I1009 03:53:01.826899 140425799219072 learning.py:507] global step 766: loss = 1.5724 (4.919 sec/step)\n",
            "INFO:tensorflow:global step 767: loss = 1.7234 (4.952 sec/step)\n",
            "I1009 03:53:06.781131 140425799219072 learning.py:507] global step 767: loss = 1.7234 (4.952 sec/step)\n",
            "INFO:tensorflow:global step 768: loss = 1.5986 (5.354 sec/step)\n",
            "I1009 03:53:12.137141 140425799219072 learning.py:507] global step 768: loss = 1.5986 (5.354 sec/step)\n",
            "INFO:tensorflow:global step 769: loss = 1.9570 (4.861 sec/step)\n",
            "I1009 03:53:17.000567 140425799219072 learning.py:507] global step 769: loss = 1.9570 (4.861 sec/step)\n",
            "INFO:tensorflow:global step 770: loss = 2.0006 (4.891 sec/step)\n",
            "I1009 03:53:21.893258 140425799219072 learning.py:507] global step 770: loss = 2.0006 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 771: loss = 1.6408 (4.929 sec/step)\n",
            "I1009 03:53:26.823981 140425799219072 learning.py:507] global step 771: loss = 1.6408 (4.929 sec/step)\n",
            "INFO:tensorflow:global step 772: loss = 1.8982 (4.817 sec/step)\n",
            "I1009 03:53:31.642882 140425799219072 learning.py:507] global step 772: loss = 1.8982 (4.817 sec/step)\n",
            "INFO:tensorflow:global step 773: loss = 1.9112 (5.005 sec/step)\n",
            "I1009 03:53:36.650402 140425799219072 learning.py:507] global step 773: loss = 1.9112 (5.005 sec/step)\n",
            "INFO:tensorflow:global step 774: loss = 1.6704 (5.373 sec/step)\n",
            "I1009 03:53:42.025941 140425799219072 learning.py:507] global step 774: loss = 1.6704 (5.373 sec/step)\n",
            "INFO:tensorflow:global step 775: loss = 1.9287 (4.696 sec/step)\n",
            "I1009 03:53:46.723318 140425799219072 learning.py:507] global step 775: loss = 1.9287 (4.696 sec/step)\n",
            "INFO:tensorflow:global step 776: loss = 1.8115 (4.850 sec/step)\n",
            "I1009 03:53:51.574951 140425799219072 learning.py:507] global step 776: loss = 1.8115 (4.850 sec/step)\n",
            "INFO:tensorflow:global step 777: loss = 2.1623 (4.801 sec/step)\n",
            "I1009 03:53:56.378634 140425799219072 learning.py:507] global step 777: loss = 2.1623 (4.801 sec/step)\n",
            "INFO:tensorflow:global step 778: loss = 1.6112 (4.704 sec/step)\n",
            "I1009 03:54:01.084823 140425799219072 learning.py:507] global step 778: loss = 1.6112 (4.704 sec/step)\n",
            "INFO:tensorflow:global step 779: loss = 2.2102 (4.864 sec/step)\n",
            "I1009 03:54:05.950884 140425799219072 learning.py:507] global step 779: loss = 2.2102 (4.864 sec/step)\n",
            "INFO:tensorflow:global step 780: loss = 1.8651 (5.055 sec/step)\n",
            "I1009 03:54:11.008166 140425799219072 learning.py:507] global step 780: loss = 1.8651 (5.055 sec/step)\n",
            "INFO:tensorflow:global step 781: loss = 1.4313 (4.749 sec/step)\n",
            "I1009 03:54:15.758393 140425799219072 learning.py:507] global step 781: loss = 1.4313 (4.749 sec/step)\n",
            "INFO:tensorflow:global step 782: loss = 1.7238 (7.884 sec/step)\n",
            "I1009 03:54:23.651448 140425799219072 learning.py:507] global step 782: loss = 1.7238 (7.884 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 782.\n",
            "I1009 03:54:24.795115 140422698682112 supervisor.py:1050] Recording summary at step 782.\n",
            "INFO:tensorflow:global step 783: loss = 2.0538 (4.950 sec/step)\n",
            "I1009 03:54:28.603982 140425799219072 learning.py:507] global step 783: loss = 2.0538 (4.950 sec/step)\n",
            "INFO:tensorflow:global step 784: loss = 1.9395 (4.641 sec/step)\n",
            "I1009 03:54:33.247069 140425799219072 learning.py:507] global step 784: loss = 1.9395 (4.641 sec/step)\n",
            "INFO:tensorflow:global step 785: loss = 3.0435 (4.828 sec/step)\n",
            "I1009 03:54:38.076890 140425799219072 learning.py:507] global step 785: loss = 3.0435 (4.828 sec/step)\n",
            "INFO:tensorflow:global step 786: loss = 2.3526 (4.682 sec/step)\n",
            "I1009 03:54:42.760601 140425799219072 learning.py:507] global step 786: loss = 2.3526 (4.682 sec/step)\n",
            "INFO:tensorflow:global step 787: loss = 2.2383 (4.734 sec/step)\n",
            "I1009 03:54:47.497352 140425799219072 learning.py:507] global step 787: loss = 2.2383 (4.734 sec/step)\n",
            "INFO:tensorflow:global step 788: loss = 1.6907 (4.964 sec/step)\n",
            "I1009 03:54:52.463357 140425799219072 learning.py:507] global step 788: loss = 1.6907 (4.964 sec/step)\n",
            "INFO:tensorflow:global step 789: loss = 1.9556 (4.786 sec/step)\n",
            "I1009 03:54:57.251647 140425799219072 learning.py:507] global step 789: loss = 1.9556 (4.786 sec/step)\n",
            "INFO:tensorflow:global step 790: loss = 1.5210 (4.754 sec/step)\n",
            "I1009 03:55:02.008839 140425799219072 learning.py:507] global step 790: loss = 1.5210 (4.754 sec/step)\n",
            "INFO:tensorflow:global step 791: loss = 2.2975 (6.401 sec/step)\n",
            "I1009 03:55:08.420976 140425799219072 learning.py:507] global step 791: loss = 2.2975 (6.401 sec/step)\n",
            "INFO:tensorflow:global step 792: loss = 2.0550 (5.032 sec/step)\n",
            "I1009 03:55:13.460407 140425799219072 learning.py:507] global step 792: loss = 2.0550 (5.032 sec/step)\n",
            "INFO:tensorflow:global step 793: loss = 1.9756 (4.695 sec/step)\n",
            "I1009 03:55:18.156903 140425799219072 learning.py:507] global step 793: loss = 1.9756 (4.695 sec/step)\n",
            "INFO:tensorflow:global step 794: loss = 2.2056 (5.016 sec/step)\n",
            "I1009 03:55:23.174527 140425799219072 learning.py:507] global step 794: loss = 2.2056 (5.016 sec/step)\n",
            "INFO:tensorflow:global step 795: loss = 1.6428 (4.971 sec/step)\n",
            "I1009 03:55:28.147130 140425799219072 learning.py:507] global step 795: loss = 1.6428 (4.971 sec/step)\n",
            "INFO:tensorflow:global step 796: loss = 1.7638 (5.099 sec/step)\n",
            "I1009 03:55:33.248295 140425799219072 learning.py:507] global step 796: loss = 1.7638 (5.099 sec/step)\n",
            "INFO:tensorflow:global step 797: loss = 2.2753 (5.190 sec/step)\n",
            "I1009 03:55:38.439982 140425799219072 learning.py:507] global step 797: loss = 2.2753 (5.190 sec/step)\n",
            "INFO:tensorflow:global step 798: loss = 2.0092 (5.112 sec/step)\n",
            "I1009 03:55:43.553884 140425799219072 learning.py:507] global step 798: loss = 2.0092 (5.112 sec/step)\n",
            "INFO:tensorflow:global step 799: loss = 2.0446 (4.775 sec/step)\n",
            "I1009 03:55:48.330261 140425799219072 learning.py:507] global step 799: loss = 2.0446 (4.775 sec/step)\n",
            "INFO:tensorflow:global step 800: loss = 2.1137 (4.826 sec/step)\n",
            "I1009 03:55:53.158023 140425799219072 learning.py:507] global step 800: loss = 2.1137 (4.826 sec/step)\n",
            "INFO:tensorflow:global step 801: loss = 1.5399 (4.839 sec/step)\n",
            "I1009 03:55:57.999152 140425799219072 learning.py:507] global step 801: loss = 1.5399 (4.839 sec/step)\n",
            "INFO:tensorflow:global step 802: loss = 1.4901 (4.884 sec/step)\n",
            "I1009 03:56:02.885290 140425799219072 learning.py:507] global step 802: loss = 1.4901 (4.884 sec/step)\n",
            "INFO:tensorflow:global step 803: loss = 1.8028 (4.741 sec/step)\n",
            "I1009 03:56:07.628251 140425799219072 learning.py:507] global step 803: loss = 1.8028 (4.741 sec/step)\n",
            "INFO:tensorflow:global step 804: loss = 1.5230 (4.739 sec/step)\n",
            "I1009 03:56:12.368931 140425799219072 learning.py:507] global step 804: loss = 1.5230 (4.739 sec/step)\n",
            "INFO:tensorflow:global step 805: loss = 1.9471 (4.762 sec/step)\n",
            "I1009 03:56:17.133232 140425799219072 learning.py:507] global step 805: loss = 1.9471 (4.762 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 805.\n",
            "I1009 03:56:24.474563 140422698682112 supervisor.py:1050] Recording summary at step 805.\n",
            "INFO:tensorflow:global step 806: loss = 1.7879 (8.296 sec/step)\n",
            "I1009 03:56:25.431721 140425799219072 learning.py:507] global step 806: loss = 1.7879 (8.296 sec/step)\n",
            "INFO:tensorflow:global step 807: loss = 2.5068 (4.862 sec/step)\n",
            "I1009 03:56:30.295476 140425799219072 learning.py:507] global step 807: loss = 2.5068 (4.862 sec/step)\n",
            "INFO:tensorflow:global step 808: loss = 1.7492 (4.749 sec/step)\n",
            "I1009 03:56:35.047324 140425799219072 learning.py:507] global step 808: loss = 1.7492 (4.749 sec/step)\n",
            "INFO:tensorflow:global step 809: loss = 2.6942 (4.639 sec/step)\n",
            "I1009 03:56:39.688353 140425799219072 learning.py:507] global step 809: loss = 2.6942 (4.639 sec/step)\n",
            "INFO:tensorflow:global step 810: loss = 1.5239 (4.791 sec/step)\n",
            "I1009 03:56:44.481258 140425799219072 learning.py:507] global step 810: loss = 1.5239 (4.791 sec/step)\n",
            "INFO:tensorflow:global step 811: loss = 1.8798 (4.890 sec/step)\n",
            "I1009 03:56:49.373353 140425799219072 learning.py:507] global step 811: loss = 1.8798 (4.890 sec/step)\n",
            "INFO:tensorflow:global step 812: loss = 1.5734 (4.875 sec/step)\n",
            "I1009 03:56:54.250003 140425799219072 learning.py:507] global step 812: loss = 1.5734 (4.875 sec/step)\n",
            "INFO:tensorflow:global step 813: loss = 1.7485 (4.849 sec/step)\n",
            "I1009 03:56:59.101265 140425799219072 learning.py:507] global step 813: loss = 1.7485 (4.849 sec/step)\n",
            "INFO:tensorflow:global step 814: loss = 2.9012 (4.970 sec/step)\n",
            "I1009 03:57:04.073667 140425799219072 learning.py:507] global step 814: loss = 2.9012 (4.970 sec/step)\n",
            "INFO:tensorflow:global step 815: loss = 1.6157 (5.175 sec/step)\n",
            "I1009 03:57:09.250983 140425799219072 learning.py:507] global step 815: loss = 1.6157 (5.175 sec/step)\n",
            "INFO:tensorflow:global step 816: loss = 2.2427 (5.167 sec/step)\n",
            "I1009 03:57:14.420152 140425799219072 learning.py:507] global step 816: loss = 2.2427 (5.167 sec/step)\n",
            "INFO:tensorflow:global step 817: loss = 1.8407 (5.014 sec/step)\n",
            "I1009 03:57:19.436269 140425799219072 learning.py:507] global step 817: loss = 1.8407 (5.014 sec/step)\n",
            "INFO:tensorflow:global step 818: loss = 1.7584 (4.958 sec/step)\n",
            "I1009 03:57:24.396405 140425799219072 learning.py:507] global step 818: loss = 1.7584 (4.958 sec/step)\n",
            "INFO:tensorflow:global step 819: loss = 2.1881 (4.972 sec/step)\n",
            "I1009 03:57:29.369879 140425799219072 learning.py:507] global step 819: loss = 2.1881 (4.972 sec/step)\n",
            "INFO:tensorflow:global step 820: loss = 1.4532 (4.904 sec/step)\n",
            "I1009 03:57:34.276100 140425799219072 learning.py:507] global step 820: loss = 1.4532 (4.904 sec/step)\n",
            "INFO:tensorflow:global step 821: loss = 1.5960 (4.907 sec/step)\n",
            "I1009 03:57:39.184581 140425799219072 learning.py:507] global step 821: loss = 1.5960 (4.907 sec/step)\n",
            "INFO:tensorflow:global step 822: loss = 2.2173 (4.882 sec/step)\n",
            "I1009 03:57:44.068452 140425799219072 learning.py:507] global step 822: loss = 2.2173 (4.882 sec/step)\n",
            "INFO:tensorflow:global step 823: loss = 1.3859 (4.712 sec/step)\n",
            "I1009 03:57:48.782126 140425799219072 learning.py:507] global step 823: loss = 1.3859 (4.712 sec/step)\n",
            "INFO:tensorflow:global step 824: loss = 1.8378 (5.021 sec/step)\n",
            "I1009 03:57:53.805270 140425799219072 learning.py:507] global step 824: loss = 1.8378 (5.021 sec/step)\n",
            "INFO:tensorflow:global step 825: loss = 2.4079 (4.891 sec/step)\n",
            "I1009 03:57:58.697839 140425799219072 learning.py:507] global step 825: loss = 2.4079 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 826: loss = 1.9817 (4.927 sec/step)\n",
            "I1009 03:58:03.626957 140425799219072 learning.py:507] global step 826: loss = 1.9817 (4.927 sec/step)\n",
            "INFO:tensorflow:global step 827: loss = 1.6918 (4.824 sec/step)\n",
            "I1009 03:58:08.453122 140425799219072 learning.py:507] global step 827: loss = 1.6918 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 828: loss = 2.0023 (4.975 sec/step)\n",
            "I1009 03:58:13.429974 140425799219072 learning.py:507] global step 828: loss = 2.0023 (4.975 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 03:58:17.244416 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 829: loss = 2.4675 (4.661 sec/step)\n",
            "I1009 03:58:19.818504 140425799219072 learning.py:507] global step 829: loss = 2.4675 (4.661 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 829.\n",
            "I1009 03:58:28.061053 140422698682112 supervisor.py:1050] Recording summary at step 829.\n",
            "INFO:tensorflow:global step 830: loss = 2.2106 (9.084 sec/step)\n",
            "I1009 03:58:29.177394 140425799219072 learning.py:507] global step 830: loss = 2.2106 (9.084 sec/step)\n",
            "INFO:tensorflow:global step 831: loss = 2.0187 (5.156 sec/step)\n",
            "I1009 03:58:34.335488 140425799219072 learning.py:507] global step 831: loss = 2.0187 (5.156 sec/step)\n",
            "INFO:tensorflow:global step 832: loss = 2.2093 (4.798 sec/step)\n",
            "I1009 03:58:39.135326 140425799219072 learning.py:507] global step 832: loss = 2.2093 (4.798 sec/step)\n",
            "INFO:tensorflow:global step 833: loss = 1.4741 (4.903 sec/step)\n",
            "I1009 03:58:44.040560 140425799219072 learning.py:507] global step 833: loss = 1.4741 (4.903 sec/step)\n",
            "INFO:tensorflow:global step 834: loss = 1.9727 (4.961 sec/step)\n",
            "I1009 03:58:49.003224 140425799219072 learning.py:507] global step 834: loss = 1.9727 (4.961 sec/step)\n",
            "INFO:tensorflow:global step 835: loss = 1.6320 (4.863 sec/step)\n",
            "I1009 03:58:53.868465 140425799219072 learning.py:507] global step 835: loss = 1.6320 (4.863 sec/step)\n",
            "INFO:tensorflow:global step 836: loss = 1.9281 (5.044 sec/step)\n",
            "I1009 03:58:58.914071 140425799219072 learning.py:507] global step 836: loss = 1.9281 (5.044 sec/step)\n",
            "INFO:tensorflow:global step 837: loss = 2.0540 (4.881 sec/step)\n",
            "I1009 03:59:03.797845 140425799219072 learning.py:507] global step 837: loss = 2.0540 (4.881 sec/step)\n",
            "INFO:tensorflow:global step 838: loss = 1.8456 (4.966 sec/step)\n",
            "I1009 03:59:08.767384 140425799219072 learning.py:507] global step 838: loss = 1.8456 (4.966 sec/step)\n",
            "INFO:tensorflow:global step 839: loss = 2.6632 (4.929 sec/step)\n",
            "I1009 03:59:13.698191 140425799219072 learning.py:507] global step 839: loss = 2.6632 (4.929 sec/step)\n",
            "INFO:tensorflow:global step 840: loss = 1.7450 (4.892 sec/step)\n",
            "I1009 03:59:18.592054 140425799219072 learning.py:507] global step 840: loss = 1.7450 (4.892 sec/step)\n",
            "INFO:tensorflow:global step 841: loss = 2.0629 (4.903 sec/step)\n",
            "I1009 03:59:23.496958 140425799219072 learning.py:507] global step 841: loss = 2.0629 (4.903 sec/step)\n",
            "INFO:tensorflow:global step 842: loss = 2.0161 (5.325 sec/step)\n",
            "I1009 03:59:28.824312 140425799219072 learning.py:507] global step 842: loss = 2.0161 (5.325 sec/step)\n",
            "INFO:tensorflow:global step 843: loss = 2.5973 (4.840 sec/step)\n",
            "I1009 03:59:33.665871 140425799219072 learning.py:507] global step 843: loss = 2.5973 (4.840 sec/step)\n",
            "INFO:tensorflow:global step 844: loss = 1.9937 (4.945 sec/step)\n",
            "I1009 03:59:38.613217 140425799219072 learning.py:507] global step 844: loss = 1.9937 (4.945 sec/step)\n",
            "INFO:tensorflow:global step 845: loss = 1.9429 (4.909 sec/step)\n",
            "I1009 03:59:43.524211 140425799219072 learning.py:507] global step 845: loss = 1.9429 (4.909 sec/step)\n",
            "INFO:tensorflow:global step 846: loss = 1.7665 (4.901 sec/step)\n",
            "I1009 03:59:48.426773 140425799219072 learning.py:507] global step 846: loss = 1.7665 (4.901 sec/step)\n",
            "INFO:tensorflow:global step 847: loss = 1.6744 (4.866 sec/step)\n",
            "I1009 03:59:53.294463 140425799219072 learning.py:507] global step 847: loss = 1.6744 (4.866 sec/step)\n",
            "INFO:tensorflow:global step 848: loss = 2.3416 (4.971 sec/step)\n",
            "I1009 03:59:58.267168 140425799219072 learning.py:507] global step 848: loss = 2.3416 (4.971 sec/step)\n",
            "INFO:tensorflow:global step 849: loss = 1.8417 (5.031 sec/step)\n",
            "I1009 04:00:03.299804 140425799219072 learning.py:507] global step 849: loss = 1.8417 (5.031 sec/step)\n",
            "INFO:tensorflow:global step 850: loss = 1.6489 (4.993 sec/step)\n",
            "I1009 04:00:08.294950 140425799219072 learning.py:507] global step 850: loss = 1.6489 (4.993 sec/step)\n",
            "INFO:tensorflow:global step 851: loss = 1.4088 (5.085 sec/step)\n",
            "I1009 04:00:13.383192 140425799219072 learning.py:507] global step 851: loss = 1.4088 (5.085 sec/step)\n",
            "INFO:tensorflow:global step 852: loss = 1.5531 (5.673 sec/step)\n",
            "I1009 04:00:19.085630 140425799219072 learning.py:507] global step 852: loss = 1.5531 (5.673 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 852.\n",
            "I1009 04:00:25.196339 140422698682112 supervisor.py:1050] Recording summary at step 852.\n",
            "INFO:tensorflow:global step 853: loss = 1.3586 (7.289 sec/step)\n",
            "I1009 04:00:26.377512 140425799219072 learning.py:507] global step 853: loss = 1.3586 (7.289 sec/step)\n",
            "INFO:tensorflow:global step 854: loss = 2.1014 (4.931 sec/step)\n",
            "I1009 04:00:31.310924 140425799219072 learning.py:507] global step 854: loss = 2.1014 (4.931 sec/step)\n",
            "INFO:tensorflow:global step 855: loss = 2.0359 (4.989 sec/step)\n",
            "I1009 04:00:36.302063 140425799219072 learning.py:507] global step 855: loss = 2.0359 (4.989 sec/step)\n",
            "INFO:tensorflow:global step 856: loss = 2.2395 (5.096 sec/step)\n",
            "I1009 04:00:41.400827 140425799219072 learning.py:507] global step 856: loss = 2.2395 (5.096 sec/step)\n",
            "INFO:tensorflow:global step 857: loss = 1.9372 (4.902 sec/step)\n",
            "I1009 04:00:46.305351 140425799219072 learning.py:507] global step 857: loss = 1.9372 (4.902 sec/step)\n",
            "INFO:tensorflow:global step 858: loss = 1.5416 (4.802 sec/step)\n",
            "I1009 04:00:51.109290 140425799219072 learning.py:507] global step 858: loss = 1.5416 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 859: loss = 1.5985 (4.891 sec/step)\n",
            "I1009 04:00:56.002634 140425799219072 learning.py:507] global step 859: loss = 1.5985 (4.891 sec/step)\n",
            "INFO:tensorflow:global step 860: loss = 1.6101 (4.873 sec/step)\n",
            "I1009 04:01:00.877423 140425799219072 learning.py:507] global step 860: loss = 1.6101 (4.873 sec/step)\n",
            "INFO:tensorflow:global step 861: loss = 1.7588 (5.006 sec/step)\n",
            "I1009 04:01:05.885024 140425799219072 learning.py:507] global step 861: loss = 1.7588 (5.006 sec/step)\n",
            "INFO:tensorflow:global step 862: loss = 1.5651 (5.021 sec/step)\n",
            "I1009 04:01:10.907562 140425799219072 learning.py:507] global step 862: loss = 1.5651 (5.021 sec/step)\n",
            "INFO:tensorflow:global step 863: loss = 1.6655 (4.902 sec/step)\n",
            "I1009 04:01:15.811892 140425799219072 learning.py:507] global step 863: loss = 1.6655 (4.902 sec/step)\n",
            "INFO:tensorflow:global step 864: loss = 2.0221 (4.847 sec/step)\n",
            "I1009 04:01:20.661570 140425799219072 learning.py:507] global step 864: loss = 2.0221 (4.847 sec/step)\n",
            "INFO:tensorflow:global step 865: loss = 1.7642 (4.849 sec/step)\n",
            "I1009 04:01:25.513126 140425799219072 learning.py:507] global step 865: loss = 1.7642 (4.849 sec/step)\n",
            "INFO:tensorflow:global step 866: loss = 1.6299 (4.794 sec/step)\n",
            "I1009 04:01:30.308836 140425799219072 learning.py:507] global step 866: loss = 1.6299 (4.794 sec/step)\n",
            "INFO:tensorflow:global step 867: loss = 2.1387 (5.174 sec/step)\n",
            "I1009 04:01:35.484294 140425799219072 learning.py:507] global step 867: loss = 2.1387 (5.174 sec/step)\n",
            "INFO:tensorflow:global step 868: loss = 1.9068 (4.938 sec/step)\n",
            "I1009 04:01:40.424563 140425799219072 learning.py:507] global step 868: loss = 1.9068 (4.938 sec/step)\n",
            "INFO:tensorflow:global step 869: loss = 1.5207 (4.739 sec/step)\n",
            "I1009 04:01:45.165483 140425799219072 learning.py:507] global step 869: loss = 1.5207 (4.739 sec/step)\n",
            "INFO:tensorflow:global step 870: loss = 2.1947 (4.803 sec/step)\n",
            "I1009 04:01:49.969937 140425799219072 learning.py:507] global step 870: loss = 2.1947 (4.803 sec/step)\n",
            "INFO:tensorflow:global step 871: loss = 1.6002 (5.023 sec/step)\n",
            "I1009 04:01:54.994848 140425799219072 learning.py:507] global step 871: loss = 1.6002 (5.023 sec/step)\n",
            "INFO:tensorflow:global step 872: loss = 1.4799 (4.822 sec/step)\n",
            "I1009 04:01:59.818989 140425799219072 learning.py:507] global step 872: loss = 1.4799 (4.822 sec/step)\n",
            "INFO:tensorflow:global step 873: loss = 1.7523 (4.799 sec/step)\n",
            "I1009 04:02:04.619713 140425799219072 learning.py:507] global step 873: loss = 1.7523 (4.799 sec/step)\n",
            "INFO:tensorflow:global step 874: loss = 1.6952 (4.761 sec/step)\n",
            "I1009 04:02:09.382506 140425799219072 learning.py:507] global step 874: loss = 1.6952 (4.761 sec/step)\n",
            "INFO:tensorflow:global step 875: loss = 1.9456 (4.626 sec/step)\n",
            "I1009 04:02:14.010652 140425799219072 learning.py:507] global step 875: loss = 1.9456 (4.626 sec/step)\n",
            "INFO:tensorflow:global step 876: loss = 2.1059 (7.086 sec/step)\n",
            "I1009 04:02:21.106609 140425799219072 learning.py:507] global step 876: loss = 2.1059 (7.086 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 876.\n",
            "I1009 04:02:25.373122 140422698682112 supervisor.py:1050] Recording summary at step 876.\n",
            "INFO:tensorflow:global step 877: loss = 1.9954 (6.203 sec/step)\n",
            "I1009 04:02:27.311831 140425799219072 learning.py:507] global step 877: loss = 1.9954 (6.203 sec/step)\n",
            "INFO:tensorflow:global step 878: loss = 1.6869 (4.796 sec/step)\n",
            "I1009 04:02:32.109977 140425799219072 learning.py:507] global step 878: loss = 1.6869 (4.796 sec/step)\n",
            "INFO:tensorflow:global step 879: loss = 1.7424 (4.824 sec/step)\n",
            "I1009 04:02:36.935588 140425799219072 learning.py:507] global step 879: loss = 1.7424 (4.824 sec/step)\n",
            "INFO:tensorflow:global step 880: loss = 1.6565 (4.767 sec/step)\n",
            "I1009 04:02:41.704172 140425799219072 learning.py:507] global step 880: loss = 1.6565 (4.767 sec/step)\n",
            "INFO:tensorflow:global step 881: loss = 1.5500 (4.896 sec/step)\n",
            "I1009 04:02:46.602520 140425799219072 learning.py:507] global step 881: loss = 1.5500 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 882: loss = 1.6075 (4.845 sec/step)\n",
            "I1009 04:02:51.449552 140425799219072 learning.py:507] global step 882: loss = 1.6075 (4.845 sec/step)\n",
            "INFO:tensorflow:global step 883: loss = 1.7464 (5.349 sec/step)\n",
            "I1009 04:02:56.800207 140425799219072 learning.py:507] global step 883: loss = 1.7464 (5.349 sec/step)\n",
            "INFO:tensorflow:global step 884: loss = 1.4627 (4.884 sec/step)\n",
            "I1009 04:03:01.685793 140425799219072 learning.py:507] global step 884: loss = 1.4627 (4.884 sec/step)\n",
            "INFO:tensorflow:global step 885: loss = 1.5112 (4.878 sec/step)\n",
            "I1009 04:03:06.565500 140425799219072 learning.py:507] global step 885: loss = 1.5112 (4.878 sec/step)\n",
            "INFO:tensorflow:global step 886: loss = 2.0839 (4.744 sec/step)\n",
            "I1009 04:03:11.311398 140425799219072 learning.py:507] global step 886: loss = 2.0839 (4.744 sec/step)\n",
            "INFO:tensorflow:global step 887: loss = 1.6995 (4.734 sec/step)\n",
            "I1009 04:03:16.047165 140425799219072 learning.py:507] global step 887: loss = 1.6995 (4.734 sec/step)\n",
            "INFO:tensorflow:global step 888: loss = 1.6244 (4.882 sec/step)\n",
            "I1009 04:03:20.930866 140425799219072 learning.py:507] global step 888: loss = 1.6244 (4.882 sec/step)\n",
            "INFO:tensorflow:global step 889: loss = 1.6538 (4.761 sec/step)\n",
            "I1009 04:03:25.694283 140425799219072 learning.py:507] global step 889: loss = 1.6538 (4.761 sec/step)\n",
            "INFO:tensorflow:global step 890: loss = 1.7797 (4.779 sec/step)\n",
            "I1009 04:03:30.475418 140425799219072 learning.py:507] global step 890: loss = 1.7797 (4.779 sec/step)\n",
            "INFO:tensorflow:global step 891: loss = 1.6830 (4.834 sec/step)\n",
            "I1009 04:03:35.311652 140425799219072 learning.py:507] global step 891: loss = 1.6830 (4.834 sec/step)\n",
            "INFO:tensorflow:global step 892: loss = 1.6332 (4.920 sec/step)\n",
            "I1009 04:03:40.233962 140425799219072 learning.py:507] global step 892: loss = 1.6332 (4.920 sec/step)\n",
            "INFO:tensorflow:global step 893: loss = 2.2291 (4.668 sec/step)\n",
            "I1009 04:03:44.903596 140425799219072 learning.py:507] global step 893: loss = 2.2291 (4.668 sec/step)\n",
            "INFO:tensorflow:global step 894: loss = 1.5300 (4.896 sec/step)\n",
            "I1009 04:03:49.801272 140425799219072 learning.py:507] global step 894: loss = 1.5300 (4.896 sec/step)\n",
            "INFO:tensorflow:global step 895: loss = 1.9911 (4.794 sec/step)\n",
            "I1009 04:03:54.597183 140425799219072 learning.py:507] global step 895: loss = 1.9911 (4.794 sec/step)\n",
            "INFO:tensorflow:global step 896: loss = 1.2565 (4.715 sec/step)\n",
            "I1009 04:03:59.314337 140425799219072 learning.py:507] global step 896: loss = 1.2565 (4.715 sec/step)\n",
            "INFO:tensorflow:global step 897: loss = 1.5034 (4.803 sec/step)\n",
            "I1009 04:04:04.119993 140425799219072 learning.py:507] global step 897: loss = 1.5034 (4.803 sec/step)\n",
            "INFO:tensorflow:global step 898: loss = 1.8553 (4.630 sec/step)\n",
            "I1009 04:04:08.752182 140425799219072 learning.py:507] global step 898: loss = 1.8553 (4.630 sec/step)\n",
            "INFO:tensorflow:global step 899: loss = 2.4030 (4.972 sec/step)\n",
            "I1009 04:04:13.726196 140425799219072 learning.py:507] global step 899: loss = 2.4030 (4.972 sec/step)\n",
            "INFO:tensorflow:global step 900: loss = 1.4918 (5.851 sec/step)\n",
            "I1009 04:04:19.585301 140425799219072 learning.py:507] global step 900: loss = 1.4918 (5.851 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 900.\n",
            "I1009 04:04:25.160046 140422698682112 supervisor.py:1050] Recording summary at step 900.\n",
            "INFO:tensorflow:global step 901: loss = 2.5835 (6.775 sec/step)\n",
            "I1009 04:04:26.378786 140425799219072 learning.py:507] global step 901: loss = 2.5835 (6.775 sec/step)\n",
            "INFO:tensorflow:global step 902: loss = 1.8059 (4.873 sec/step)\n",
            "I1009 04:04:31.253969 140425799219072 learning.py:507] global step 902: loss = 1.8059 (4.873 sec/step)\n",
            "INFO:tensorflow:global step 903: loss = 1.7280 (4.716 sec/step)\n",
            "I1009 04:04:35.972886 140425799219072 learning.py:507] global step 903: loss = 1.7280 (4.716 sec/step)\n",
            "INFO:tensorflow:global step 904: loss = 1.6465 (5.190 sec/step)\n",
            "I1009 04:04:41.164868 140425799219072 learning.py:507] global step 904: loss = 1.6465 (5.190 sec/step)\n",
            "INFO:tensorflow:global step 905: loss = 1.3375 (4.881 sec/step)\n",
            "I1009 04:04:46.047677 140425799219072 learning.py:507] global step 905: loss = 1.3375 (4.881 sec/step)\n",
            "INFO:tensorflow:global step 906: loss = 1.8240 (4.731 sec/step)\n",
            "I1009 04:04:50.780378 140425799219072 learning.py:507] global step 906: loss = 1.8240 (4.731 sec/step)\n",
            "INFO:tensorflow:global step 907: loss = 1.9144 (4.802 sec/step)\n",
            "I1009 04:04:55.583741 140425799219072 learning.py:507] global step 907: loss = 1.9144 (4.802 sec/step)\n",
            "INFO:tensorflow:global step 908: loss = 1.5238 (4.654 sec/step)\n",
            "I1009 04:05:00.239053 140425799219072 learning.py:507] global step 908: loss = 1.5238 (4.654 sec/step)\n",
            "INFO:tensorflow:global step 909: loss = 1.9006 (4.825 sec/step)\n",
            "I1009 04:05:05.066076 140425799219072 learning.py:507] global step 909: loss = 1.9006 (4.825 sec/step)\n",
            "INFO:tensorflow:global step 910: loss = 1.9068 (4.861 sec/step)\n",
            "I1009 04:05:09.929355 140425799219072 learning.py:507] global step 910: loss = 1.9068 (4.861 sec/step)\n",
            "INFO:tensorflow:global step 911: loss = 1.5670 (4.808 sec/step)\n",
            "I1009 04:05:14.739708 140425799219072 learning.py:507] global step 911: loss = 1.5670 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 912: loss = 1.7420 (4.880 sec/step)\n",
            "I1009 04:05:19.621981 140425799219072 learning.py:507] global step 912: loss = 1.7420 (4.880 sec/step)\n",
            "INFO:tensorflow:global step 913: loss = 1.6343 (4.738 sec/step)\n",
            "I1009 04:05:24.362172 140425799219072 learning.py:507] global step 913: loss = 1.6343 (4.738 sec/step)\n",
            "INFO:tensorflow:global step 914: loss = 2.4095 (4.871 sec/step)\n",
            "I1009 04:05:29.234979 140425799219072 learning.py:507] global step 914: loss = 2.4095 (4.871 sec/step)\n",
            "INFO:tensorflow:global step 915: loss = 1.9795 (4.933 sec/step)\n",
            "I1009 04:05:34.170196 140425799219072 learning.py:507] global step 915: loss = 1.9795 (4.933 sec/step)\n",
            "INFO:tensorflow:global step 916: loss = 1.3191 (4.821 sec/step)\n",
            "I1009 04:05:38.993444 140425799219072 learning.py:507] global step 916: loss = 1.3191 (4.821 sec/step)\n",
            "INFO:tensorflow:global step 917: loss = 1.9506 (4.918 sec/step)\n",
            "I1009 04:05:43.913086 140425799219072 learning.py:507] global step 917: loss = 1.9506 (4.918 sec/step)\n",
            "INFO:tensorflow:global step 918: loss = 1.4418 (4.940 sec/step)\n",
            "I1009 04:05:48.854923 140425799219072 learning.py:507] global step 918: loss = 1.4418 (4.940 sec/step)\n",
            "INFO:tensorflow:global step 919: loss = 1.5178 (4.914 sec/step)\n",
            "I1009 04:05:53.771601 140425799219072 learning.py:507] global step 919: loss = 1.5178 (4.914 sec/step)\n",
            "INFO:tensorflow:global step 920: loss = 1.9365 (4.808 sec/step)\n",
            "I1009 04:05:58.581386 140425799219072 learning.py:507] global step 920: loss = 1.9365 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 921: loss = 2.0597 (4.919 sec/step)\n",
            "I1009 04:06:03.502286 140425799219072 learning.py:507] global step 921: loss = 2.0597 (4.919 sec/step)\n",
            "INFO:tensorflow:global step 922: loss = 1.9025 (4.868 sec/step)\n",
            "I1009 04:06:08.372550 140425799219072 learning.py:507] global step 922: loss = 1.9025 (4.868 sec/step)\n",
            "INFO:tensorflow:global step 923: loss = 1.7429 (4.772 sec/step)\n",
            "I1009 04:06:13.146205 140425799219072 learning.py:507] global step 923: loss = 1.7429 (4.772 sec/step)\n",
            "INFO:tensorflow:global step 924: loss = 2.0239 (5.144 sec/step)\n",
            "I1009 04:06:18.436299 140425799219072 learning.py:507] global step 924: loss = 2.0239 (5.144 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 924.\n",
            "I1009 04:06:24.718776 140422698682112 supervisor.py:1050] Recording summary at step 924.\n",
            "INFO:tensorflow:global step 925: loss = 2.3996 (7.375 sec/step)\n",
            "I1009 04:06:25.964875 140425799219072 learning.py:507] global step 925: loss = 2.3996 (7.375 sec/step)\n",
            "INFO:tensorflow:global step 926: loss = 1.8683 (4.835 sec/step)\n",
            "I1009 04:06:30.801986 140425799219072 learning.py:507] global step 926: loss = 1.8683 (4.835 sec/step)\n",
            "INFO:tensorflow:global step 927: loss = 1.4907 (4.876 sec/step)\n",
            "I1009 04:06:35.680232 140425799219072 learning.py:507] global step 927: loss = 1.4907 (4.876 sec/step)\n",
            "INFO:tensorflow:global step 928: loss = 1.7073 (4.948 sec/step)\n",
            "I1009 04:06:40.629853 140425799219072 learning.py:507] global step 928: loss = 1.7073 (4.948 sec/step)\n",
            "INFO:tensorflow:global step 929: loss = 1.9224 (4.902 sec/step)\n",
            "I1009 04:06:45.533139 140425799219072 learning.py:507] global step 929: loss = 1.9224 (4.902 sec/step)\n",
            "INFO:tensorflow:global step 930: loss = 1.6206 (4.822 sec/step)\n",
            "I1009 04:06:50.356490 140425799219072 learning.py:507] global step 930: loss = 1.6206 (4.822 sec/step)\n",
            "INFO:tensorflow:global step 931: loss = 1.6427 (4.805 sec/step)\n",
            "I1009 04:06:55.163054 140425799219072 learning.py:507] global step 931: loss = 1.6427 (4.805 sec/step)\n",
            "INFO:tensorflow:global step 932: loss = 1.4639 (5.001 sec/step)\n",
            "I1009 04:07:00.166864 140425799219072 learning.py:507] global step 932: loss = 1.4639 (5.001 sec/step)\n",
            "INFO:tensorflow:global step 933: loss = 1.4048 (4.830 sec/step)\n",
            "I1009 04:07:05.000699 140425799219072 learning.py:507] global step 933: loss = 1.4048 (4.830 sec/step)\n",
            "INFO:tensorflow:global step 934: loss = 1.5721 (4.740 sec/step)\n",
            "I1009 04:07:09.744157 140425799219072 learning.py:507] global step 934: loss = 1.5721 (4.740 sec/step)\n",
            "INFO:tensorflow:global step 935: loss = 2.9350 (4.786 sec/step)\n",
            "I1009 04:07:14.532565 140425799219072 learning.py:507] global step 935: loss = 2.9350 (4.786 sec/step)\n",
            "INFO:tensorflow:global step 936: loss = 1.9969 (4.793 sec/step)\n",
            "I1009 04:07:19.327299 140425799219072 learning.py:507] global step 936: loss = 1.9969 (4.793 sec/step)\n",
            "INFO:tensorflow:global step 937: loss = 1.5773 (4.803 sec/step)\n",
            "I1009 04:07:24.132543 140425799219072 learning.py:507] global step 937: loss = 1.5773 (4.803 sec/step)\n",
            "INFO:tensorflow:global step 938: loss = 2.1495 (5.124 sec/step)\n",
            "I1009 04:07:29.258477 140425799219072 learning.py:507] global step 938: loss = 2.1495 (5.124 sec/step)\n",
            "INFO:tensorflow:global step 939: loss = 1.4765 (4.800 sec/step)\n",
            "I1009 04:07:34.060583 140425799219072 learning.py:507] global step 939: loss = 1.4765 (4.800 sec/step)\n",
            "INFO:tensorflow:global step 940: loss = 1.5357 (4.883 sec/step)\n",
            "I1009 04:07:38.945971 140425799219072 learning.py:507] global step 940: loss = 1.5357 (4.883 sec/step)\n",
            "INFO:tensorflow:global step 941: loss = 1.5996 (4.813 sec/step)\n",
            "I1009 04:07:43.760567 140425799219072 learning.py:507] global step 941: loss = 1.5996 (4.813 sec/step)\n",
            "INFO:tensorflow:global step 942: loss = 1.8134 (4.778 sec/step)\n",
            "I1009 04:07:48.540511 140425799219072 learning.py:507] global step 942: loss = 1.8134 (4.778 sec/step)\n",
            "INFO:tensorflow:global step 943: loss = 2.0436 (4.837 sec/step)\n",
            "I1009 04:07:53.379887 140425799219072 learning.py:507] global step 943: loss = 2.0436 (4.837 sec/step)\n",
            "INFO:tensorflow:global step 944: loss = 2.4210 (4.699 sec/step)\n",
            "I1009 04:07:58.080966 140425799219072 learning.py:507] global step 944: loss = 2.4210 (4.699 sec/step)\n",
            "INFO:tensorflow:global step 945: loss = 1.7074 (4.620 sec/step)\n",
            "I1009 04:08:02.703323 140425799219072 learning.py:507] global step 945: loss = 1.7074 (4.620 sec/step)\n",
            "INFO:tensorflow:global step 946: loss = 1.7776 (4.902 sec/step)\n",
            "I1009 04:08:07.606937 140425799219072 learning.py:507] global step 946: loss = 1.7776 (4.902 sec/step)\n",
            "INFO:tensorflow:global step 947: loss = 1.4197 (4.788 sec/step)\n",
            "I1009 04:08:12.396477 140425799219072 learning.py:507] global step 947: loss = 1.4197 (4.788 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "I1009 04:08:17.244416 140422665111296 supervisor.py:1117] Saving checkpoint to path /content/compproject/training/model.ckpt\n",
            "INFO:tensorflow:global step 948: loss = 1.6413 (4.992 sec/step)\n",
            "I1009 04:08:17.409975 140425799219072 learning.py:507] global step 948: loss = 1.6413 (4.992 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 948.\n",
            "I1009 04:08:27.070474 140422698682112 supervisor.py:1050] Recording summary at step 948.\n",
            "INFO:tensorflow:global step 949: loss = 2.2279 (10.262 sec/step)\n",
            "I1009 04:08:27.912047 140425799219072 learning.py:507] global step 949: loss = 2.2279 (10.262 sec/step)\n",
            "INFO:tensorflow:global step 950: loss = 1.7069 (5.001 sec/step)\n",
            "I1009 04:08:32.915610 140425799219072 learning.py:507] global step 950: loss = 1.7069 (5.001 sec/step)\n",
            "INFO:tensorflow:global step 951: loss = 1.4084 (4.810 sec/step)\n",
            "I1009 04:08:37.727453 140425799219072 learning.py:507] global step 951: loss = 1.4084 (4.810 sec/step)\n",
            "INFO:tensorflow:global step 952: loss = 1.5309 (4.794 sec/step)\n",
            "I1009 04:08:42.523324 140425799219072 learning.py:507] global step 952: loss = 1.5309 (4.794 sec/step)\n",
            "INFO:tensorflow:global step 953: loss = 1.8584 (4.900 sec/step)\n",
            "I1009 04:08:47.425464 140425799219072 learning.py:507] global step 953: loss = 1.8584 (4.900 sec/step)\n",
            "INFO:tensorflow:global step 954: loss = 1.9739 (4.740 sec/step)\n",
            "I1009 04:08:52.167811 140425799219072 learning.py:507] global step 954: loss = 1.9739 (4.740 sec/step)\n",
            "INFO:tensorflow:global step 955: loss = 1.7201 (5.158 sec/step)\n",
            "I1009 04:08:57.327999 140425799219072 learning.py:507] global step 955: loss = 1.7201 (5.158 sec/step)\n",
            "INFO:tensorflow:global step 956: loss = 1.5416 (4.791 sec/step)\n",
            "I1009 04:09:02.121064 140425799219072 learning.py:507] global step 956: loss = 1.5416 (4.791 sec/step)\n",
            "INFO:tensorflow:global step 957: loss = 2.0277 (5.045 sec/step)\n",
            "I1009 04:09:07.167852 140425799219072 learning.py:507] global step 957: loss = 2.0277 (5.045 sec/step)\n",
            "INFO:tensorflow:global step 958: loss = 1.8525 (4.880 sec/step)\n",
            "I1009 04:09:12.050128 140425799219072 learning.py:507] global step 958: loss = 1.8525 (4.880 sec/step)\n",
            "INFO:tensorflow:global step 959: loss = 1.7648 (4.877 sec/step)\n",
            "I1009 04:09:16.929441 140425799219072 learning.py:507] global step 959: loss = 1.7648 (4.877 sec/step)\n",
            "INFO:tensorflow:global step 960: loss = 2.2740 (4.841 sec/step)\n",
            "I1009 04:09:21.772294 140425799219072 learning.py:507] global step 960: loss = 2.2740 (4.841 sec/step)\n",
            "INFO:tensorflow:global step 961: loss = 1.9809 (5.083 sec/step)\n",
            "I1009 04:09:26.856775 140425799219072 learning.py:507] global step 961: loss = 1.9809 (5.083 sec/step)\n",
            "INFO:tensorflow:global step 962: loss = 2.7834 (4.841 sec/step)\n",
            "I1009 04:09:31.700483 140425799219072 learning.py:507] global step 962: loss = 2.7834 (4.841 sec/step)\n",
            "INFO:tensorflow:global step 963: loss = 1.6651 (5.265 sec/step)\n",
            "I1009 04:09:36.967173 140425799219072 learning.py:507] global step 963: loss = 1.6651 (5.265 sec/step)\n",
            "INFO:tensorflow:global step 964: loss = 1.7223 (4.843 sec/step)\n",
            "I1009 04:09:41.811771 140425799219072 learning.py:507] global step 964: loss = 1.7223 (4.843 sec/step)\n",
            "INFO:tensorflow:global step 965: loss = 1.8839 (4.760 sec/step)\n",
            "I1009 04:09:46.573802 140425799219072 learning.py:507] global step 965: loss = 1.8839 (4.760 sec/step)\n",
            "INFO:tensorflow:global step 966: loss = 1.7028 (4.936 sec/step)\n",
            "I1009 04:09:51.512063 140425799219072 learning.py:507] global step 966: loss = 1.7028 (4.936 sec/step)\n",
            "INFO:tensorflow:global step 967: loss = 1.6231 (4.808 sec/step)\n",
            "I1009 04:09:56.322064 140425799219072 learning.py:507] global step 967: loss = 1.6231 (4.808 sec/step)\n",
            "INFO:tensorflow:global step 968: loss = 1.6740 (4.766 sec/step)\n",
            "I1009 04:10:01.090275 140425799219072 learning.py:507] global step 968: loss = 1.6740 (4.766 sec/step)\n",
            "INFO:tensorflow:global step 969: loss = 1.2633 (4.774 sec/step)\n",
            "I1009 04:10:05.867222 140425799219072 learning.py:507] global step 969: loss = 1.2633 (4.774 sec/step)\n",
            "INFO:tensorflow:global step 970: loss = 1.8630 (4.723 sec/step)\n",
            "I1009 04:10:10.594287 140425799219072 learning.py:507] global step 970: loss = 1.8630 (4.723 sec/step)\n",
            "INFO:tensorflow:global step 971: loss = 1.8848 (4.956 sec/step)\n",
            "I1009 04:10:15.552119 140425799219072 learning.py:507] global step 971: loss = 1.8848 (4.956 sec/step)\n",
            "INFO:tensorflow:global step 972: loss = 1.8789 (7.824 sec/step)\n",
            "I1009 04:10:23.378487 140425799219072 learning.py:507] global step 972: loss = 1.8789 (7.824 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 972.\n",
            "I1009 04:10:25.706725 140422698682112 supervisor.py:1050] Recording summary at step 972.\n",
            "INFO:tensorflow:global step 973: loss = 1.8440 (5.055 sec/step)\n",
            "I1009 04:10:28.435883 140425799219072 learning.py:507] global step 973: loss = 1.8440 (5.055 sec/step)\n",
            "INFO:tensorflow:global step 974: loss = 1.6765 (4.669 sec/step)\n",
            "I1009 04:10:33.107069 140425799219072 learning.py:507] global step 974: loss = 1.6765 (4.669 sec/step)\n",
            "INFO:tensorflow:global step 975: loss = 1.9688 (4.641 sec/step)\n",
            "I1009 04:10:37.749769 140425799219072 learning.py:507] global step 975: loss = 1.9688 (4.641 sec/step)\n",
            "INFO:tensorflow:global step 976: loss = 1.3981 (4.620 sec/step)\n",
            "I1009 04:10:42.372279 140425799219072 learning.py:507] global step 976: loss = 1.3981 (4.620 sec/step)\n",
            "INFO:tensorflow:global step 977: loss = 2.6064 (4.820 sec/step)\n",
            "I1009 04:10:47.194270 140425799219072 learning.py:507] global step 977: loss = 2.6064 (4.820 sec/step)\n",
            "INFO:tensorflow:global step 978: loss = 1.5255 (4.624 sec/step)\n",
            "I1009 04:10:51.820292 140425799219072 learning.py:507] global step 978: loss = 1.5255 (4.624 sec/step)\n",
            "INFO:tensorflow:global step 979: loss = 2.4366 (5.385 sec/step)\n",
            "I1009 04:10:57.207316 140425799219072 learning.py:507] global step 979: loss = 2.4366 (5.385 sec/step)\n",
            "INFO:tensorflow:global step 980: loss = 2.2894 (4.677 sec/step)\n",
            "I1009 04:11:01.886751 140425799219072 learning.py:507] global step 980: loss = 2.2894 (4.677 sec/step)\n",
            "INFO:tensorflow:global step 981: loss = 1.5287 (4.761 sec/step)\n",
            "I1009 04:11:06.650026 140425799219072 learning.py:507] global step 981: loss = 1.5287 (4.761 sec/step)\n",
            "INFO:tensorflow:global step 982: loss = 1.5276 (4.811 sec/step)\n",
            "I1009 04:11:11.462580 140425799219072 learning.py:507] global step 982: loss = 1.5276 (4.811 sec/step)\n",
            "INFO:tensorflow:global step 983: loss = 1.3933 (4.657 sec/step)\n",
            "I1009 04:11:16.121338 140425799219072 learning.py:507] global step 983: loss = 1.3933 (4.657 sec/step)\n",
            "INFO:tensorflow:global step 984: loss = 1.5652 (4.609 sec/step)\n",
            "I1009 04:11:20.732359 140425799219072 learning.py:507] global step 984: loss = 1.5652 (4.609 sec/step)\n",
            "INFO:tensorflow:global step 985: loss = 1.8431 (5.033 sec/step)\n",
            "I1009 04:11:25.766676 140425799219072 learning.py:507] global step 985: loss = 1.8431 (5.033 sec/step)\n",
            "INFO:tensorflow:global step 986: loss = 1.8856 (5.199 sec/step)\n",
            "I1009 04:11:30.967466 140425799219072 learning.py:507] global step 986: loss = 1.8856 (5.199 sec/step)\n",
            "INFO:tensorflow:global step 987: loss = 2.5806 (4.800 sec/step)\n",
            "I1009 04:11:35.769317 140425799219072 learning.py:507] global step 987: loss = 2.5806 (4.800 sec/step)\n",
            "INFO:tensorflow:global step 988: loss = 1.8018 (4.913 sec/step)\n",
            "I1009 04:11:40.683831 140425799219072 learning.py:507] global step 988: loss = 1.8018 (4.913 sec/step)\n",
            "INFO:tensorflow:global step 989: loss = 2.3413 (4.669 sec/step)\n",
            "I1009 04:11:45.354819 140425799219072 learning.py:507] global step 989: loss = 2.3413 (4.669 sec/step)\n",
            "INFO:tensorflow:global step 990: loss = 1.6560 (4.654 sec/step)\n",
            "I1009 04:11:50.011021 140425799219072 learning.py:507] global step 990: loss = 1.6560 (4.654 sec/step)\n",
            "INFO:tensorflow:global step 991: loss = 2.0144 (4.792 sec/step)\n",
            "I1009 04:11:54.805339 140425799219072 learning.py:507] global step 991: loss = 2.0144 (4.792 sec/step)\n",
            "INFO:tensorflow:global step 992: loss = 1.4114 (5.057 sec/step)\n",
            "I1009 04:11:59.864012 140425799219072 learning.py:507] global step 992: loss = 1.4114 (5.057 sec/step)\n",
            "INFO:tensorflow:global step 993: loss = 1.7672 (4.791 sec/step)\n",
            "I1009 04:12:04.657088 140425799219072 learning.py:507] global step 993: loss = 1.7672 (4.791 sec/step)\n",
            "INFO:tensorflow:global step 994: loss = 2.0439 (4.875 sec/step)\n",
            "I1009 04:12:09.533823 140425799219072 learning.py:507] global step 994: loss = 2.0439 (4.875 sec/step)\n",
            "INFO:tensorflow:global step 995: loss = 2.1150 (4.708 sec/step)\n",
            "I1009 04:12:14.244148 140425799219072 learning.py:507] global step 995: loss = 2.1150 (4.708 sec/step)\n",
            "INFO:tensorflow:global step 996: loss = 1.7021 (7.039 sec/step)\n",
            "I1009 04:12:21.285460 140425799219072 learning.py:507] global step 996: loss = 1.7021 (7.039 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 996.\n",
            "I1009 04:12:25.169315 140422698682112 supervisor.py:1050] Recording summary at step 996.\n",
            "INFO:tensorflow:global step 997: loss = 1.7228 (5.594 sec/step)\n",
            "I1009 04:12:26.881159 140425799219072 learning.py:507] global step 997: loss = 1.7228 (5.594 sec/step)\n",
            "INFO:tensorflow:global step 998: loss = 2.1329 (4.714 sec/step)\n",
            "I1009 04:12:31.596829 140425799219072 learning.py:507] global step 998: loss = 2.1329 (4.714 sec/step)\n",
            "INFO:tensorflow:global step 999: loss = 2.0769 (4.622 sec/step)\n",
            "I1009 04:12:36.221242 140425799219072 learning.py:507] global step 999: loss = 2.0769 (4.622 sec/step)\n",
            "INFO:tensorflow:global step 1000: loss = 1.4759 (4.711 sec/step)\n",
            "I1009 04:12:40.934367 140425799219072 learning.py:507] global step 1000: loss = 1.4759 (4.711 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I1009 04:12:40.935271 140425799219072 learning.py:777] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I1009 04:12:40.935504 140425799219072 learning.py:785] Finished training! Saving model to disk.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgzzh11v4gaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath('/content/compproject/training'), \"frozen_inference_graph_300.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M80VnHyRTWW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d76b6a34-7a23-4170-a6d9-1350fe5a4ade"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once in a notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fname = os.path.basename(pb_fname)\n",
        "# Create & upload a text file.\n",
        "uploaded = drive.CreateFile({'title': fname})\n",
        "uploaded.SetContentFile(pb_fname)\n",
        "uploaded.Upload()\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploaded file with ID 1UscSJTN8SPZzV4gF8JGwcfoCqBC_lsG9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4brE5dVxjtK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "86c6d963-be67-4e87-b557-2925a53d9893"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyL5BMa6istL",
        "colab_type": "code",
        "outputId": "673cdca1-4b98-46a7-ca8d-8681019c6604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 /content/models/research/object_detection/inference/infer_detections.py \\\n",
        "    --input_tfrecord_paths=/content/compproject/data/valid.record \\\n",
        "    --output_tfrecord_path=/content/compproject/detections.record \\\n",
        "    --inference_graph=/content/compproject/training/frozen_inference_graph_2100.pb"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:96: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W1010 04:22:54.939427 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1010 04:22:54.939744 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W1010 04:22:54.939942 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:65: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2019-10-10 04:22:54.942297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-10 04:22:54.962290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:54.963064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-10 04:22:54.963379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-10 04:22:54.965043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-10 04:22:54.966511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-10 04:22:54.966857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-10 04:22:54.968723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-10 04:22:54.970120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-10 04:22:54.974378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-10 04:22:54.974493: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:54.975276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:54.975941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-10 04:22:54.983717: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-10 04:22:54.983946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27a9480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-10 04:22:54.983980: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-10-10 04:22:55.042334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.043122: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27a9d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-10 04:22:55.043168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-10 04:22:55.043357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.044089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-10 04:22:55.044171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-10 04:22:55.044205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-10 04:22:55.044236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-10 04:22:55.044266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-10 04:22:55.044296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-10 04:22:55.044325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-10 04:22:55.044354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-10 04:22:55.044451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.045408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.046048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-10 04:22:55.046111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-10 04:22:55.047494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-10 04:22:55.047536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-10 04:22:55.047552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-10 04:22:55.047694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.048519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-10 04:22:55.049418: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-10 04:22:55.049510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1010 04:22:55.050480 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:68: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Reading input from 1 files\n",
            "I1010 04:22:55.050768 139974849140608 infer_detections.py:68] Reading input from 1 files\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W1010 04:22:55.051739 139974849140608 deprecation.py:323] From /content/models/research/object_detection/inference/detection_inference.py:35: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "W1010 04:22:55.058990 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:277: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "W1010 04:22:55.059299 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:189: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "W1010 04:22:55.062575 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:112: RefVariable.count_up_to (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "W1010 04:22:55.062762 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py:2522: count_up_to (from tensorflow.python.ops.state_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Dataset.range instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1010 04:22:55.065834 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1010 04:22:55.067076 139974849140608 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:198: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "W1010 04:22:55.071428 139974849140608 deprecation.py:323] From /content/models/research/object_detection/inference/detection_inference.py:37: TFRecordReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W1010 04:22:55.072667 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:39: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W1010 04:22:55.072897 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:43: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Reading graph and building model...\n",
            "I1010 04:22:55.125332 139974849140608 infer_detections.py:71] Reading graph and building model...\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1010 04:22:55.125617 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:68: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "W1010 04:22:55.154879 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:70: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1010 04:22:55.973397 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:76: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "INFO:tensorflow:Running inference and writing output to /content/compproject/detections.record\n",
            "I1010 04:22:55.995515 139974849140608 infer_detections.py:77] Running inference and writing output to /content/compproject/detections.record\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "W1010 04:22:55.995711 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:78: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W1010 04:22:56.101079 139974849140608 deprecation.py:323] From /content/models/research/object_detection/inference/infer_detections.py:79: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1010 04:22:56.102325 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:80: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
            "\n",
            "W1010 04:22:56.108890 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/infer_detections.py:84: The name tf.logging.log_every_n is deprecated. Please use tf.compat.v1.logging.log_every_n instead.\n",
            "\n",
            "INFO:tensorflow:Processed 0 images...\n",
            "I1010 04:22:56.109117 139974849140608 infer_detections.py:85] Processed 0 images...\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W1010 04:22:56.109467 139974849140608 module_wrapper.py:139] From /content/models/research/object_detection/inference/detection_inference.py:117: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "2019-10-10 04:22:57.858051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-10 04:22:58.611658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "INFO:tensorflow:Processed 10 images...\n",
            "I1010 04:22:59.682339 139974849140608 infer_detections.py:85] Processed 10 images...\n",
            "INFO:tensorflow:Processed 20 images...\n",
            "I1010 04:23:00.043089 139974849140608 infer_detections.py:85] Processed 20 images...\n",
            "INFO:tensorflow:Processed 30 images...\n",
            "I1010 04:23:00.404681 139974849140608 infer_detections.py:85] Processed 30 images...\n",
            "INFO:tensorflow:Processed 40 images...\n",
            "I1010 04:23:00.767016 139974849140608 infer_detections.py:85] Processed 40 images...\n",
            "INFO:tensorflow:Processed 50 images...\n",
            "I1010 04:23:01.128818 139974849140608 infer_detections.py:85] Processed 50 images...\n",
            "INFO:tensorflow:Processed 60 images...\n",
            "I1010 04:23:01.499736 139974849140608 infer_detections.py:85] Processed 60 images...\n",
            "INFO:tensorflow:Processed 70 images...\n",
            "I1010 04:23:01.860185 139974849140608 infer_detections.py:85] Processed 70 images...\n",
            "INFO:tensorflow:Processed 80 images...\n",
            "I1010 04:23:02.225819 139974849140608 infer_detections.py:85] Processed 80 images...\n",
            "INFO:tensorflow:Processed 90 images...\n",
            "I1010 04:23:02.598004 139974849140608 infer_detections.py:85] Processed 90 images...\n",
            "INFO:tensorflow:Processed 100 images...\n",
            "I1010 04:23:02.989851 139974849140608 infer_detections.py:85] Processed 100 images...\n",
            "INFO:tensorflow:Processed 110 images...\n",
            "I1010 04:23:03.358797 139974849140608 infer_detections.py:85] Processed 110 images...\n",
            "INFO:tensorflow:Processed 120 images...\n",
            "I1010 04:23:03.760711 139974849140608 infer_detections.py:85] Processed 120 images...\n",
            "INFO:tensorflow:Processed 130 images...\n",
            "I1010 04:23:04.138050 139974849140608 infer_detections.py:85] Processed 130 images...\n",
            "INFO:tensorflow:Processed 140 images...\n",
            "I1010 04:23:04.509694 139974849140608 infer_detections.py:85] Processed 140 images...\n",
            "INFO:tensorflow:Processed 150 images...\n",
            "I1010 04:23:04.891409 139974849140608 infer_detections.py:85] Processed 150 images...\n",
            "INFO:tensorflow:Processed 160 images...\n",
            "I1010 04:23:05.263385 139974849140608 infer_detections.py:85] Processed 160 images...\n",
            "INFO:tensorflow:Processed 170 images...\n",
            "I1010 04:23:05.652192 139974849140608 infer_detections.py:85] Processed 170 images...\n",
            "INFO:tensorflow:Processed 180 images...\n",
            "I1010 04:23:06.023836 139974849140608 infer_detections.py:85] Processed 180 images...\n",
            "INFO:tensorflow:Processed 190 images...\n",
            "I1010 04:23:06.387337 139974849140608 infer_detections.py:85] Processed 190 images...\n",
            "INFO:tensorflow:Processed 200 images...\n",
            "I1010 04:23:06.775932 139974849140608 infer_detections.py:85] Processed 200 images...\n",
            "INFO:tensorflow:Processed 210 images...\n",
            "I1010 04:23:07.151573 139974849140608 infer_detections.py:85] Processed 210 images...\n",
            "INFO:tensorflow:Processed 220 images...\n",
            "I1010 04:23:07.529844 139974849140608 infer_detections.py:85] Processed 220 images...\n",
            "INFO:tensorflow:Finished processing records\n",
            "I1010 04:23:07.838913 139974849140608 infer_detections.py:92] Finished processing records\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr3dAN4XpytB",
        "colab_type": "code",
        "outputId": "5fd967a0-023d-4ff6-e706-2f38ccd60edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!python3 confusion_matrix.py --detections_record=detections.record --label_map=/content/compproject/training/labelmap.pbtxt --output_path=confusion_matrix_300.csv\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From confusion_matrix.py:146: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1010 04:19:05.557204 139977069356928 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From confusion_matrix.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "W1010 04:19:05.559253 139977069356928 deprecation.py:323] From confusion_matrix.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Processed 100 images\n",
            "Processed 200 images\n",
            "Processed 228 images\n",
            "\n",
            "Confusion Matrix:\n",
            "[[67.  0.  4.  5.]\n",
            " [29. 30.  5. 12.]\n",
            " [20.  1. 45. 10.]\n",
            " [ 8.  3.  7.  0.]] \n",
            "\n",
            "    category  ...  m_recall_@0.5IOU\n",
            "0  peacesign  ...          0.881579\n",
            "1   palmhand  ...          0.394737\n",
            "2     oksign  ...          0.592105\n",
            "\n",
            "[3 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw3NlO324ok-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "ba0ac3b1-ad1b-4f30-995d-6123dcb8ade8"
      },
      "source": [
        "!python3 confusion_matrix.py --detections_record=detections.record --label_map=/content/compproject/training/labelmap.pbtxt --output_path=confusion_matrix_2100.csv\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From confusion_matrix.py:146: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1010 04:23:27.329237 140187422312320 module_wrapper.py:139] From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From confusion_matrix.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "W1010 04:23:27.331402 140187422312320 deprecation.py:323] From confusion_matrix.py:38: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Processed 100 images\n",
            "Processed 200 images\n",
            "Processed 228 images\n",
            "\n",
            "Confusion Matrix:\n",
            "[[74.  0.  0.  2.]\n",
            " [18. 48.  1.  9.]\n",
            " [13.  1. 56.  6.]\n",
            " [18. 11.  3.  0.]] \n",
            "\n",
            "    category  ...  m_recall_@0.5IOU\n",
            "0  peacesign  ...          0.973684\n",
            "1   palmhand  ...          0.631579\n",
            "2     oksign  ...          0.736842\n",
            "\n",
            "[3 rows x 4 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbgdFU6qTkVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/compproject/training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZf9GmW6TprF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/compproject/training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn8HeHeAefPP",
        "colab_type": "code",
        "outputId": "84ee133f-f83e-484b-dba6-f9a14d9fab20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/models/research\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
        "  \n",
        "%matplotlib inline\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "output_directory = '/content/compproject/training'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sirmpx6lffaS",
        "colab_type": "code",
        "outputId": "c1c9770b-a749-43c4-fd39-0e2c68487845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path=/content/compproject/training/ssd_mobilenet_v2.config --trained_checkpoint_prefix=/content/compproject/training/model.ckpt-1000 --output_directory /content/compproject/training"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1009 04:15:39.429652 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W1009 04:15:39.482714 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/core/preprocessor.py:2660: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1009 04:15:39.525027 140646824134528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1009 04:15:42.441479 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.441791 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.493680 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.545938 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.597552 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.649620 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:15:42.701656 140646824134528 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:567: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1009 04:15:43.202256 140646824134528 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:567: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:362: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W1009 04:15:43.663376 140646824134528 deprecation.py:323] From /content/models/research/object_detection/exporter.py:362: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1009 04:15:45.631449 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1009 04:15:45.631922 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1009 04:15:45.632339 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1009 04:15:45.632666 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1009 04:15:45.633075 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1009 04:15:45.633353 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1009 04:15:45.633705 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1009 04:15:45.633960 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1009 04:15:45.634345 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1009 04:15:45.634667 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1009 04:15:45.635078 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1009 04:15:45.635365 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1009 04:15:45.635730 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1009 04:15:45.635990 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1009 04:15:45.636371 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1009 04:15:45.636690 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1009 04:15:45.637089 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1009 04:15:45.637368 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1009 04:15:45.637737 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1009 04:15:45.638008 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1009 04:15:45.638398 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1009 04:15:45.638710 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1009 04:15:45.639129 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1009 04:15:45.639411 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1009 04:15:45.639785 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1009 04:15:45.640071 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1009 04:15:45.640449 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1009 04:15:45.640763 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1009 04:15:45.641188 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1009 04:15:45.641466 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1009 04:15:45.641840 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1009 04:15:45.642125 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1009 04:15:45.642567 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1009 04:15:45.642872 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1009 04:15:45.643283 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1009 04:15:45.643545 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1009 04:15:45.643820 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1009 04:15:45.644123 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1009 04:15:45.644433 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1009 04:15:45.644747 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1009 04:15:45.645022 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1009 04:15:45.645333 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1009 04:15:45.645592 140646824134528 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:518: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W1009 04:15:45.649688 140646824134528 deprecation.py:323] From /content/models/research/object_detection/exporter.py:518: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W1009 04:15:45.651428 140646824134528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "252 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.61m params)\n",
            "  BoxPredictor_0 (--/13.85k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "  BoxPredictor_1 (--/61.49k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "  BoxPredictor_2 (--/24.62k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  BoxPredictor_3 (--/12.34k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_4 (--/12.34k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "  BoxPredictor_5 (--/6.19k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "252 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/4.49m flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n",
            "  FeatureExtractor/MobilenetV2/Conv_1/mul_fold (409.60k/409.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/mul_fold (327.68k/327.68k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_16/project/mul_fold (307.20k/307.20k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_15/expand/mul_fold (153.60k/153.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_16/expand/mul_fold (153.60k/153.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_15/project/mul_fold (153.60k/153.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_14/project/mul_fold (153.60k/153.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_14/expand/mul_fold (153.60k/153.60k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_13/project/mul_fold (92.16k/92.16k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_11/project/mul_fold (55.30k/55.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_13/expand/mul_fold (55.30k/55.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_12/project/mul_fold (55.30k/55.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_12/expand/mul_fold (55.30k/55.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_11/expand/mul_fold (55.30k/55.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_10/project/mul_fold (36.86k/36.86k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_7/expand/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_7/project/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_8/expand/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_8/project/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_9/expand/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_9/project/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_10/expand/mul_fold (24.58k/24.58k flops)\n",
            "  FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_6/project/mul_fold (12.29k/12.29k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/mul_fold (8.64k/8.64k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/mul_fold (8.64k/8.64k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/mul_fold (8.64k/8.64k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_4/project/mul_fold (6.14k/6.14k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_6/expand/mul_fold (6.14k/6.14k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_5/project/mul_fold (6.14k/6.14k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_5/expand/mul_fold (6.14k/6.14k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_4/expand/mul_fold (6.14k/6.14k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/mul_fold (5.18k/5.18k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/mul_fold (5.18k/5.18k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/mul_fold (5.18k/5.18k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_3/project/mul_fold (4.61k/4.61k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_2/project/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_3/expand/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_2/expand/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/mul_fold (3.46k/3.46k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_1/project/mul_fold (2.30k/2.30k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/mul_fold (1.73k/1.73k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/mul_fold (1.73k/1.73k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/mul_fold (1.73k/1.73k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_1/expand/mul_fold (1.54k/1.54k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/mul_fold (1.30k/1.30k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/mul_fold (1.30k/1.30k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/mul_fold (864/864 flops)\n",
            "  FeatureExtractor/MobilenetV2/Conv/mul_fold (864/864 flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv/project/mul_fold (512/512 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  FeatureExtractor/MobilenetV2/expanded_conv/depthwise/mul_fold (288/288 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:411: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W1009 04:15:47.901290 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/exporter.py:411: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2019-10-09 04:15:49.787311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-09 04:15:49.837004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:49.837848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:15:49.844703: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:15:49.870006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:15:49.930624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:15:49.943336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:15:49.959935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:15:49.979444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:15:50.054202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:15:50.054523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.055419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.056125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:15:50.081481: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-09 04:15:50.081848: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29b2d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:15:50.081917: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-10-09 04:15:50.195734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.196677: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29b2f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:15:50.196712: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-09 04:15:50.197088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.197770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:15:50.197892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:15:50.197948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:15:50.197987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:15:50.198046: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:15:50.198087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:15:50.198134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:15:50.198195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:15:50.198336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.199179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.199845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:15:50.204591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:15:50.207595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:15:50.207650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:15:50.207674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:15:50.208133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.208951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:50.209669: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-09 04:15:50.209737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "I1009 04:15:50.212273 140646824134528 saver.py:1284] Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1009 04:15:55.860952 140646824134528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-10-09 04:15:56.989475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:56.990293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:15:56.990385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:15:56.990419: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:15:56.990452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:15:56.990478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:15:56.990505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:15:56.990530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:15:56.990557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:15:56.990653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:56.991393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:56.992062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:15:56.992116: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:15:56.992133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:15:56.992145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:15:56.992283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:56.993013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:56.993702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "I1009 04:15:56.995303 140646824134528 saver.py:1284] Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1009 04:15:58.590793 140646824134528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1009 04:15:58.591214 140646824134528 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 632 variables.\n",
            "I1009 04:15:59.383550 140646824134528 graph_util_impl.py:334] Froze 632 variables.\n",
            "INFO:tensorflow:Converted 632 variables to const ops.\n",
            "I1009 04:15:59.528367 140646824134528 graph_util_impl.py:394] Converted 632 variables to const ops.\n",
            "2019-10-09 04:15:59.818389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:59.819198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:15:59.819336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:15:59.819401: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:15:59.819431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:15:59.819457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:15:59.819483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:15:59.819507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:15:59.819534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:15:59.819634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:59.820394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:59.821064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:15:59.821124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:15:59.821143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:15:59.821163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:15:59.821372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:59.822142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:15:59.822827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:288: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W1009 04:16:00.855075 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/exporter.py:288: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:291: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W1009 04:16:00.858822 140646824134528 deprecation.py:323] From /content/models/research/object_detection/exporter.py:291: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:297: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W1009 04:16:00.859678 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/exporter.py:297: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:300: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W1009 04:16:00.859915 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/exporter.py:300: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:305: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W1009 04:16:00.860196 140646824134528 module_wrapper.py:137] From /content/models/research/object_detection/exporter.py:305: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I1009 04:16:00.860563 140646824134528 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I1009 04:16:00.860677 140646824134528 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/compproject/training/saved_model/saved_model.pb\n",
            "I1009 04:16:01.402276 140646824134528 builder_impl.py:425] SavedModel written to: /content/compproject/training/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /content/compproject/training/pipeline.config\n",
            "I1009 04:16:01.450138 140646824134528 config_util.py:190] Writing pipeline config file to /content/compproject/training/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVQ1v__tTYFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k53D0YRKf6OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
        "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_FROZEN_GRAPH ='/content/compproject/training/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/content/compproject/training/object-detection.pbtxt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X2Ik_tUgH9f",
        "colab_type": "code",
        "outputId": "6a2f0681-a149-42df-ea87-8496e88cfb52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/content/compproject/images/valid'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 3) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = pb_fname\n",
        "\n",
        "assert os.path.isfile(pb_fname)\n",
        "assert os.path.isfile(PATH_TO_LABELS)\n",
        "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
        "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
        "print(TEST_IMAGE_PATHS)\n",
        "\n",
        "num_classes = 3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/compproject/images/valid/image2.jpg', '/content/compproject/images/valid/image1.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTVISMkr46Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dLsY0oL48Zx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFeblGpMgiLO",
        "colab_type": "code",
        "outputId": "342ffed4-04db-44a2-c3f9-8651dcb043d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "    (im_width, im_height) = image.size\n",
        "    return np.array(image.getdata()).reshape(\n",
        "        (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(image, graph):\n",
        "    with graph.as_default():\n",
        "        with tf.Session() as sess:\n",
        "            # Get handles to input and output tensors\n",
        "            ops = tf.get_default_graph().get_operations()\n",
        "            all_tensor_names = {\n",
        "                output.name for op in ops for output in op.outputs}\n",
        "            tensor_dict = {}\n",
        "            for key in [\n",
        "                'num_detections', 'detection_boxes', 'detection_scores',\n",
        "                'detection_classes', 'detection_masks'\n",
        "            ]:\n",
        "                tensor_name = key + ':0'\n",
        "                if tensor_name in all_tensor_names:\n",
        "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "                        tensor_name)\n",
        "            if 'detection_masks' in tensor_dict:\n",
        "                # The following processing is only for single image\n",
        "                detection_boxes = tf.squeeze(\n",
        "                    tensor_dict['detection_boxes'], [0])\n",
        "                detection_masks = tf.squeeze(\n",
        "                    tensor_dict['detection_masks'], [0])\n",
        "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "                real_num_detection = tf.cast(\n",
        "                    tensor_dict['num_detections'][0], tf.int32)\n",
        "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
        "                                           real_num_detection, -1])\n",
        "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
        "                                           real_num_detection, -1, -1])\n",
        "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "                detection_masks_reframed = tf.cast(\n",
        "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "                # Follow the convention by adding back the batch dimension\n",
        "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "                    detection_masks_reframed, 0)\n",
        "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "            # Run inference\n",
        "            output_dict = sess.run(tensor_dict,\n",
        "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "            output_dict['num_detections'] = int(\n",
        "                output_dict['num_detections'][0])\n",
        "            output_dict['detection_classes'] = output_dict[\n",
        "                'detection_classes'][0].astype(np.uint8)\n",
        "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "            if 'detection_masks' in output_dict:\n",
        "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "    return output_dict\n",
        "\n",
        "\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    # Visualization of the results of a detection.\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        output_dict['detection_boxes'],\n",
        "        output_dict['detection_classes'],\n",
        "        output_dict['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=output_dict.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:137: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAHVCAYAAAC+Mo9RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASoAAAHWCAYAAADAasRNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O782JgxAd5sR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8b39b5a-66aa-4477-ebd5-d0a5a5bc0e06"
      },
      "source": [
        "%cd /content/models/research/object_detection\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8y7dJA_guTM",
        "colab_type": "code",
        "outputId": "4cc67476-34af-439c-c74d-0d15c0efef15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python export_tflite_ssd_graph.py --pipeline_config_path=/content/compproject/training/ssd_mobilenet_v2.config --trained_checkpoint_prefix=/content/compproject/training/model.ckpt-1000 --output_directory=/content/compproject/litemodel --add_postprocessing_op=true"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1009 04:30:23.210998 140166865774464 module_wrapper.py:137] From export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1009 04:30:23.223653 140166865774464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W1009 04:30:26.027598 140166865774464 module_wrapper.py:137] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.027935 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.068083 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.108012 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.148849 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.196932 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1009 04:30:26.247692 140166865774464 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "2019-10-09 04:30:26.308809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-09 04:30:26.328129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.328919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:30:26.329307: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:26.330897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:30:26.332289: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:30:26.332733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:30:26.351547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:30:26.353370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:30:26.357817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:30:26.358062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.358955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.359722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:30:26.367301: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-09 04:30:26.367599: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14acd80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:30:26.367643: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-10-09 04:30:26.428365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.429273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14acbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:30:26.429309: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-09 04:30:26.429531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.430250: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:30:26.430350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:26.430387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:30:26.430422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:30:26.430450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:30:26.430481: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:30:26.430513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:30:26.430546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:30:26.430650: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.431417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.432122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:30:26.432195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:26.433823: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:30:26.433862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:30:26.433877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:30:26.434088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.434876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:26.435587: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-09 04:30:26.435645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:260: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W1009 04:30:27.084880 140166865774464 module_wrapper.py:137] From /content/models/research/object_detection/export_tflite_ssd_graph_lib.py:260: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "I1009 04:30:29.102446 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "I1009 04:30:29.102963 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "I1009 04:30:29.103337 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "I1009 04:30:29.103578 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "I1009 04:30:29.103922 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "I1009 04:30:29.104171 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "I1009 04:30:29.104508 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "I1009 04:30:29.104734 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "I1009 04:30:29.105094 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "I1009 04:30:29.105342 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "I1009 04:30:29.105672 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "I1009 04:30:29.105910 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "I1009 04:30:29.106256 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "I1009 04:30:29.106490 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "I1009 04:30:29.106825 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "I1009 04:30:29.107073 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "I1009 04:30:29.107403 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "I1009 04:30:29.107627 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "I1009 04:30:29.107964 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "I1009 04:30:29.108209 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "I1009 04:30:29.108537 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "I1009 04:30:29.108763 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "I1009 04:30:29.109117 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "I1009 04:30:29.109349 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "I1009 04:30:29.109747 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "I1009 04:30:29.110054 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "I1009 04:30:29.110410 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "I1009 04:30:29.110647 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "I1009 04:30:29.110986 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "I1009 04:30:29.111242 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "I1009 04:30:29.111578 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "I1009 04:30:29.111823 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "I1009 04:30:29.112174 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/expand/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "I1009 04:30:29.112418 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "I1009 04:30:29.112752 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/Conv_1/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "I1009 04:30:29.112987 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "I1009 04:30:29.113222 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "I1009 04:30:29.113439 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "I1009 04:30:29.113654 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "I1009 04:30:29.113898 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "I1009 04:30:29.114138 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "I1009 04:30:29.114356 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/add_fold\n",
            "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "I1009 04:30:29.114569 140166865774464 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/add_fold\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W1009 04:30:29.788685 140166865774464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-10-09 04:30:30.813824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:30.814652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:30:30.814753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:30.814803: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:30:30.814847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:30:30.814888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:30:30.814930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:30:30.814970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:30:30.815009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:30:30.815148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:30.815894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:30.816560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:30:30.816622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:30:30.816643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:30:30.816659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:30:30.816814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:30.817569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:30.818288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "I1009 04:30:30.819889 140166865774464 saver.py:1284] Restoring parameters from /content/compproject/training/model.ckpt-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W1009 04:30:32.191220 140166865774464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W1009 04:30:32.191577 140166865774464 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 632 variables.\n",
            "I1009 04:30:32.920731 140166865774464 graph_util_impl.py:334] Froze 632 variables.\n",
            "INFO:tensorflow:Converted 632 variables to const ops.\n",
            "I1009 04:30:33.027002 140166865774464 graph_util_impl.py:394] Converted 632 variables to const ops.\n",
            "2019-10-09 04:30:33.232758: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDFSkKOLhSSl",
        "colab_type": "code",
        "outputId": "723f4d83-771e-4970-d1e4-a8763fa95398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        }
      },
      "source": [
        "!tflite_convert \\\n",
        "--graph_def_file=/content/compproject/litemodel/tflite_graph.pb \\\n",
        "--output_file=/content/compproject/litemodel/detect.tflite \\\n",
        "--output_format=TFLITE \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\n",
        "--inference_type=QUANTIZED_UINT8 \\\n",
        "--mean_values=128 \\\n",
        "--std_dev_values=127 \\\n",
        "--change_concat_input_ranges=false \\\n",
        "--allow_custom_ops"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-10-09 04:30:55.302983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-10-09 04:30:55.321338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.322108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:30:55.322473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:55.329101: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:30:55.330555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:30:55.330935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:30:55.332848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:30:55.334705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:30:55.338928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:30:55.339126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.339946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.340682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:30:55.369936: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-10-09 04:30:55.371730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558af85bd640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:30:55.371776: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-10-09 04:30:55.444797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.445669: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558af85bdd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2019-10-09 04:30:55.445701: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-10-09 04:30:55.445895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.446577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-10-09 04:30:55.446641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:55.446664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
            "2019-10-09 04:30:55.446682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
            "2019-10-09 04:30:55.446701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
            "2019-10-09 04:30:55.446720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
            "2019-10-09 04:30:55.446739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
            "2019-10-09 04:30:55.446758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2019-10-09 04:30:55.446825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.447534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.448192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2019-10-09 04:30:55.451162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
            "2019-10-09 04:30:55.452653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-10-09 04:30:55.452697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2019-10-09 04:30:55.452726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2019-10-09 04:30:55.453550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.454343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-10-09 04:30:55.455057: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-10-09 04:30:55.455161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKnTLR0DfLcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}